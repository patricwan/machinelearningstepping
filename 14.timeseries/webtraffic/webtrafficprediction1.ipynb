{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/zoupet/predictive-analysis-with-different-approaches\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import scipy\n",
    "from datetime import timedelta\n",
    "\n",
    "# Forceasting with decompasable model\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# For marchine Learning Approach\n",
    "from statsmodels.tsa.tsatools import lagmat\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "train = pd.read_csv(\"../../../data/webtraffic/train_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_flattened = pd.melt(train[list(train.columns[-50:])+['Page']], id_vars='Page', var_name='date', value_name='Visits')\n",
    "train_flattened['date'] = train_flattened['date'].astype('datetime64[ns]')\n",
    "train_flattened['weekend'] = ((train_flattened.date.dt.dayofweek) // 5 == 1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Median by page\n",
    "df_median = pd.DataFrame(train_flattened.groupby(['Page'])['Visits'].median())\n",
    "df_median.columns = ['median']\n",
    "\n",
    "# Average by page\n",
    "df_mean = pd.DataFrame(train_flattened.groupby(['Page'])['Visits'].mean())\n",
    "df_mean.columns = ['mean']\n",
    "\n",
    "# Merging data\n",
    "train_flattened = train_flattened.set_index('Page').join(df_mean).join(df_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_flattened.reset_index(drop=False,inplace=True)\n",
    "train_flattened['weekday'] = train_flattened['date'].apply(lambda x: x.weekday())\n",
    "\n",
    "# Feature engineering with the date\n",
    "train_flattened['year']=train_flattened.date.dt.year \n",
    "train_flattened['month']=train_flattened.date.dt.month \n",
    "train_flattened['day']=train_flattened.date.dt.day\n",
    "\n",
    "train_flattened.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 8))\n",
    "mean_group = train_flattened[['Page','date','Visits']].groupby(['date'])['Visits'].mean()\n",
    "plt.plot(mean_group)\n",
    "plt.title('Time Series - Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 8))\n",
    "median_group = train_flattened[['Page','date','Visits']].groupby(['date'])['Visits'].median()\n",
    "plt.plot(median_group, color = 'r')\n",
    "plt.title('Time Series - median')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 8))\n",
    "std_group = train_flattened[['Page','date','Visits']].groupby(['date'])['Visits'].std()\n",
    "plt.plot(std_group, color = 'g')\n",
    "plt.title('Time Series - std')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the next graphics\n",
    "train_flattened['month_num'] = train_flattened['month']\n",
    "train_flattened['month'].replace('11','11 - November',inplace=True)\n",
    "train_flattened['month'].replace('12','12 - December',inplace=True)\n",
    "\n",
    "train_flattened['weekday_num'] = train_flattened['weekday']\n",
    "train_flattened['weekday'].replace(0,'01 - Monday',inplace=True)\n",
    "train_flattened['weekday'].replace(1,'02 - Tuesday',inplace=True)\n",
    "train_flattened['weekday'].replace(2,'03 - Wednesday',inplace=True)\n",
    "train_flattened['weekday'].replace(3,'04 - Thursday',inplace=True)\n",
    "train_flattened['weekday'].replace(4,'05 - Friday',inplace=True)\n",
    "train_flattened['weekday'].replace(5,'06 - Saturday',inplace=True)\n",
    "train_flattened['weekday'].replace(6,'07 - Sunday',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_group = train_flattened.groupby([\"month\", \"weekday\"])['Visits'].mean().reset_index()\n",
    "train_group = train_group.pivot('weekday','month','Visits')\n",
    "train_group.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=3.5) \n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(50, 30))\n",
    "sns.heatmap(train_group, annot=False, ax=ax, fmt=\"d\", linewidths=2)\n",
    "plt.title('Web Traffic Months cross Weekdays')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_day = train_flattened.groupby([\"month\", \"day\"])['Visits'].mean().reset_index()\n",
    "train_day = train_day.pivot('day','month','Visits')\n",
    "train_day.sort_index(inplace=True)\n",
    "train_day.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(50, 30))\n",
    "sns.heatmap(train_day, annot=False, ax=ax, fmt=\"d\", linewidths=2)\n",
    "plt.title('Web Traffic Months cross days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "times_series_means =  pd.DataFrame(mean_group).reset_index(drop=False)\n",
    "times_series_means['weekday'] = times_series_means['date'].apply(lambda x: x.weekday())\n",
    "times_series_means['Date_str'] = times_series_means['date'].apply(lambda x: str(x))\n",
    "times_series_means[['year','month','day']] = pd.DataFrame(times_series_means['Date_str'].str.split('-',2).tolist(), columns = ['year','month','day'])\n",
    "date_staging = pd.DataFrame(times_series_means['day'].str.split(' ',2).tolist(), columns = ['day','other'])\n",
    "times_series_means['day'] = date_staging['day']*1\n",
    "times_series_means.drop('Date_str',axis = 1, inplace =True)\n",
    "times_series_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_series_means.reset_index(drop=True,inplace=True)\n",
    "\n",
    "def lag_func(data,lag):\n",
    "    lag = lag\n",
    "    X = lagmat(data[\"diff\"], lag)\n",
    "    lagged = data.copy()\n",
    "    for c in range(1,lag+1):\n",
    "        lagged[\"lag%d\" % c] = X[:, c-1]\n",
    "    return lagged\n",
    "\n",
    "def diff_creation(data):\n",
    "    data[\"diff\"] = np.nan\n",
    "    data.ix[1:, \"diff\"] = (data.iloc[1:, 1].as_matrix() - data.iloc[:len(data)-1, 1].as_matrix())\n",
    "    return data\n",
    "\n",
    "df_count = diff_creation(times_series_means)\n",
    "\n",
    "# Creation of 7 features with \"diff\"\n",
    "lag = 7\n",
    "lagged = lag_func(df_count,lag)\n",
    "last_date = lagged['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lagged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(data_lag):\n",
    "    xc = [\"lag%d\" % i for i in range(1,lag+1)] + ['weekday'] + ['day']\n",
    "    split = 0.70\n",
    "    xt = data_lag[(lag+1):][xc]\n",
    "    yt = data_lag[(lag+1):][\"diff\"]\n",
    "    isplit = int(len(xt) * split)\n",
    "    x_train, y_train, x_test, y_test = xt[:isplit], yt[:isplit], xt[isplit:], yt[isplit:]\n",
    "    return x_train, y_train, x_test, y_test, xt, yt\n",
    "\n",
    "x_train, y_train, x_test, y_test, xt, yt = train_test(lagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "from sklearn.ensemble import ExtraTreesRegressor,GradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def modelisation(x_tr, y_tr, x_ts, y_ts, xt, yt, model0, model1):\n",
    "    # Modelisation with all product\n",
    "    model0.fit(x_tr, y_tr)\n",
    "\n",
    "    prediction = model0.predict(x_ts)\n",
    "    r2 = r2_score(y_ts.as_matrix(), model0.predict(x_ts))\n",
    "    mae = mean_absolute_error(y_ts.as_matrix(), model0.predict(x_ts))\n",
    "    print (\"-----------------------------------------------\")\n",
    "    print (\"mae with 70% of the data to train:\", mae)\n",
    "    print (\"-----------------------------------------------\")\n",
    "\n",
    "    # Model with all data\n",
    "    model1.fit(xt, yt) \n",
    "    \n",
    "    return model1, prediction, model0\n",
    "\n",
    "model0 =  AdaBoostRegressor(n_estimators = 5000, random_state = 42, learning_rate=0.01)\n",
    "model1 =  AdaBoostRegressor(n_estimators = 5000, random_state = 42, learning_rate=0.01)\n",
    "\n",
    "clr, prediction, clr0  = modelisation(x_train, y_train, x_test, y_test, xt, yt, model0, model1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Performance 1\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(50, 12))\n",
    "line_up, = plt.plot(prediction,label='Prediction')\n",
    "line_down, = plt.plot(np.array(y_test),label='Reality')\n",
    "plt.ylabel('Series')\n",
    "plt.legend(handles=[line_up, line_down])\n",
    "plt.title('Performance of predictions - Benchmark Predictions vs Reality')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def pred_df(data,number_of_days):\n",
    "    data_pred = pd.DataFrame(pd.Series(data[\"date\"][data.shape[0]-1] + timedelta(days=1)),columns = [\"date\"])\n",
    "    for i in range(number_of_days):\n",
    "        inter = pd.DataFrame(pd.Series(data[\"date\"][data.shape[0]-1] + timedelta(days=i+2)),columns = [\"date\"])\n",
    "        data_pred = pd.concat([data_pred,inter]).reset_index(drop=True)\n",
    "    return data_pred\n",
    "\n",
    "data_to_pred = pred_df(df_count,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialisation(data_lag, data_pred, model, xtrain, ytrain, number_of_days):\n",
    "    # Initialisation\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    for i in range(number_of_days-1):\n",
    "        lag1 = data_lag.tail(1)[\"diff\"].values[0]\n",
    "        lag2 = data_lag.tail(1)[\"lag1\"].values[0]\n",
    "        lag3 = data_lag.tail(1)[\"lag2\"].values[0]\n",
    "        lag4 = data_lag.tail(1)[\"lag3\"].values[0]\n",
    "        lag5 = data_lag.tail(1)[\"lag4\"].values[0]\n",
    "        lag6 = data_lag.tail(1)[\"lag5\"].values[0]\n",
    "        lag7 = data_lag.tail(1)[\"lag6\"].values[0]\n",
    "        lag8 = data_lag.tail(1)[\"lag7\"].values[0]\n",
    "        \n",
    "        data_pred['weekday'] = data_pred['date'].apply(lambda x:x.weekday())\n",
    "        weekday = data_pred['weekday'][0]\n",
    "        \n",
    "        row = pd.Series([lag1,lag2,lag3,lag4,lag5,lag6,lag7,lag8,weekday]\n",
    "                        ,['lag1', 'lag2', 'lag3','lag4','lag5','lag6','lag7','lag8','weekday'])\n",
    "        to_predict = pd.DataFrame(columns = ['lag1', 'lag2', 'lag3','lag4','lag5','lag6','lag7','lag8','weekday'])\n",
    "        prediction = pd.DataFrame(columns = ['diff'])\n",
    "        to_predict = to_predict.append([row])\n",
    "        prediction = pd.DataFrame(model.predict(to_predict),columns = ['diff'])\n",
    "\n",
    "        # Loop\n",
    "        if i == 0:\n",
    "            last_predict = data_lag[\"Visits\"][data_lag.shape[0]-1] + prediction.values[0][0]\n",
    "\n",
    "        if i > 0 :\n",
    "            last_predict = data_lag[\"Visits\"][data_lag.shape[0]-1] + prediction.values[0][0]\n",
    "        \n",
    "        data_lag = pd.concat([data_lag,prediction.join(data_pred[\"date\"]).join(to_predict)]).reset_index(drop=True)\n",
    "        data_lag[\"Visits\"][data_lag.shape[0]-1] = last_predict\n",
    "        \n",
    "        # test\n",
    "        data_pred = data_pred[data_pred[\"date\"]>data_pred[\"date\"][0]].reset_index(drop=True)\n",
    "        \n",
    "    return data_lag\n",
    "\n",
    "model_fin = AdaBoostRegressor(n_estimators = 5000, random_state = 42, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lagged = initialisation(lagged, data_to_pred, model_fin, xt, yt, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lagged[lagged['diff']<0]\n",
    "lagged.ix[(lagged.Visits < 0), 'Visits'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_lagged = lagged[['Visits','date']]\n",
    "df_train = df_lagged[df_lagged['date'] <= last_date]\n",
    "df_pred = df_lagged[df_lagged['date'] >= last_date]\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.plot(df_train.date,df_train.Visits)\n",
    "plt.plot(df_pred.date,df_pred.Visits,color='b')\n",
    "plt.title('Training time series in red, Prediction on 30 days in blue -- ML Approach')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lagged_basic = lagged[['date','Visits','weekday']]\n",
    "lagged_basic_tr   = lagged_basic[lagged_basic['date'] < last_date]\n",
    "lagged_basic_pred = lagged_basic[lagged_basic['date'] >= last_date]\n",
    "lagged_basic_pred.drop('Visits',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction_by_days = pd.DataFrame(lagged_basic.groupby(['weekday'])['Visits'].mean())\n",
    "prediction_by_days.reset_index(drop=False,inplace=True)\n",
    "prediction_by_days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_pred = pd.merge(lagged_basic_pred,prediction_by_days,on='weekday')\n",
    "basic_approach = pd.concat([lagged_basic_tr,basic_pred])\n",
    "plot_basic = np.array(basic_approach[basic_approach['date'] > last_date].sort_values(by='date').Visits)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.plot(plot_basic)\n",
    "plt.title('Display the predictions with the Basic model')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_lagged = basic_approach[['Visits','date']].sort_values(by='date')\n",
    "df_train = df_lagged[df_lagged['date'] <= last_date]\n",
    "df_pred = df_lagged[df_lagged['date'] >= last_date]\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.plot(df_train.date,df_train.Visits)\n",
    "plt.plot(df_pred.date,df_pred.Visits,color='b')\n",
    "plt.title('Training time series in red, Prediction on 30 days in blue -- ML Approach')\n",
    "plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show Rolling mean, Rolling Std and Test for the stationnarity\n",
    "df_date_index = times_series_means[['date','Visits']].set_index('date')\n",
    "\n",
    "def test_stationarity(timeseries):\n",
    "    plt.figure(figsize=(50, 8))\n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=7)\n",
    "    rolstd = pd.rolling_std(timeseries, window=7)\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = sm.tsa.adfuller(timeseries['Visits'], autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "test_stationarity(df_date_index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive decomposition of our Time Series as explained above\n",
    "decomposition = sm.tsa.seasonal_decompose(df_date_index, model='multiplicative',freq = 7)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "rcParams['figure.figsize'] = 30, 20\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.title('Obesered = Trend + Seasonality + Residuals')\n",
    "plt.plot(df_date_index, label='Observed')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "sns.set(font_scale=1) \n",
    "df_date_index = times_series_means[['date','Visits']]\n",
    "df_date_index = df_date_index.set_index('date')\n",
    "df_prophet = df_date_index.copy()\n",
    "df_prophet.reset_index(drop=False,inplace=True)\n",
    "df_prophet.columns = ['ds','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(df_prophet)\n",
    "future = m.make_future_dataframe(periods=30,freq='D')\n",
    "forecast = m.predict(future)\n",
    "fig = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m.plot_components(forecast);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dl = times_series_means[['date','Visits']]\n",
    "\n",
    "train_size = int(len(df_dl) * 0.80)\n",
    "test_size = len(df_dl) - train_size\n",
    "train, test = df_dl.iloc[0:train_size,:], df_dl.iloc[train_size:len(df_dl),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "look_back = 1\n",
    "\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset.iloc[i:(i+look_back), 1].values[0]\n",
    "        b = dataset.iloc[i+look_back, 1]\n",
    "        dataX.append(a)\n",
    "        dataY.append(b)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = create_dataset(train, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=look_back, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=150, batch_size=2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f MAE)' % (trainScore, trainScore))\n",
    "testScore = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f MAE)' % (testScore, testScore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    " \n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(df_dl)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    " \n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(df_dl)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(df_dl)-1, :] = testPredict\n",
    " \n",
    "# plot baseline and predictions\n",
    "plt.plot(np.array(df_dl.Visits))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.title('Predicition with Keras')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
