{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(11, 365, 1)\n",
      "11\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "from sklearn import metrics\n",
    "# from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "import gc\n",
    "\n",
    "from Utils import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress tf warnings\n",
    "\n",
    "timesteps = 365\n",
    "\n",
    "df, promo_df, items, stores = load_unstack('pw')\n",
    "\n",
    "# data after 2015\n",
    "df = df[pd.date_range(date(2013,1,1), date(2016,8,15))]\n",
    "promo_df = promo_df[pd.date_range(date(2013,1,1), date(2016,8,15))]\n",
    "\n",
    "promo_df = promo_df[df[pd.date_range(date(2013,1,1), date(2016,8,15))].max(axis=1)>0]\n",
    "df = df[df[pd.date_range(date(2013,1,1), date(2016,8,15))].max(axis=1)>0]\n",
    "promo_df = promo_df.astype('int')\n",
    "\n",
    "#print(\"df top 5\", df[:5])\n",
    "#print(\"promo_df top 5\", promo_df[:5])\n",
    "\n",
    "df_test = pd.read_csv(\"../../../data/favgrocery/test.csv\", usecols=[0, 1, 2, 3, 4], dtype={'onpromotion': bool},\n",
    "                      parse_dates=[\"date\"]).set_index(['store_nbr', 'item_nbr', 'date'])\n",
    "item_nbr_test = df_test.index.get_level_values(1)\n",
    "item_nbr_train = df.index.get_level_values(1)\n",
    "item_inter = list(set(item_nbr_train).intersection(set(item_nbr_test)))\n",
    "df = df.loc[df.index.get_level_values(1).isin(item_inter)]\n",
    "promo_df = promo_df.loc[promo_df.index.get_level_values(1).isin(item_inter)]\n",
    "\n",
    "df_index = df.index\n",
    "del item_nbr_test, item_nbr_train, item_inter, df_test; gc.collect()\n",
    "\n",
    "#print(\"df top 5 before gener train:\", df[:5])\n",
    "#print(\"promo_df top 5 before gener train:\", promo_df[:5])\n",
    "#print(\"items top 5 before gener train:\", items[:5])\n",
    "#print(\"stores top 5 before gener train:\", stores[:5])\n",
    "\n",
    "train_data = train_generator(df, promo_df, items, stores, timesteps, date(2016, 7, 9),\n",
    "                                           n_range=380, day_skip=1, batch_size=1000, aux_as_tensor=True, reshape_output=2)\n",
    "Xval, Yval = create_dataset(df, promo_df, items, stores, timesteps, date(2016, 7, 26),\n",
    "                                     aux_as_tensor=True, reshape_output=2)\n",
    "print(len(Xval))\n",
    "print(Xval[1].shape)\n",
    "print(len(Yval))\n",
    "print(Yval[0].shape)\n",
    "\n",
    "Xtest, _ = create_dataset(df, promo_df, items, stores, timesteps, date(2016, 2, 16),\n",
    "                                    aux_as_tensor=True, is_train=False, reshape_output=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_5:0\", shape=(?, 365, 1), dtype=float32)\n",
      "Tensor(\"input_6:0\", shape=(?, 365, 1), dtype=float32)\n",
      "Tensor(\"input_12:0\", shape=(?, 381), dtype=uint8)\n",
      "Tensor(\"embedding_1/embedding_lookup/Identity:0\", shape=(?, 381, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = (Xval[7][:, 0, 2] * 0.25 + 1) / (Xval[7][:, 0, 2] * 0.25 + 1).mean()\n",
    "latent_dim = 100\n",
    "\n",
    "seq_in = Input(shape=(timesteps, 1))\n",
    "is0_in = Input(shape=(timesteps, 1))\n",
    "print(seq_in)\n",
    "print(is0_in)\n",
    "\n",
    "promo_in = Input(shape=(timesteps+16, 1))\n",
    "yearAgo_in = Input(shape=(timesteps+16, 1))\n",
    "quarterAgo_in = Input(shape=(timesteps+16, 1))\n",
    "item_mean_in = Input(shape=(timesteps, 1))\n",
    "store_mean_in = Input(shape=(timesteps, 1))\n",
    "# store_family_mean_in = Input(shape=(timesteps, 1))\n",
    "weekday_in = Input(shape=(timesteps+16,), dtype='uint8')\n",
    "weekday_embed_encode = Embedding(7, 4, input_length=timesteps+16)(weekday_in)\n",
    "# weekday_embed_decode = Embedding(7, 4, input_length=timesteps+16)(weekday_in)\n",
    "dom_in = Input(shape=(timesteps+16,), dtype='uint8')\n",
    "dom_embed_encode = Embedding(31, 4, input_length=timesteps+16)(dom_in)\n",
    "print(weekday_in)\n",
    "print(weekday_embed_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_14:0\", shape=(?, 381, 6), dtype=float32)\n",
      "Tensor(\"lambda_1/strided_slice:0\", shape=(?, 381), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cat_features = Input(shape=(timesteps+16, 6))\n",
    "\n",
    "item_family = Lambda(lambda x: x[:, :, 0])(cat_features)\n",
    "item_class = Lambda(lambda x: x[:, :, 1])(cat_features)\n",
    "item_perish = Lambda(lambda x: x[:, :, 2])(cat_features)\n",
    "store_nbr = Lambda(lambda x: x[:, :, 3])(cat_features)\n",
    "store_cluster = Lambda(lambda x: x[:, :, 4])(cat_features)\n",
    "store_type = Lambda(lambda x: x[:, :, 5])(cat_features)\n",
    "\n",
    "print(cat_features)\n",
    "print(item_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_3/embedding_lookup/Identity:0\", shape=(?, 381, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "family_embed = Embedding(33, 8, input_length=timesteps+16)(item_family)\n",
    "class_embed = Embedding(337, 8, input_length=timesteps+16)(item_class)\n",
    "store_embed = Embedding(54, 8, input_length=timesteps+16)(store_nbr)\n",
    "cluster_embed = Embedding(17, 3, input_length=timesteps+16)(store_cluster)\n",
    "type_embed = Embedding(5, 2, input_length=timesteps+16)(store_type)\n",
    "\n",
    "print(family_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lambda_7/strided_slice:0\", shape=(?, 365, 29), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encode_slice = Lambda(lambda x: x[:, :timesteps, :])\n",
    "encode_features = concatenate([promo_in, yearAgo_in, quarterAgo_in, weekday_embed_encode,\n",
    "                               family_embed, Reshape((timesteps+16,1))(item_perish), store_embed, cluster_embed, type_embed], axis=2)\n",
    "encode_features = encode_slice(encode_features)\n",
    "print(encode_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
