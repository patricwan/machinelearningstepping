{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先 import 必要的模块\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#竞赛的评价指标为logloss\n",
    "from sklearn.metrics import log_loss  \n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "# path to where the data lies\n",
    "dpath = '../data/'\n",
    "train = pd.read_csv(dpath +\"Otto_train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of           id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0          1       1       0       0       0       0       0       0       0   \n",
       "1          2       0       0       0       0       0       0       0       1   \n",
       "2          3       0       0       0       0       0       0       0       1   \n",
       "3          4       1       0       0       1       6       1       5       0   \n",
       "4          5       0       0       0       0       0       0       0       0   \n",
       "5          6       2       1       0       0       7       0       0       0   \n",
       "6          7       2       0       0       0       0       0       0       2   \n",
       "7          8       0       0       0       0       0       0       0       0   \n",
       "8          9       0       0       0       0       0       0       0       4   \n",
       "9         10       0       0       0       0       0       0       1       0   \n",
       "10        11       0       1       1       2       0       0       2       1   \n",
       "11        12       0       1       2       1       0       0       0       0   \n",
       "12        13       1       0       1       0       0       0       0       1   \n",
       "13        14       0       0       0       1       0       0       0       2   \n",
       "14        15       0       0       0       0       0       0       0       0   \n",
       "15        16       0       0       0       2       0       0       0       1   \n",
       "16        17       0       0       0       0       0       0       0       0   \n",
       "17        18       0       0       0       0       0       0       0       0   \n",
       "18        19       0       0       0       0       0       0       0       1   \n",
       "19        20       0       0       0       0       0       0       0       0   \n",
       "20        21       0       0       2       0       0       0       0       0   \n",
       "21        22       0       0       0       0       0       0       0       0   \n",
       "22        23       0       0       0       0       0       0       0       4   \n",
       "23        24       0       0       0       0       1       0       0       1   \n",
       "24        25       0       0       0       0       0       0       0       1   \n",
       "25        26       0       0       0       0       0       0       0       3   \n",
       "26        27       2       0       0       0       0       0       0       4   \n",
       "27        28       0       0       0       0       0       0       0       1   \n",
       "28        29       0       0       0       0       3       0       0       0   \n",
       "29        30       2       0       0       0       0       0       4       1   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "61848  61849       0       0       0       0       0       0       0       2   \n",
       "61849  61850       5       0       1       1       0       0       1       1   \n",
       "61850  61851       0       0       1       0       0       0       0       6   \n",
       "61851  61852       3       0       0       0       0       0       0       0   \n",
       "61852  61853       0       0       0       0       0       0       0       6   \n",
       "61853  61854       0       0       0       0       0       0       0       0   \n",
       "61854  61855       0       0       1       0       0       0       0       0   \n",
       "61855  61856       0       0       0       0       0       0       0       0   \n",
       "61856  61857       0       0       1       0       0       0       1       3   \n",
       "61857  61858       0       0       0       0       0       0       0      12   \n",
       "61858  61859       4       1       0       0       0       0       0      14   \n",
       "61859  61860       0       0       0       0       1       0       0       2   \n",
       "61860  61861       0       0       0       0       0       0       0       3   \n",
       "61861  61862       0       0       0       0       0       0       0      12   \n",
       "61862  61863       2       0       0       0       0       0       0       1   \n",
       "61863  61864       0       0       0       0       1       0       0       4   \n",
       "61864  61865       0       0       0       0       0       0       0       1   \n",
       "61865  61866       0       0       0       0       0       0       0       2   \n",
       "61866  61867       0       0       0       0       0       0       0      15   \n",
       "61867  61868       0       0       0       0       0       0       0       0   \n",
       "61868  61869       0       0       0       0       0       0       0       2   \n",
       "61869  61870       0       0       0       0       0       0       0       2   \n",
       "61870  61871       1       0       1       0       1       0       0       0   \n",
       "61871  61872       0       0       0       0       0       0       1       1   \n",
       "61872  61873       0       0       0       0       0       0       0       0   \n",
       "61873  61874       1       0       0       1       1       0       0       0   \n",
       "61874  61875       4       0       0       0       0       0       0       0   \n",
       "61875  61876       0       0       0       0       0       0       0       3   \n",
       "61876  61877       1       0       0       0       0       0       0       0   \n",
       "61877  61878       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       feat_9  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "0           0  ...        1        0        0        0        0        0   \n",
       "1           0  ...        0        0        0        0        0        0   \n",
       "2           0  ...        0        0        0        0        0        0   \n",
       "3           0  ...        0        1        2        0        0        0   \n",
       "4           0  ...        1        0        0        0        0        1   \n",
       "5           0  ...        0        3        0        0        0        0   \n",
       "6           0  ...        1        1        0        0        0        0   \n",
       "7           0  ...        0        0        1        0        0        0   \n",
       "8           0  ...        0        2        0        0        0        0   \n",
       "9           0  ...        0        0        1        0        0        0   \n",
       "10          0  ...        0        0        1        0        1        0   \n",
       "11          0  ...        0        2        0        0        0        0   \n",
       "12          0  ...        0        2        0        5        0        0   \n",
       "13          0  ...        2        0        0        1        0        0   \n",
       "14          0  ...        0        0        2        0        0        0   \n",
       "15          0  ...        1        0        1        0        2        0   \n",
       "16          0  ...        0        2        0        0        0        0   \n",
       "17          0  ...        0        0        0        0        0        0   \n",
       "18          0  ...        0        0        3        1        0        0   \n",
       "19          0  ...        0        0        3        0        0        0   \n",
       "20          0  ...        0        0        2        0        0        0   \n",
       "21          0  ...        0        0        0        1        0        0   \n",
       "22          0  ...        0        0        0        0        0        0   \n",
       "23          1  ...        0        0        1        0        0        0   \n",
       "24          0  ...        0        0        0        0        0        0   \n",
       "25          0  ...        0        0        0        1        0        0   \n",
       "26          0  ...        0        0        0        0        1        0   \n",
       "27          0  ...        0        0        0        0        0        0   \n",
       "28          0  ...        0        2        0        0        0        0   \n",
       "29          0  ...        0        0        3        2        0        0   \n",
       "...       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "61848       0  ...        0        0        0        0        0        0   \n",
       "61849       0  ...        0        2        0        0        0        0   \n",
       "61850       0  ...        0        0        0        0        0        0   \n",
       "61851       0  ...        0        1        0        1        0        0   \n",
       "61852       0  ...        0        0        0        0        3        0   \n",
       "61853       0  ...        0        1        1        0        0        0   \n",
       "61854       0  ...        0        0        0        0        0        2   \n",
       "61855       0  ...        0        0        0        0        0        0   \n",
       "61856       0  ...        1        7        3        0        1        0   \n",
       "61857       0  ...        0        0        0        1        1        0   \n",
       "61858       0  ...        2        0        2        1        0        0   \n",
       "61859       0  ...        0        1        1        0        2        0   \n",
       "61860       0  ...        0        0        0        0        1        0   \n",
       "61861       0  ...        0        0        0        0        0        0   \n",
       "61862       3  ...        0        5        2        0        0        0   \n",
       "61863       0  ...        0        0        0        1        0        0   \n",
       "61864       0  ...        0        8        1        0        0        0   \n",
       "61865       0  ...        0        0        1        0        0        0   \n",
       "61866       3  ...        0        0        0        0        3        0   \n",
       "61867       0  ...        0        0        2        0        0        0   \n",
       "61868       0  ...        0        2        0        0        2        0   \n",
       "61869       0  ...        0        3        2        0        0        0   \n",
       "61870       0  ...        1        0        0        0        0        0   \n",
       "61871       0  ...        0        0        0        0        1        0   \n",
       "61872       0  ...        0        1        0        0        0        0   \n",
       "61873       0  ...        1        0        0        0        0        0   \n",
       "61874       0  ...        0        2        0        0        2        0   \n",
       "61875       1  ...        0        3        1        0        0        0   \n",
       "61876       0  ...        0        0        0        0        1        0   \n",
       "61877       0  ...        0        0        0        0        0        0   \n",
       "\n",
       "       feat_91  feat_92  feat_93   target  \n",
       "0            0        0        0  Class_1  \n",
       "1            0        0        0  Class_1  \n",
       "2            0        0        0  Class_1  \n",
       "3            0        0        0  Class_1  \n",
       "4            0        0        0  Class_1  \n",
       "5            2        0        0  Class_1  \n",
       "6            0        0        1  Class_1  \n",
       "7            0        0        0  Class_1  \n",
       "8            0        0        1  Class_1  \n",
       "9            1        0        0  Class_1  \n",
       "10           0        1        0  Class_1  \n",
       "11           0        1        0  Class_1  \n",
       "12           0        0        0  Class_1  \n",
       "13           0        0        0  Class_1  \n",
       "14           0        0        0  Class_1  \n",
       "15           0        0        0  Class_1  \n",
       "16           0        0        0  Class_1  \n",
       "17           0        0        0  Class_1  \n",
       "18           1        0        1  Class_1  \n",
       "19           0        0        0  Class_1  \n",
       "20           0        0        0  Class_1  \n",
       "21           2        0        0  Class_1  \n",
       "22           0        0        0  Class_1  \n",
       "23           0        0        0  Class_1  \n",
       "24           0        0        0  Class_1  \n",
       "25           0        0        0  Class_1  \n",
       "26           1        0        0  Class_1  \n",
       "27           1        1        0  Class_1  \n",
       "28           0        1        0  Class_1  \n",
       "29           0        0        1  Class_1  \n",
       "...        ...      ...      ...      ...  \n",
       "61848        4        0        0  Class_9  \n",
       "61849        0        5        0  Class_9  \n",
       "61850        0        0        0  Class_9  \n",
       "61851        0        7        0  Class_9  \n",
       "61852        0        0        0  Class_9  \n",
       "61853        0        0        0  Class_9  \n",
       "61854        0        0        0  Class_9  \n",
       "61855        0        0        0  Class_9  \n",
       "61856        0        1        0  Class_9  \n",
       "61857        1        0        0  Class_9  \n",
       "61858        1        0        0  Class_9  \n",
       "61859        0        3        0  Class_9  \n",
       "61860        0        0        0  Class_9  \n",
       "61861        0        0        0  Class_9  \n",
       "61862        0        0        0  Class_9  \n",
       "61863        0        1        0  Class_9  \n",
       "61864        0        0        0  Class_9  \n",
       "61865        0        0        0  Class_9  \n",
       "61866        0        0        0  Class_9  \n",
       "61867        0        0        0  Class_9  \n",
       "61868        0        1        0  Class_9  \n",
       "61869        0        1        0  Class_9  \n",
       "61870        0        2        0  Class_9  \n",
       "61871        0        0        0  Class_9  \n",
       "61872        0        0        0  Class_9  \n",
       "61873        0        2        0  Class_9  \n",
       "61874        0        1        0  Class_9  \n",
       "61875        0        0        0  Class_9  \n",
       "61876        3       10        0  Class_9  \n",
       "61877        0        2        0  Class_9  \n",
       "\n",
       "[61878 rows x 95 columns]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "       ...       feat_84       feat_85       feat_86       feat_87  \\\n",
       "count  ...  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean   ...      0.070752      0.532306      1.128576      0.393549   \n",
       "std    ...      1.151460      1.900438      2.681554      1.575455   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      1.000000      0.000000   \n",
       "max    ...     76.000000     55.000000     65.000000     67.000000   \n",
       "\n",
       "            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n",
       "std        2.115466      1.527385      4.597804      2.045646      0.982385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     61.000000    130.000000     52.000000     19.000000   \n",
       "\n",
       "            feat_93  \n",
       "count  61878.000000  \n",
       "mean       0.126135  \n",
       "std        1.201720  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       87.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 各属性的统计特性\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target 分布，看看各类样本分布是否均衡\n",
    "sns.countplot(train[\"target\"]);\n",
    "pyplot.xlabel('target');\n",
    "pyplot.ylabel('Number of occurrences');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  0,  0, ...,  3, 10,  0],\n",
       "       [ 0,  0,  0, ...,  0,  2,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将类别字符串变成数字\n",
    "# drop ids and get labels\n",
    "y_train = train[\"target\"]\n",
    "y_train = y_train.map(lambda s: s[6:])\n",
    "y_train = y_train.map(lambda s: int(s)-1)\n",
    "\n",
    "train = train.drop([\"id\", \"target\"], axis=1)\n",
    "X_train = np.array(train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40209324, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       ...,\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [ 0.40209324, -0.21010603, -0.30716546, ...,  1.33702606,\n",
       "         9.792457  , -0.10496314],\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "         1.64894093, -0.10496314]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化特征的标准化器\n",
    "ss_X = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征进行标准化处理\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [ 1.05769457,  9.37407441,  0.03357394, ...,  0.35933168,\n",
       "        -0.38693809, -0.10496314],\n",
       "       ...,\n",
       "       [-0.25350808, -0.21010603,  4.12244675, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [-0.25350808, -0.21010603,  3.10022855, ..., -0.12951551,\n",
       "         9.792457  , -0.10496314],\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练样本6w+，交叉验证太慢，用train_test_split估计模型性能\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_part, X_val, y_train_part, y_val = train_test_split(X_train, y_train, train_size = 0.8,random_state = 0)\n",
    "\n",
    "X_train_part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# default SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "SVC1 = LinearSVC().fit(X_train_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在校验集上测试，估计模型性能\n",
    "y_predict = SVC1.predict(X_val)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (SVC1, metrics.classification_report(y_val, y_predict)))\n",
    "print(\"1  Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性SVM正则参数调优\n",
    "\n",
    "线性SVM LinearSVC的需要调整正则超参数包括C（正则系数，一般在log域（取log后的值）均匀设置候选参数）和正则函数penalty（L2/L1）\n",
    "\n",
    "采用交叉验证，网格搜索步骤与Logistic回归正则参数处理类似，在此略。\n",
    "\n",
    "这里我们用校验集（X_val、y_val）来估计模型性能\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_grid_point_Linear(C, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    # 在训练集是那个利用SVC训练\n",
    "    SVC2 =  LinearSVC( C = C)\n",
    "    SVC2 = SVC2.fit(X_train, y_train)\n",
    "    \n",
    "    # 在校验集上返回accuracy\n",
    "    accuracy = SVC2.score(X_val, y_val)\n",
    "    \n",
    "    print(\"fit_grid_point_Linear accuracy: {}\".format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "C_s = np.logspace(-3, 3, 7)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份  \n",
    "#penalty_s = ['l1','l2']\n",
    "print(\"logspace C_s \", C_s)\n",
    "      \n",
    "accuracy_s = []\n",
    "for i, oneC in enumerate(C_s):\n",
    "#    for j, penalty in enumerate(penalty_s):\n",
    "    tmp = fit_grid_point_Linear(oneC, X_train, y_train, X_val, y_val)\n",
    "    accuracy_s.append(tmp)\n",
    "\n",
    "x_axis = np.log10(C_s)\n",
    "#for j, penalty in enumerate(penalty_s):\n",
    "pyplot.plot(x_axis, np.array(accuracy_s), 'b-')\n",
    "    \n",
    "pyplot.legend()\n",
    "pyplot.xlabel( 'log(C)' )                                                                                                      \n",
    "pyplot.ylabel( 'accuracy' )\n",
    "pyplot.savefig('SVM_Otto.png' )\n",
    "\n",
    "pyplot.show()\n",
    "print(\"Shown Correctly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF核SVM正则参数调优\n",
    "\n",
    "RBF核是SVM最常用的核函数（没有之一）。 RBF核SVM 的需要调整正则超参数包括C（正则系数，一般在log域（取log后的值）均匀设置候选参数）和核函数的宽度gamma C越小，决策边界越平滑； gamma越小，决策边界越平滑。\n",
    "\n",
    "采用交叉验证，网格搜索步骤与Logistic回归正则参数处理类似，在此略。\n",
    "\n",
    "这里我们用校验集（X_val、y_val）来估计模型性能\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_grid_point_RBF(C, gamma, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    # 在训练集是那个利用SVC训练\n",
    "    SVC3 =  SVC( C = C, kernel='rbf', gamma = gamma)\n",
    "    SVC3 = SVC3.fit(X_train, y_train)\n",
    "    \n",
    "    # 在校验集上返回accuracy\n",
    "    accuracy = SVC3.score(X_val, y_val)\n",
    "    \n",
    "    print(\"accuracy: {}\".format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "C_s = np.logspace(-2, 2, 5)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份 \n",
    "gamma_s = np.logspace(-2, 2, 5)  \n",
    "\n",
    "accuracy_s = []\n",
    "for i, oneC in enumerate(C_s):\n",
    "    for j, gamma in enumerate(gamma_s):\n",
    "        tmp = fit_grid_point_RBF(oneC, gamma, X_train, y_train, X_val, y_val)\n",
    "        accuracy_s.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述部分运行结果来看，gamma参数设置不合适（gamma越大，对应RBF核的sigma越小，决策边界更复杂，可能发生了过拟合） 所以调小gamma值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "C_s = np.logspace(-1, 2, 4)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份 \n",
    "gamma_s = np.logspace(-5, -2, 4)  \n",
    "\n",
    "accuracy_s = []\n",
    "for i, oneC in enumerate(C_s):\n",
    "    for j, gamma in enumerate(gamma_s):\n",
    "        tmp = fit_grid_point_RBF(oneC, gamma, X_train, y_train, X_val, y_val)\n",
    "        accuracy_s.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "C_s = np.logspace(-2, 2, 5)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份 \n",
    "gamma_s = np.logspace(-2, 2, 5)  \n",
    "\n",
    "accuracy_s = []\n",
    "for i, oneC in enumerate(C_s):\n",
    "    for j, gamma in enumerate(gamma_s):\n",
    "        tmp = fit_grid_point_RBF(oneC, gamma, X_train, y_train, X_val, y_val)\n",
    "        accuracy_s.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述部分运行结果来看，gamma参数设置不合适（gamma越大，对应RBF核的sigma越小，决策边界更复杂，可能发生了过拟合） 所以调小gamma值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "C_s = np.logspace(-1, 2, 4)# logspace(a,b,N)把10的a次方到10的b次方区间分成N份 \n",
    "gamma_s = np.logspace(-5, -2, 4)  \n",
    "\n",
    "accuracy_s = []\n",
    "for i, oneC in enumerate(C_s):\n",
    "    for j, gamma in enumerate(gamma_s):\n",
    "        tmp = fit_grid_point_RBF(oneC, gamma, X_train, y_train, X_val, y_val)\n",
    "        accuracy_s.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (4,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-52549b6bc574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_s1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_s1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' Test - log(gamma)'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (4,4)"
     ]
    }
   ],
   "source": [
    "accuracy_s1 =np.array(accuracy_s).reshape(len(C_s),len(gamma_s))\n",
    "x_axis = np.log10(C_s)\n",
    "for j, gamma in enumerate(gamma_s):\n",
    "    pyplot.plot(x_axis, np.array(accuracy_s1[:,j]), label = ' Test - log(gamma)' + str(np.log10(gamma)))\n",
    "\n",
    "pyplot.legend()\n",
    "pyplot.xlabel( 'log(C)' )                                                                                                      \n",
    "pyplot.ylabel( 'accuracy' )\n",
    "pyplot.savefig('RBF_SVM_Otto.png' )\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
