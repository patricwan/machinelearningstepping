{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 便利店销量预测\n",
    "这是[便利店销量预测比赛](https://www.kaggle.com/c/rossmann-store-sales)的一个简单尝试参考。<br>\n",
    "by [@寒小阳](http://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"page-name\">\n",
    "    Forecast sales using store, promotion, and competitor data\n",
    "</h1>\n",
    "\n",
    "\n",
    "<p>Rossmann operates over 3,000 drug stores in 7 European countries. Currently, <br />Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.</p>\n",
    "<p><span style=\"font-size: 1em; line-height: 1.5em;\">In their first Kaggle competition, Rossmann is challenging you to predict 6 weeks of daily sales for 1,115 stores located across Germany. Reliable sales forecasts enable store managers to create effective staff schedules that increase productivity and motivation. By helping Rossmann create a robust prediction model, you will help store managers stay focused on what’s most important to them: their customers and their teams! </span></p>\n",
    "<p><span style=\"font-size: 1em; line-height: 1.5em;\"> <img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/4594/media/rossmann_banner2.png\" alt=\"\" height=\"81\" width=\"640\" /><br /></span></p>\n",
    "<p><em><span style=\"font-size: 1em; line-height: 1.5em;\">If you are interested in joining Rossmann at their headquarters near Hanover, Germany, please contact Mr. Frank König (Frank.Koenig {at} rossmann.de) Rossmann is currently recruiting data scientists at <a href=\"http://www.rossmann.de/unternehmen/karriere/stellenboerse/stellenanzeigen~jid=3A5205E3-C4F9-4F5D-AA93-438D0B064D70~\">senior</a> and <a href=\"http://www.rossmann.de/unternehmen/karriere/stellenboerse/stellenanzeigen~jid=F5142F37-C823-4767-B7CF-21DE3B351D66~\">entry-level</a> positions.</span></em></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据\n",
    "<table id=\"data-files\" class=\"nicetable full roomy align-top border\">   \n",
    "<thead>\n",
    "    <tr>\n",
    "        <th colspan=\"2\">File Name</th> \n",
    "        <th>Available Formats</th>         \n",
    "    </tr> \n",
    "</thead>\n",
    "\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">sample_submission.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/sample_submission.csv.zip\" name=\"sample_submission.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (55.25 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">store.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/store.csv.zip\" name=\"store.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (8.33 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">test.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/test.csv.zip\" name=\"test.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (143.25 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">train.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/train.csv.zip\" name=\"train.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (5.66 mb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Files</h3>\n",
    "<ul>\n",
    "<li><strong>train.csv</strong> - historical data including Sales</li>\n",
    "<li><strong>test.csv</strong> - historical data excluding Sales</li>\n",
    "<li><strong>sample_submission.csv</strong> - a sample submission file in the correct format</li>\n",
    "<li><strong>store.csv</strong> - supplemental information about the stores</li>\n",
    "</ul>\n",
    "<h3>Data fields</h3>\n",
    "<p>Most of the fields are self-explanatory. The following are descriptions for those that aren't.</p>\n",
    "<ul>\n",
    "<li><strong>Id</strong> - an Id that represents a (Store, Date) duple within the test set</li>\n",
    "<li><strong>Store</strong> - a unique Id for each store</li>\n",
    "<li><strong>Sales</strong> - the turnover for any given day (this is what you are predicting)</li>\n",
    "<li><strong>Customers</strong> - the number of customers on a given day</li>\n",
    "<li><strong>Open</strong> - an indicator for whether the store was open: 0 = closed, 1 = open</li>\n",
    "<li><strong>StateHoliday</strong> - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None</li>\n",
    "<li><strong>SchoolHoliday</strong> - indicates if the (Store, Date) was affected by the closure of public schools</li>\n",
    "<li><strong>StoreType</strong> - differentiates between 4 different store models: a, b, c, d</li>\n",
    "<li><strong>Assortment</strong> - describes an assortment level: a = basic, b = extra, c = extended</li>\n",
    "<li><strong>CompetitionDistance</strong> - distance in meters to the nearest competitor store</li>\n",
    "<li><strong>CompetitionOpenSince[Month/Year]</strong> - gives the approximate year and month of the time the nearest competitor was opened</li>\n",
    "<li><strong>Promo</strong> - indicates whether a store is running a promo on that day</li>\n",
    "<li><strong>Promo2</strong> - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating</li>\n",
    "<li><strong>Promo2Since[Year/Week]</strong> - describes the year and calendar week when the store started participating in Promo2</li>\n",
    "<li><strong>PromoInterval</strong> - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy as sp\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import cross_validation\n",
    "from matplotlib import pylab as plt\n",
    "plot = True\n",
    "\n",
    "goal = 'Sales'\n",
    "myid = 'Id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一些变换和评判准则\n",
    "使用不同的loss function的时候要特别注意这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv('../data/store/store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0      1         c          a               1270.0                        9.0   \n",
       "1      2         a          a                570.0                       11.0   \n",
       "2      3         a          a              14130.0                       12.0   \n",
       "3      4         c          c                620.0                        9.0   \n",
       "4      5         a          a              29910.0                        4.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "1                    2007.0       1             13.0           2010.0   \n",
       "2                    2006.0       1             14.0           2011.0   \n",
       "3                    2009.0       0              NaN              NaN   \n",
       "4                    2015.0       0              NaN              NaN   \n",
       "\n",
       "     PromoInterval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  \n",
       "2  Jan,Apr,Jul,Oct  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/store/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1            0   \n",
       "1      2          5  2015-07-31   6064        625     1      1            0   \n",
       "2      3          5  2015-07-31   8314        821     1      1            0   \n",
       "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5  2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/store/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
       "0   1      1          4  2015-09-17   1.0      1            0              0\n",
       "1   2      3          4  2015-09-17   1.0      1            0              0\n",
       "2   3      7          4  2015-09-17   1.0      1            0              0\n",
       "3   4      8          4  2015-09-17   1.0      1            0              0\n",
       "4   5      9          4  2015-09-17   1.0      1            0              0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "        加载数据，设定数值型和非数值型数据\n",
    "    \"\"\"\n",
    "    store = pd.read_csv('../data/store/store.csv')\n",
    "    train_org = pd.read_csv('../data/store/train.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    test_org = pd.read_csv('../data/store/test.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    train = pd.merge(train_org,store, on='Store', how='left')\n",
    "    test = pd.merge(test_org,store, on='Store', how='left')\n",
    "    features = test.columns.tolist()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    features_numeric = test.select_dtypes(include=numerics).columns.tolist()\n",
    "    features_non_numeric = [f for f in features if f not in features_numeric]\n",
    "    return (train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据与特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(train,test,features,features_non_numeric):\n",
    "    \"\"\"\n",
    "        Feature engineering and selection.\n",
    "    \"\"\"\n",
    "    # # FEATURE ENGINEERING\n",
    "    train = train[train['Sales'] > 0]\n",
    "\n",
    "    for data in [train,test]:\n",
    "        # year month day\n",
    "        data['year'] = data.Date.apply(lambda x: x.split('-')[0])\n",
    "        data['year'] = data['year'].astype(float)\n",
    "        data['month'] = data.Date.apply(lambda x: x.split('-')[1])\n",
    "        data['month'] = data['month'].astype(float)\n",
    "        data['day'] = data.Date.apply(lambda x: x.split('-')[2])\n",
    "        data['day'] = data['day'].astype(float)\n",
    "\n",
    "        # promo interval \"Jan,Apr,Jul,Oct\"\n",
    "        data['promojan'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jan\" in x else 0)\n",
    "        data['promofeb'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Feb\" in x else 0)\n",
    "        data['promomar'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Mar\" in x else 0)\n",
    "        data['promoapr'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Apr\" in x else 0)\n",
    "        data['promomay'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"May\" in x else 0)\n",
    "        data['promojun'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jun\" in x else 0)\n",
    "        data['promojul'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jul\" in x else 0)\n",
    "        data['promoaug'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Aug\" in x else 0)\n",
    "        data['promosep'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Sep\" in x else 0)\n",
    "        data['promooct'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Oct\" in x else 0)\n",
    "        data['promonov'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Nov\" in x else 0)\n",
    "        data['promodec'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Dec\" in x else 0)\n",
    "\n",
    "    # # Features set.\n",
    "    noisy_features = [myid,'Date']\n",
    "    features = [c for c in features if c not in noisy_features]\n",
    "    features_non_numeric = [c for c in features_non_numeric if c not in noisy_features]\n",
    "    features.extend(['year','month','day'])\n",
    "    # Fill NA\n",
    "    class DataFrameImputer(TransformerMixin):\n",
    "        # http://stackoverflow.com/questions/25239958/impute-categorical-missing-values-in-scikit-learn\n",
    "        def __init__(self):\n",
    "            \"\"\"Impute missing values.\n",
    "            Columns of dtype object are imputed with the most frequent value\n",
    "            in column.\n",
    "            Columns of other types are imputed with mean of column.\n",
    "            \"\"\"\n",
    "        def fit(self, X, y=None):\n",
    "            self.fill = pd.Series([X[c].value_counts().index[0] # mode\n",
    "                if X[c].dtype == np.dtype('O') else X[c].mean() for c in X], # mean\n",
    "                index=X.columns)\n",
    "            return self\n",
    "        def transform(self, X, y=None):\n",
    "            return X.fillna(self.fill)\n",
    "    train = DataFrameImputer().fit_transform(train)\n",
    "    test = DataFrameImputer().fit_transform(test)\n",
    "    # Pre-processing non-numberic values\n",
    "    le = LabelEncoder()\n",
    "    for col in features_non_numeric:\n",
    "        le.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "    # LR和神经网络这种模型都对输入数据的幅度极度敏感，请先做归一化操作\n",
    "    scaler = StandardScaler()\n",
    "    for col in set(features) - set(features_non_numeric) - \\\n",
    "      set([]): # TODO: add what not to scale\n",
    "        #scaler.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = train[col] #scaler.transform(train[col])\n",
    "        test[col] = test[col] #scaler.transform(test[col])\n",
    "    return (train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_native(train,test,features,features_non_numeric):\n",
    "    depth = 13\n",
    "    eta = 0.01\n",
    "    ntrees = 8000\n",
    "    mcw = 3\n",
    "    params = {\"objective\": \"reg:linear\",\n",
    "              \"booster\": \"gbtree\",\n",
    "              \"eta\": eta,\n",
    "              \"max_depth\": depth,\n",
    "              \"min_child_weight\": mcw,\n",
    "              \"subsample\": 0.9,\n",
    "              \"colsample_bytree\": 0.7,\n",
    "              \"silent\": 1\n",
    "              }\n",
    "    print(\"Running with params: \" + str(params))\n",
    "    print(\"Running with ntrees: \" + str(ntrees))\n",
    "    print(\"Running with features: \" + str(features))\n",
    "\n",
    "    # Train model with local split\n",
    "    tsize = 0.05\n",
    "    X_train, X_test = cross_validation.train_test_split(train, test_size=tsize)\n",
    "    dtrain = xgb.DMatrix(X_train[features], np.log(X_train[goal] + 1))\n",
    "    dvalid = xgb.DMatrix(X_test[features], np.log(X_test[goal] + 1))\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    gbm = xgb.train(params, dtrain, ntrees, evals=watchlist, early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)\n",
    "    train_probs = gbm.predict(xgb.DMatrix(X_test[features]))\n",
    "    indices = train_probs < 0\n",
    "    train_probs[indices] = 0\n",
    "    error = rmspe(np.exp(train_probs) - 1, X_test[goal].values)\n",
    "    print(error)\n",
    "\n",
    "    # Predict and Export\n",
    "    test_probs = gbm.predict(xgb.DMatrix(test[features]))\n",
    "    indices = test_probs < 0\n",
    "    test_probs[indices] = 0\n",
    "    submission = pd.DataFrame({myid: test[myid], goal: np.exp(test_probs) - 1})\n",
    "    if not os.path.exists('result/'):\n",
    "        os.makedirs('result/')\n",
    "    submission.to_csv(\"./result/dat-xgb_d%s_eta%s_ntree%s_mcw%s_tsize%s.csv\" % (str(depth),str(eta),str(ntrees),str(mcw),str(tsize)) , index=False)\n",
    "    # Feature importance\n",
    "    if plot:\n",
    "      outfile = open('xgb.fmap', 'w')\n",
    "      i = 0\n",
    "      for feat in features:\n",
    "          outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "          i = i + 1\n",
    "      outfile.close()\n",
    "      importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "      importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "      df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "      df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "      # Plotitup\n",
    "      plt.figure()\n",
    "      df.plot()\n",
    "      df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(25, 15))\n",
    "      plt.title('XGBoost Feature Importance')\n",
    "      plt.xlabel('relative importance')\n",
    "      plt.gcf().savefig('Feature_Importance_xgb_d%s_eta%s_ntree%s_mcw%s_tsize%s.png' % (str(depth),str(eta),str(ntrees),str(mcw),str(tsize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 载入数据中...\n",
      "=> 处理数据与特征工程...\n",
      "=> 使用XGBoost建模...\n",
      "Running with params: {'objective': 'reg:linear', 'booster': 'gbtree', 'eta': 0.01, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9, 'colsample_bytree': 0.7, 'silent': 1}\n",
      "Running with ntrees: 8000\n",
      "Running with features: ['Store', 'DayOfWeek', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'year', 'month', 'day']\n",
      "[0]\teval-rmse:8.18518\ttrain-rmse:8.18621\teval-rmspe:0.999864\ttrain-rmspe:0.999864\n",
      "Multiple eval metrics have been passed: 'train-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmspe hasn't improved in 100 rounds.\n",
      "[1]\teval-rmse:8.10349\ttrain-rmse:8.10452\teval-rmspe:0.999838\ttrain-rmspe:0.999838\n",
      "[2]\teval-rmse:8.02262\ttrain-rmse:8.02365\teval-rmspe:0.99981\ttrain-rmspe:0.99981\n",
      "[3]\teval-rmse:7.94255\ttrain-rmse:7.94357\teval-rmspe:0.999779\ttrain-rmspe:0.99978\n",
      "[4]\teval-rmse:7.86328\ttrain-rmse:7.8643\teval-rmspe:0.999747\ttrain-rmspe:0.999747\n",
      "[5]\teval-rmse:7.78479\ttrain-rmse:7.78579\teval-rmspe:0.999713\ttrain-rmspe:0.999713\n",
      "[6]\teval-rmse:7.70708\ttrain-rmse:7.70808\teval-rmspe:0.999676\ttrain-rmspe:0.999676\n",
      "[7]\teval-rmse:7.63016\ttrain-rmse:7.63114\teval-rmspe:0.999637\ttrain-rmspe:0.999637\n",
      "[8]\teval-rmse:7.55402\ttrain-rmse:7.55499\teval-rmspe:0.999595\ttrain-rmspe:0.999595\n",
      "[9]\teval-rmse:7.47865\ttrain-rmse:7.47961\teval-rmspe:0.99955\ttrain-rmspe:0.99955\n",
      "[10]\teval-rmse:7.40401\ttrain-rmse:7.40498\teval-rmspe:0.999502\ttrain-rmspe:0.999502\n",
      "[11]\teval-rmse:7.33013\ttrain-rmse:7.33111\teval-rmspe:0.999451\ttrain-rmspe:0.999451\n",
      "[12]\teval-rmse:7.25699\ttrain-rmse:7.25798\teval-rmspe:0.999397\ttrain-rmspe:0.999397\n",
      "[13]\teval-rmse:7.18456\ttrain-rmse:7.18555\teval-rmspe:0.999339\ttrain-rmspe:0.999339\n",
      "[14]\teval-rmse:7.11287\ttrain-rmse:7.11385\teval-rmspe:0.999278\ttrain-rmspe:0.999278\n",
      "[15]\teval-rmse:7.04189\ttrain-rmse:7.04287\teval-rmspe:0.999213\ttrain-rmspe:0.999213\n",
      "[16]\teval-rmse:6.97162\ttrain-rmse:6.97259\teval-rmspe:0.999143\ttrain-rmspe:0.999144\n",
      "[17]\teval-rmse:6.90206\ttrain-rmse:6.90303\teval-rmspe:0.99907\ttrain-rmspe:0.99907\n",
      "[18]\teval-rmse:6.83319\ttrain-rmse:6.83415\teval-rmspe:0.998992\ttrain-rmspe:0.998993\n",
      "[19]\teval-rmse:6.76502\ttrain-rmse:6.76599\teval-rmspe:0.998909\ttrain-rmspe:0.99891\n",
      "[20]\teval-rmse:6.69754\ttrain-rmse:6.69851\teval-rmspe:0.998822\ttrain-rmspe:0.998822\n",
      "[21]\teval-rmse:6.63072\ttrain-rmse:6.63169\teval-rmspe:0.998729\ttrain-rmspe:0.99873\n",
      "[22]\teval-rmse:6.56457\ttrain-rmse:6.56553\teval-rmspe:0.998631\ttrain-rmspe:0.998632\n",
      "[23]\teval-rmse:6.49909\ttrain-rmse:6.50006\teval-rmspe:0.998528\ttrain-rmspe:0.998529\n",
      "[24]\teval-rmse:6.43429\ttrain-rmse:6.43525\teval-rmspe:0.998418\ttrain-rmspe:0.998419\n",
      "[25]\teval-rmse:6.37011\ttrain-rmse:6.37106\teval-rmspe:0.998303\ttrain-rmspe:0.998304\n",
      "[26]\teval-rmse:6.30661\ttrain-rmse:6.30755\teval-rmspe:0.998181\ttrain-rmspe:0.998182\n",
      "[27]\teval-rmse:6.24369\ttrain-rmse:6.24464\teval-rmspe:0.998053\ttrain-rmspe:0.998054\n",
      "[28]\teval-rmse:6.1814\ttrain-rmse:6.18236\teval-rmspe:0.997918\ttrain-rmspe:0.997919\n",
      "[29]\teval-rmse:6.11976\ttrain-rmse:6.12072\teval-rmspe:0.997776\ttrain-rmspe:0.997777\n",
      "[30]\teval-rmse:6.05876\ttrain-rmse:6.05969\teval-rmspe:0.997626\ttrain-rmspe:0.997627\n",
      "[31]\teval-rmse:5.99835\ttrain-rmse:5.99929\teval-rmspe:0.997468\ttrain-rmspe:0.99747\n",
      "[32]\teval-rmse:5.93852\ttrain-rmse:5.93947\teval-rmspe:0.997303\ttrain-rmspe:0.997305\n",
      "[33]\teval-rmse:5.87933\ttrain-rmse:5.88028\teval-rmspe:0.997129\ttrain-rmspe:0.997131\n",
      "[34]\teval-rmse:5.82071\ttrain-rmse:5.82165\teval-rmspe:0.996947\ttrain-rmspe:0.996949\n",
      "[35]\teval-rmse:5.76266\ttrain-rmse:5.76361\teval-rmspe:0.996756\ttrain-rmspe:0.996758\n",
      "[36]\teval-rmse:5.70523\ttrain-rmse:5.70617\teval-rmspe:0.996555\ttrain-rmspe:0.996557\n",
      "[37]\teval-rmse:5.64835\ttrain-rmse:5.64929\teval-rmspe:0.996345\ttrain-rmspe:0.996347\n",
      "[38]\teval-rmse:5.59204\ttrain-rmse:5.59298\teval-rmspe:0.996125\ttrain-rmspe:0.996128\n",
      "[39]\teval-rmse:5.53629\ttrain-rmse:5.53721\teval-rmspe:0.995895\ttrain-rmspe:0.995898\n",
      "[40]\teval-rmse:5.48108\ttrain-rmse:5.482\teval-rmspe:0.995656\ttrain-rmspe:0.995659\n",
      "[41]\teval-rmse:5.42647\ttrain-rmse:5.42737\teval-rmspe:0.995404\ttrain-rmspe:0.995407\n",
      "[42]\teval-rmse:5.3724\ttrain-rmse:5.37329\teval-rmspe:0.995141\ttrain-rmspe:0.995144\n",
      "[43]\teval-rmse:5.31884\ttrain-rmse:5.31973\teval-rmspe:0.994867\ttrain-rmspe:0.99487\n",
      "[44]\teval-rmse:5.26582\ttrain-rmse:5.26673\teval-rmspe:0.99458\ttrain-rmspe:0.994584\n",
      "[45]\teval-rmse:5.21334\ttrain-rmse:5.21425\teval-rmspe:0.994281\ttrain-rmspe:0.994285\n",
      "[46]\teval-rmse:5.16137\ttrain-rmse:5.16228\teval-rmspe:0.99397\ttrain-rmspe:0.993974\n",
      "[47]\teval-rmse:5.10994\ttrain-rmse:5.11086\teval-rmspe:0.993645\ttrain-rmspe:0.993649\n",
      "[48]\teval-rmse:5.05901\ttrain-rmse:5.05993\teval-rmspe:0.993307\ttrain-rmspe:0.993312\n",
      "[49]\teval-rmse:5.0086\ttrain-rmse:5.00951\teval-rmspe:0.992956\ttrain-rmspe:0.99296\n",
      "[50]\teval-rmse:4.95869\ttrain-rmse:4.95959\teval-rmspe:0.99259\ttrain-rmspe:0.992595\n",
      "[51]\teval-rmse:4.90927\ttrain-rmse:4.91016\teval-rmspe:0.992211\ttrain-rmspe:0.992216\n",
      "[52]\teval-rmse:4.86035\ttrain-rmse:4.86124\teval-rmspe:0.991815\ttrain-rmspe:0.991821\n",
      "[53]\teval-rmse:4.81191\ttrain-rmse:4.8128\teval-rmspe:0.991405\ttrain-rmspe:0.991411\n",
      "[54]\teval-rmse:4.76395\ttrain-rmse:4.76485\teval-rmspe:0.990979\ttrain-rmspe:0.990985\n",
      "[55]\teval-rmse:4.71652\ttrain-rmse:4.71741\teval-rmspe:0.990535\ttrain-rmspe:0.990541\n",
      "[56]\teval-rmse:4.66956\ttrain-rmse:4.67044\teval-rmspe:0.990074\ttrain-rmspe:0.990081\n",
      "[57]\teval-rmse:4.62306\ttrain-rmse:4.62394\teval-rmspe:0.989596\ttrain-rmspe:0.989604\n",
      "[58]\teval-rmse:4.57703\ttrain-rmse:4.57791\teval-rmspe:0.989101\ttrain-rmspe:0.989109\n",
      "[59]\teval-rmse:4.53144\ttrain-rmse:4.53231\teval-rmspe:0.988591\ttrain-rmspe:0.988599\n",
      "[60]\teval-rmse:4.48632\ttrain-rmse:4.48719\teval-rmspe:0.988061\ttrain-rmspe:0.98807\n",
      "[61]\teval-rmse:4.44166\ttrain-rmse:4.44253\teval-rmspe:0.987512\ttrain-rmspe:0.987521\n",
      "[62]\teval-rmse:4.39745\ttrain-rmse:4.39832\teval-rmspe:0.986943\ttrain-rmspe:0.986953\n",
      "[63]\teval-rmse:4.35368\ttrain-rmse:4.35455\teval-rmspe:0.986355\ttrain-rmspe:0.986366\n",
      "[64]\teval-rmse:4.31034\ttrain-rmse:4.3112\teval-rmspe:0.985748\ttrain-rmspe:0.98576\n",
      "[65]\teval-rmse:4.26744\ttrain-rmse:4.26831\teval-rmspe:0.98512\ttrain-rmspe:0.985132\n",
      "[66]\teval-rmse:4.22498\ttrain-rmse:4.22585\teval-rmspe:0.984471\ttrain-rmspe:0.984484\n",
      "[67]\teval-rmse:4.18292\ttrain-rmse:4.18378\teval-rmspe:0.983803\ttrain-rmspe:0.983817\n",
      "[68]\teval-rmse:4.14127\ttrain-rmse:4.14214\teval-rmspe:0.983115\ttrain-rmspe:0.983129\n",
      "[69]\teval-rmse:4.10003\ttrain-rmse:4.1009\teval-rmspe:0.982405\ttrain-rmspe:0.98242\n",
      "[70]\teval-rmse:4.05923\ttrain-rmse:4.06009\teval-rmspe:0.981673\ttrain-rmspe:0.981688\n",
      "[71]\teval-rmse:4.01885\ttrain-rmse:4.0197\teval-rmspe:0.980916\ttrain-rmspe:0.980933\n",
      "[72]\teval-rmse:3.97889\ttrain-rmse:3.97974\teval-rmspe:0.980135\ttrain-rmspe:0.980153\n",
      "[73]\teval-rmse:3.93931\ttrain-rmse:3.94016\teval-rmspe:0.979332\ttrain-rmspe:0.97935\n",
      "[74]\teval-rmse:3.90011\ttrain-rmse:3.90096\teval-rmspe:0.978508\ttrain-rmspe:0.978527\n",
      "[75]\teval-rmse:3.86135\ttrain-rmse:3.86219\teval-rmspe:0.977656\ttrain-rmspe:0.977676\n",
      "[76]\teval-rmse:3.82294\ttrain-rmse:3.82377\teval-rmspe:0.976783\ttrain-rmspe:0.976804\n",
      "[77]\teval-rmse:3.78491\ttrain-rmse:3.78573\teval-rmspe:0.975886\ttrain-rmspe:0.975909\n",
      "[78]\teval-rmse:3.74724\ttrain-rmse:3.74806\teval-rmspe:0.974966\ttrain-rmspe:0.974989\n",
      "[79]\teval-rmse:3.70998\ttrain-rmse:3.71079\teval-rmspe:0.974018\ttrain-rmspe:0.974043\n",
      "[80]\teval-rmse:3.67308\ttrain-rmse:3.67388\teval-rmspe:0.973046\ttrain-rmspe:0.973072\n",
      "[81]\teval-rmse:3.63653\ttrain-rmse:3.63735\teval-rmspe:0.972048\ttrain-rmspe:0.972075\n",
      "[82]\teval-rmse:3.60036\ttrain-rmse:3.60117\teval-rmspe:0.971024\ttrain-rmspe:0.971052\n",
      "[83]\teval-rmse:3.56457\ttrain-rmse:3.56537\teval-rmspe:0.969971\ttrain-rmspe:0.970001\n",
      "[84]\teval-rmse:3.52913\ttrain-rmse:3.52993\teval-rmspe:0.968893\ttrain-rmspe:0.968923\n",
      "[85]\teval-rmse:3.49407\ttrain-rmse:3.49485\teval-rmspe:0.967785\ttrain-rmspe:0.967817\n",
      "[86]\teval-rmse:3.45935\ttrain-rmse:3.46014\teval-rmspe:0.96665\ttrain-rmspe:0.966684\n",
      "[87]\teval-rmse:3.42496\ttrain-rmse:3.42576\teval-rmspe:0.965488\ttrain-rmspe:0.965524\n",
      "[88]\teval-rmse:3.39096\ttrain-rmse:3.39175\teval-rmspe:0.964294\ttrain-rmspe:0.964331\n",
      "[89]\teval-rmse:3.35725\ttrain-rmse:3.35803\teval-rmspe:0.96308\ttrain-rmspe:0.963118\n",
      "[90]\teval-rmse:3.3239\ttrain-rmse:3.32468\teval-rmspe:0.961831\ttrain-rmspe:0.961871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91]\teval-rmse:3.29091\ttrain-rmse:3.29169\teval-rmspe:0.960552\ttrain-rmspe:0.960594\n",
      "[92]\teval-rmse:3.25823\ttrain-rmse:3.259\teval-rmspe:0.959247\ttrain-rmspe:0.959291\n",
      "[93]\teval-rmse:3.2259\ttrain-rmse:3.22666\teval-rmspe:0.957909\ttrain-rmspe:0.957956\n",
      "[94]\teval-rmse:3.19384\ttrain-rmse:3.19461\teval-rmspe:0.956548\ttrain-rmspe:0.956597\n",
      "[95]\teval-rmse:3.16211\ttrain-rmse:3.16287\teval-rmspe:0.955161\ttrain-rmspe:0.955212\n",
      "[96]\teval-rmse:3.13074\ttrain-rmse:3.1315\teval-rmspe:0.953734\ttrain-rmspe:0.953787\n",
      "[97]\teval-rmse:3.09968\ttrain-rmse:3.10042\teval-rmspe:0.952281\ttrain-rmspe:0.952336\n",
      "[98]\teval-rmse:3.06893\ttrain-rmse:3.06966\teval-rmspe:0.950796\ttrain-rmspe:0.950854\n",
      "[99]\teval-rmse:3.03849\ttrain-rmse:3.03921\teval-rmspe:0.949281\ttrain-rmspe:0.949342\n",
      "[100]\teval-rmse:3.00834\ttrain-rmse:3.00907\teval-rmspe:0.947737\ttrain-rmspe:0.947801\n",
      "[101]\teval-rmse:2.9785\ttrain-rmse:2.97924\teval-rmspe:0.94616\ttrain-rmspe:0.946227\n",
      "[102]\teval-rmse:2.94896\ttrain-rmse:2.94968\teval-rmspe:0.944555\ttrain-rmspe:0.944625\n",
      "[103]\teval-rmse:2.91973\ttrain-rmse:2.92045\teval-rmspe:0.942915\ttrain-rmspe:0.942988\n",
      "[104]\teval-rmse:2.89076\ttrain-rmse:2.89147\teval-rmspe:0.941252\ttrain-rmspe:0.941328\n",
      "[105]\teval-rmse:2.86211\ttrain-rmse:2.86281\teval-rmspe:0.939553\ttrain-rmspe:0.939633\n",
      "[106]\teval-rmse:2.83374\ttrain-rmse:2.83445\teval-rmspe:0.937821\ttrain-rmspe:0.937905\n",
      "[107]\teval-rmse:2.80566\ttrain-rmse:2.80638\teval-rmspe:0.936055\ttrain-rmspe:0.936142\n",
      "[108]\teval-rmse:2.77785\ttrain-rmse:2.77856\teval-rmspe:0.934264\ttrain-rmspe:0.934355\n",
      "[109]\teval-rmse:2.75029\ttrain-rmse:2.75099\teval-rmspe:0.932449\ttrain-rmspe:0.932543\n",
      "[110]\teval-rmse:2.72306\ttrain-rmse:2.72376\teval-rmspe:0.93059\ttrain-rmspe:0.930688\n",
      "[111]\teval-rmse:2.69609\ttrain-rmse:2.69679\teval-rmspe:0.928702\ttrain-rmspe:0.928806\n",
      "[112]\teval-rmse:2.6694\ttrain-rmse:2.6701\teval-rmspe:0.926781\ttrain-rmspe:0.926888\n",
      "[113]\teval-rmse:2.64298\ttrain-rmse:2.64367\teval-rmspe:0.92483\ttrain-rmspe:0.924942\n",
      "[114]\teval-rmse:2.61681\ttrain-rmse:2.6175\teval-rmspe:0.922848\ttrain-rmspe:0.922965\n",
      "[115]\teval-rmse:2.59093\ttrain-rmse:2.5916\teval-rmspe:0.920835\ttrain-rmspe:0.920956\n",
      "[116]\teval-rmse:2.56529\ttrain-rmse:2.56596\teval-rmspe:0.91879\ttrain-rmspe:0.918917\n",
      "[117]\teval-rmse:2.53991\ttrain-rmse:2.54058\teval-rmspe:0.916714\ttrain-rmspe:0.916846\n",
      "[118]\teval-rmse:2.5148\ttrain-rmse:2.51546\teval-rmspe:0.914606\ttrain-rmspe:0.914743\n",
      "[119]\teval-rmse:2.48991\ttrain-rmse:2.49057\teval-rmspe:0.912474\ttrain-rmspe:0.912616\n",
      "[120]\teval-rmse:2.46526\ttrain-rmse:2.46592\teval-rmspe:0.910311\ttrain-rmspe:0.91046\n",
      "[121]\teval-rmse:2.44087\ttrain-rmse:2.44154\teval-rmspe:0.908114\ttrain-rmspe:0.90827\n",
      "[122]\teval-rmse:2.41671\ttrain-rmse:2.41737\teval-rmspe:0.905894\ttrain-rmspe:0.906055\n",
      "[123]\teval-rmse:2.39278\ttrain-rmse:2.39344\teval-rmspe:0.903643\ttrain-rmspe:0.903811\n",
      "[124]\teval-rmse:2.36913\ttrain-rmse:2.36979\teval-rmspe:0.901356\ttrain-rmspe:0.901529\n",
      "[125]\teval-rmse:2.34568\ttrain-rmse:2.34633\teval-rmspe:0.899048\ttrain-rmspe:0.899228\n",
      "[126]\teval-rmse:2.32252\ttrain-rmse:2.32317\teval-rmspe:0.896695\ttrain-rmspe:0.896882\n",
      "[127]\teval-rmse:2.2996\ttrain-rmse:2.30024\teval-rmspe:0.894308\ttrain-rmspe:0.894503\n",
      "[128]\teval-rmse:2.27691\ttrain-rmse:2.27755\teval-rmspe:0.891893\ttrain-rmspe:0.892095\n",
      "[129]\teval-rmse:2.25442\ttrain-rmse:2.25506\teval-rmspe:0.889457\ttrain-rmspe:0.889666\n",
      "[130]\teval-rmse:2.23218\ttrain-rmse:2.23281\teval-rmspe:0.886985\ttrain-rmspe:0.887203\n",
      "[131]\teval-rmse:2.21012\ttrain-rmse:2.21075\teval-rmspe:0.884496\ttrain-rmspe:0.884722\n",
      "[132]\teval-rmse:2.18833\ttrain-rmse:2.18896\teval-rmspe:0.881965\ttrain-rmspe:0.882199\n",
      "[133]\teval-rmse:2.16674\ttrain-rmse:2.16736\teval-rmspe:0.879413\ttrain-rmspe:0.879655\n",
      "[134]\teval-rmse:2.14537\ttrain-rmse:2.14597\teval-rmspe:0.876833\ttrain-rmspe:0.877084\n",
      "[135]\teval-rmse:2.12415\ttrain-rmse:2.12475\teval-rmspe:0.874234\ttrain-rmspe:0.874494\n",
      "[136]\teval-rmse:2.10321\ttrain-rmse:2.10381\teval-rmspe:0.871593\ttrain-rmspe:0.871864\n",
      "[137]\teval-rmse:2.08244\ttrain-rmse:2.08303\teval-rmspe:0.868934\ttrain-rmspe:0.869215\n",
      "[138]\teval-rmse:2.06194\ttrain-rmse:2.06253\teval-rmspe:0.866233\ttrain-rmspe:0.866524\n",
      "[139]\teval-rmse:2.04159\ttrain-rmse:2.04218\teval-rmspe:0.863519\ttrain-rmspe:0.863821\n",
      "[140]\teval-rmse:2.02147\ttrain-rmse:2.02205\teval-rmspe:0.860774\ttrain-rmspe:0.861087\n",
      "[141]\teval-rmse:2.00158\ttrain-rmse:2.00216\teval-rmspe:0.857996\ttrain-rmspe:0.858319\n",
      "[142]\teval-rmse:1.98184\ttrain-rmse:1.98241\teval-rmspe:0.855204\ttrain-rmspe:0.855539\n",
      "[143]\teval-rmse:1.96231\ttrain-rmse:1.96289\teval-rmspe:0.852378\ttrain-rmspe:0.852726\n",
      "[144]\teval-rmse:1.94302\ttrain-rmse:1.94359\teval-rmspe:0.849521\ttrain-rmspe:0.84988\n",
      "[145]\teval-rmse:1.9239\ttrain-rmse:1.92446\teval-rmspe:0.846645\ttrain-rmspe:0.847017\n",
      "[146]\teval-rmse:1.905\ttrain-rmse:1.90556\teval-rmspe:0.843735\ttrain-rmspe:0.844121\n",
      "[147]\teval-rmse:1.88622\ttrain-rmse:1.88678\teval-rmspe:0.840819\ttrain-rmspe:0.841218\n",
      "[148]\teval-rmse:1.86767\ttrain-rmse:1.86823\teval-rmspe:0.837867\ttrain-rmspe:0.838281\n",
      "[149]\teval-rmse:1.8493\ttrain-rmse:1.84986\teval-rmspe:0.834895\ttrain-rmspe:0.835324\n",
      "[150]\teval-rmse:1.83111\ttrain-rmse:1.83167\teval-rmspe:0.8319\ttrain-rmspe:0.832345\n",
      "[151]\teval-rmse:1.81308\ttrain-rmse:1.81365\teval-rmspe:0.828886\ttrain-rmspe:0.829347\n",
      "[152]\teval-rmse:1.79529\ttrain-rmse:1.79585\teval-rmspe:0.82584\ttrain-rmspe:0.826317\n",
      "[153]\teval-rmse:1.77764\ttrain-rmse:1.7782\teval-rmspe:0.822779\ttrain-rmspe:0.823273\n",
      "[154]\teval-rmse:1.76022\ttrain-rmse:1.76078\teval-rmspe:0.819682\ttrain-rmspe:0.820192\n",
      "[155]\teval-rmse:1.74297\ttrain-rmse:1.74352\teval-rmspe:0.816566\ttrain-rmspe:0.817092\n",
      "[156]\teval-rmse:1.72588\ttrain-rmse:1.72642\teval-rmspe:0.813437\ttrain-rmspe:0.813979\n",
      "[157]\teval-rmse:1.7089\ttrain-rmse:1.70945\teval-rmspe:0.810301\ttrain-rmspe:0.810861\n",
      "[158]\teval-rmse:1.69217\ttrain-rmse:1.69271\teval-rmspe:0.807127\ttrain-rmspe:0.807704\n",
      "[159]\teval-rmse:1.6756\ttrain-rmse:1.67613\teval-rmspe:0.803934\ttrain-rmspe:0.804528\n",
      "[160]\teval-rmse:1.65921\ttrain-rmse:1.65974\teval-rmspe:0.800715\ttrain-rmspe:0.801329\n",
      "[161]\teval-rmse:1.64296\ttrain-rmse:1.64349\teval-rmspe:0.797487\ttrain-rmspe:0.798121\n",
      "[162]\teval-rmse:1.62688\ttrain-rmse:1.62741\teval-rmspe:0.794237\ttrain-rmspe:0.79489\n",
      "[163]\teval-rmse:1.61097\ttrain-rmse:1.6115\teval-rmspe:0.790965\ttrain-rmspe:0.791642\n",
      "[164]\teval-rmse:1.59518\ttrain-rmse:1.59571\teval-rmspe:0.78769\ttrain-rmspe:0.788388\n",
      "[165]\teval-rmse:1.57957\ttrain-rmse:1.58011\teval-rmspe:0.784388\ttrain-rmspe:0.785108\n",
      "[166]\teval-rmse:1.56413\ttrain-rmse:1.56466\teval-rmspe:0.78107\ttrain-rmspe:0.781812\n",
      "[167]\teval-rmse:1.54887\ttrain-rmse:1.5494\teval-rmspe:0.777729\ttrain-rmspe:0.778493\n",
      "[168]\teval-rmse:1.53375\ttrain-rmse:1.53428\teval-rmspe:0.774375\ttrain-rmspe:0.775163\n",
      "[169]\teval-rmse:1.51877\ttrain-rmse:1.51931\teval-rmspe:0.771006\ttrain-rmspe:0.771822\n",
      "[170]\teval-rmse:1.50397\ttrain-rmse:1.5045\teval-rmspe:0.767625\ttrain-rmspe:0.768466\n",
      "[171]\teval-rmse:1.48932\ttrain-rmse:1.48985\teval-rmspe:0.764224\ttrain-rmspe:0.765092\n",
      "[172]\teval-rmse:1.4748\ttrain-rmse:1.47533\teval-rmspe:0.760817\ttrain-rmspe:0.76171\n",
      "[173]\teval-rmse:1.46041\ttrain-rmse:1.46093\teval-rmspe:0.7574\ttrain-rmspe:0.75832\n",
      "[174]\teval-rmse:1.44619\ttrain-rmse:1.44671\teval-rmspe:0.753963\ttrain-rmspe:0.754911\n",
      "[175]\teval-rmse:1.43207\ttrain-rmse:1.43258\teval-rmspe:0.750528\ttrain-rmspe:0.751502\n",
      "[176]\teval-rmse:1.4181\ttrain-rmse:1.41862\teval-rmspe:0.747077\ttrain-rmspe:0.74808\n",
      "[177]\teval-rmse:1.40432\ttrain-rmse:1.40483\teval-rmspe:0.743606\ttrain-rmspe:0.744637\n",
      "[178]\teval-rmse:1.39066\ttrain-rmse:1.39115\teval-rmspe:0.740127\ttrain-rmspe:0.741186\n",
      "[179]\teval-rmse:1.37713\ttrain-rmse:1.37764\teval-rmspe:0.736632\ttrain-rmspe:0.737723\n",
      "[180]\teval-rmse:1.36372\ttrain-rmse:1.36422\teval-rmspe:0.733133\ttrain-rmspe:0.734254\n",
      "[181]\teval-rmse:1.35047\ttrain-rmse:1.35097\teval-rmspe:0.729624\ttrain-rmspe:0.730774\n",
      "[182]\teval-rmse:1.33736\ttrain-rmse:1.33785\teval-rmspe:0.726106\ttrain-rmspe:0.727287\n",
      "[183]\teval-rmse:1.32439\ttrain-rmse:1.32488\teval-rmspe:0.722575\ttrain-rmspe:0.723788\n",
      "[184]\teval-rmse:1.31151\ttrain-rmse:1.312\teval-rmspe:0.71904\ttrain-rmspe:0.720289\n",
      "[185]\teval-rmse:1.29877\ttrain-rmse:1.29926\teval-rmspe:0.715497\ttrain-rmspe:0.716779\n",
      "[186]\teval-rmse:1.28618\ttrain-rmse:1.28667\teval-rmspe:0.711943\ttrain-rmspe:0.71326\n",
      "[187]\teval-rmse:1.27371\ttrain-rmse:1.2742\teval-rmspe:0.708388\ttrain-rmspe:0.709741\n",
      "[188]\teval-rmse:1.26133\ttrain-rmse:1.26182\teval-rmspe:0.70483\ttrain-rmspe:0.706219\n",
      "[189]\teval-rmse:1.2491\ttrain-rmse:1.24959\teval-rmspe:0.701267\ttrain-rmspe:0.702695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190]\teval-rmse:1.23704\ttrain-rmse:1.23752\teval-rmspe:0.697684\ttrain-rmspe:0.699146\n",
      "[191]\teval-rmse:1.22511\ttrain-rmse:1.22558\teval-rmspe:0.6941\ttrain-rmspe:0.695597\n",
      "[192]\teval-rmse:1.21324\ttrain-rmse:1.21371\teval-rmspe:0.690517\ttrain-rmspe:0.69205\n",
      "[193]\teval-rmse:1.20156\ttrain-rmse:1.20202\teval-rmspe:0.686922\ttrain-rmspe:0.688494\n",
      "[194]\teval-rmse:1.18995\ttrain-rmse:1.1904\teval-rmspe:0.683328\ttrain-rmspe:0.684938\n",
      "[195]\teval-rmse:1.17843\ttrain-rmse:1.17888\teval-rmspe:0.679738\ttrain-rmspe:0.681389\n",
      "[196]\teval-rmse:1.16705\ttrain-rmse:1.16749\teval-rmspe:0.676139\ttrain-rmspe:0.677832\n",
      "[197]\teval-rmse:1.15579\ttrain-rmse:1.15623\teval-rmspe:0.672537\ttrain-rmspe:0.674273\n",
      "[198]\teval-rmse:1.14469\ttrain-rmse:1.14513\teval-rmspe:0.668924\ttrain-rmspe:0.670703\n",
      "[199]\teval-rmse:1.13362\ttrain-rmse:1.13405\teval-rmspe:0.665328\ttrain-rmspe:0.667151\n",
      "[200]\teval-rmse:1.12271\ttrain-rmse:1.12314\teval-rmspe:0.661718\ttrain-rmspe:0.663585\n",
      "[201]\teval-rmse:1.11191\ttrain-rmse:1.11234\teval-rmspe:0.65811\ttrain-rmspe:0.660026\n",
      "[202]\teval-rmse:1.10122\ttrain-rmse:1.10164\teval-rmspe:0.654507\ttrain-rmspe:0.65647\n",
      "[203]\teval-rmse:1.09065\ttrain-rmse:1.09106\teval-rmspe:0.650899\ttrain-rmspe:0.652913\n",
      "[204]\teval-rmse:1.08022\ttrain-rmse:1.08063\teval-rmspe:0.647284\ttrain-rmspe:0.649347\n",
      "[205]\teval-rmse:1.06987\ttrain-rmse:1.07027\teval-rmspe:0.643675\ttrain-rmspe:0.645785\n",
      "[206]\teval-rmse:1.05957\ttrain-rmse:1.05997\teval-rmspe:0.640078\ttrain-rmspe:0.642238\n",
      "[207]\teval-rmse:1.0494\ttrain-rmse:1.0498\teval-rmspe:0.636477\ttrain-rmspe:0.638686\n",
      "[208]\teval-rmse:1.03931\ttrain-rmse:1.03971\teval-rmspe:0.63288\ttrain-rmspe:0.635141\n",
      "[209]\teval-rmse:1.02934\ttrain-rmse:1.02973\teval-rmspe:0.629287\ttrain-rmspe:0.631597\n",
      "[210]\teval-rmse:1.01948\ttrain-rmse:1.01986\teval-rmspe:0.625695\ttrain-rmspe:0.628058\n",
      "[211]\teval-rmse:1.00976\ttrain-rmse:1.01015\teval-rmspe:0.622096\ttrain-rmspe:0.624509\n",
      "[212]\teval-rmse:1.00013\ttrain-rmse:1.00052\teval-rmspe:0.618504\ttrain-rmspe:0.620974\n",
      "[213]\teval-rmse:0.990632\ttrain-rmse:0.991015\teval-rmspe:0.614912\ttrain-rmspe:0.617438\n",
      "[214]\teval-rmse:0.98122\ttrain-rmse:0.981602\teval-rmspe:0.611328\ttrain-rmspe:0.613866\n",
      "[215]\teval-rmse:0.971846\ttrain-rmse:0.972218\teval-rmspe:0.607755\ttrain-rmspe:0.610348\n",
      "[216]\teval-rmse:0.962568\ttrain-rmse:0.96294\teval-rmspe:0.604186\ttrain-rmspe:0.606842\n",
      "[217]\teval-rmse:0.953404\ttrain-rmse:0.953768\teval-rmspe:0.600623\ttrain-rmspe:0.603331\n",
      "[218]\teval-rmse:0.944324\ttrain-rmse:0.944682\teval-rmspe:0.597066\ttrain-rmspe:0.599836\n",
      "[219]\teval-rmse:0.935334\ttrain-rmse:0.935686\teval-rmspe:0.593513\ttrain-rmspe:0.596341\n",
      "[220]\teval-rmse:0.926503\ttrain-rmse:0.92685\teval-rmspe:0.589965\ttrain-rmspe:0.592853\n",
      "[221]\teval-rmse:0.917718\ttrain-rmse:0.918054\teval-rmspe:0.586427\ttrain-rmspe:0.589375\n",
      "[222]\teval-rmse:0.909029\ttrain-rmse:0.909363\teval-rmspe:0.582895\ttrain-rmspe:0.585898\n",
      "[223]\teval-rmse:0.900406\ttrain-rmse:0.900737\teval-rmspe:0.579374\ttrain-rmspe:0.582446\n",
      "[224]\teval-rmse:0.891947\ttrain-rmse:0.892269\teval-rmspe:0.575858\ttrain-rmspe:0.578991\n",
      "[225]\teval-rmse:0.883482\ttrain-rmse:0.8838\teval-rmspe:0.572355\ttrain-rmspe:0.575558\n",
      "[226]\teval-rmse:0.875183\ttrain-rmse:0.875497\teval-rmspe:0.568854\ttrain-rmspe:0.572074\n",
      "[227]\teval-rmse:0.866952\ttrain-rmse:0.867258\teval-rmspe:0.565367\ttrain-rmspe:0.568649\n",
      "[228]\teval-rmse:0.858813\ttrain-rmse:0.85912\teval-rmspe:0.561884\ttrain-rmspe:0.565226\n",
      "[229]\teval-rmse:0.850735\ttrain-rmse:0.85104\teval-rmspe:0.558415\ttrain-rmspe:0.561831\n",
      "[230]\teval-rmse:0.84279\ttrain-rmse:0.843089\teval-rmspe:0.554955\ttrain-rmspe:0.55841\n",
      "[231]\teval-rmse:0.834932\ttrain-rmse:0.835223\teval-rmspe:0.551503\ttrain-rmspe:0.555002\n",
      "[232]\teval-rmse:0.827078\ttrain-rmse:0.827367\teval-rmspe:0.548064\ttrain-rmspe:0.551635\n",
      "[233]\teval-rmse:0.819311\ttrain-rmse:0.819605\teval-rmspe:0.544633\ttrain-rmspe:0.548283\n",
      "[234]\teval-rmse:0.811698\ttrain-rmse:0.811988\teval-rmspe:0.541213\ttrain-rmspe:0.544939\n",
      "[235]\teval-rmse:0.804143\ttrain-rmse:0.804432\teval-rmspe:0.537806\ttrain-rmspe:0.541604\n",
      "[236]\teval-rmse:0.796675\ttrain-rmse:0.79696\teval-rmspe:0.534409\ttrain-rmspe:0.53827\n",
      "[237]\teval-rmse:0.789213\ttrain-rmse:0.789496\teval-rmspe:0.531028\ttrain-rmspe:0.534956\n",
      "[238]\teval-rmse:0.781872\ttrain-rmse:0.782152\teval-rmspe:0.52766\ttrain-rmspe:0.531664\n",
      "[239]\teval-rmse:0.774638\ttrain-rmse:0.774906\teval-rmspe:0.524308\ttrain-rmspe:0.528365\n",
      "[240]\teval-rmse:0.767488\ttrain-rmse:0.767754\teval-rmspe:0.520965\ttrain-rmspe:0.525017\n",
      "[241]\teval-rmse:0.760394\ttrain-rmse:0.76065\teval-rmspe:0.517635\ttrain-rmspe:0.521746\n",
      "[242]\teval-rmse:0.753332\ttrain-rmse:0.753584\teval-rmspe:0.514317\ttrain-rmspe:0.518503\n",
      "[243]\teval-rmse:0.746317\ttrain-rmse:0.746563\teval-rmspe:0.51101\ttrain-rmspe:0.515279\n",
      "[244]\teval-rmse:0.739451\ttrain-rmse:0.739692\teval-rmspe:0.507719\ttrain-rmspe:0.512073\n",
      "[245]\teval-rmse:0.73262\ttrain-rmse:0.732861\teval-rmspe:0.504441\ttrain-rmspe:0.508872\n",
      "[246]\teval-rmse:0.725852\ttrain-rmse:0.72609\teval-rmspe:0.501176\ttrain-rmspe:0.505662\n",
      "[247]\teval-rmse:0.719203\ttrain-rmse:0.719435\teval-rmspe:0.497933\ttrain-rmspe:0.502494\n",
      "[248]\teval-rmse:0.712619\ttrain-rmse:0.712849\teval-rmspe:0.494703\ttrain-rmspe:0.49936\n",
      "[249]\teval-rmse:0.706116\ttrain-rmse:0.706336\teval-rmspe:0.491489\ttrain-rmspe:0.496147\n",
      "[250]\teval-rmse:0.699618\ttrain-rmse:0.699836\teval-rmspe:0.488284\ttrain-rmspe:0.49303\n",
      "[251]\teval-rmse:0.693202\ttrain-rmse:0.693411\teval-rmspe:0.4851\ttrain-rmspe:0.489932\n",
      "[252]\teval-rmse:0.686887\ttrain-rmse:0.687084\teval-rmspe:0.481934\ttrain-rmspe:0.486801\n",
      "[253]\teval-rmse:0.680663\ttrain-rmse:0.68085\teval-rmspe:0.478783\ttrain-rmspe:0.483713\n",
      "[254]\teval-rmse:0.674513\ttrain-rmse:0.674688\teval-rmspe:0.475651\ttrain-rmspe:0.480664\n",
      "[255]\teval-rmse:0.668362\ttrain-rmse:0.668538\teval-rmspe:0.472516\ttrain-rmspe:0.477629\n",
      "[256]\teval-rmse:0.662305\ttrain-rmse:0.662478\teval-rmspe:0.469409\ttrain-rmspe:0.474601\n",
      "[257]\teval-rmse:0.656337\ttrain-rmse:0.656503\teval-rmspe:0.466323\ttrain-rmspe:0.471514\n",
      "[258]\teval-rmse:0.650335\ttrain-rmse:0.650496\teval-rmspe:0.463241\ttrain-rmspe:0.468527\n",
      "[259]\teval-rmse:0.644487\ttrain-rmse:0.644636\teval-rmspe:0.46019\ttrain-rmspe:0.465565\n",
      "[260]\teval-rmse:0.638716\ttrain-rmse:0.638856\teval-rmspe:0.457157\ttrain-rmspe:0.462521\n",
      "[261]\teval-rmse:0.632938\ttrain-rmse:0.633072\teval-rmspe:0.45413\ttrain-rmspe:0.459584\n",
      "[262]\teval-rmse:0.627275\ttrain-rmse:0.627398\teval-rmspe:0.451132\ttrain-rmspe:0.456688\n",
      "[263]\teval-rmse:0.621614\ttrain-rmse:0.621729\teval-rmspe:0.448139\ttrain-rmspe:0.453784\n",
      "[264]\teval-rmse:0.616091\ttrain-rmse:0.616195\teval-rmspe:0.445175\ttrain-rmspe:0.450908\n",
      "[265]\teval-rmse:0.610621\ttrain-rmse:0.610711\teval-rmspe:0.44223\ttrain-rmspe:0.447952\n",
      "[266]\teval-rmse:0.605132\ttrain-rmse:0.605215\teval-rmspe:0.439285\ttrain-rmspe:0.445068\n",
      "[267]\teval-rmse:0.599733\ttrain-rmse:0.599813\teval-rmspe:0.436361\ttrain-rmspe:0.442251\n",
      "[268]\teval-rmse:0.594417\ttrain-rmse:0.594485\teval-rmspe:0.433464\ttrain-rmspe:0.439444\n",
      "[269]\teval-rmse:0.589146\ttrain-rmse:0.589209\teval-rmspe:0.430582\ttrain-rmspe:0.436656\n",
      "[270]\teval-rmse:0.583841\ttrain-rmse:0.583891\teval-rmspe:0.427697\ttrain-rmspe:0.433878\n",
      "[271]\teval-rmse:0.578633\ttrain-rmse:0.578684\teval-rmspe:0.424841\ttrain-rmspe:0.431129\n",
      "[272]\teval-rmse:0.573491\ttrain-rmse:0.57354\teval-rmspe:0.422007\ttrain-rmspe:0.428399\n",
      "[273]\teval-rmse:0.568487\ttrain-rmse:0.568527\teval-rmspe:0.419205\ttrain-rmspe:0.425632\n",
      "[274]\teval-rmse:0.563545\ttrain-rmse:0.563574\teval-rmspe:0.416427\ttrain-rmspe:0.422842\n",
      "[275]\teval-rmse:0.558592\ttrain-rmse:0.558619\teval-rmspe:0.413652\ttrain-rmspe:0.420173\n",
      "[276]\teval-rmse:0.553734\ttrain-rmse:0.553749\teval-rmspe:0.410905\ttrain-rmspe:0.417513\n",
      "[277]\teval-rmse:0.548944\ttrain-rmse:0.548944\teval-rmspe:0.408183\ttrain-rmspe:0.414818\n",
      "[278]\teval-rmse:0.544221\ttrain-rmse:0.544211\teval-rmspe:0.405479\ttrain-rmspe:0.412214\n",
      "[279]\teval-rmse:0.539402\ttrain-rmse:0.539376\teval-rmspe:0.40276\ttrain-rmspe:0.409592\n",
      "[280]\teval-rmse:0.534647\ttrain-rmse:0.534607\teval-rmspe:0.400059\ttrain-rmspe:0.406983\n",
      "[281]\teval-rmse:0.529981\ttrain-rmse:0.529926\teval-rmspe:0.397392\ttrain-rmspe:0.404423\n",
      "[282]\teval-rmse:0.525462\ttrain-rmse:0.525393\teval-rmspe:0.394764\ttrain-rmspe:0.401891\n",
      "[283]\teval-rmse:0.520753\ttrain-rmse:0.520682\teval-rmspe:0.392091\ttrain-rmspe:0.399333\n",
      "[284]\teval-rmse:0.516299\ttrain-rmse:0.516217\teval-rmspe:0.389496\ttrain-rmspe:0.396762\n",
      "[285]\teval-rmse:0.511879\ttrain-rmse:0.511787\teval-rmspe:0.386918\ttrain-rmspe:0.39428\n",
      "[286]\teval-rmse:0.507515\ttrain-rmse:0.507412\teval-rmspe:0.38436\ttrain-rmspe:0.391822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[287]\teval-rmse:0.503174\ttrain-rmse:0.503061\teval-rmspe:0.381809\ttrain-rmspe:0.389377\n",
      "[288]\teval-rmse:0.498866\ttrain-rmse:0.498744\teval-rmspe:0.37928\ttrain-rmspe:0.386954\n",
      "[289]\teval-rmse:0.494673\ttrain-rmse:0.494542\teval-rmspe:0.376787\ttrain-rmspe:0.384567\n",
      "[290]\teval-rmse:0.49055\ttrain-rmse:0.490404\teval-rmspe:0.374328\ttrain-rmspe:0.382211\n",
      "[291]\teval-rmse:0.486449\ttrain-rmse:0.486295\teval-rmspe:0.371879\ttrain-rmspe:0.37989\n",
      "[292]\teval-rmse:0.48237\ttrain-rmse:0.4822\teval-rmspe:0.369436\ttrain-rmspe:0.377417\n",
      "[293]\teval-rmse:0.478321\ttrain-rmse:0.47814\teval-rmspe:0.367012\ttrain-rmspe:0.375101\n",
      "[294]\teval-rmse:0.474333\ttrain-rmse:0.474137\teval-rmspe:0.36461\ttrain-rmspe:0.372792\n",
      "[295]\teval-rmse:0.470406\ttrain-rmse:0.470195\teval-rmspe:0.362235\ttrain-rmspe:0.370383\n",
      "[296]\teval-rmse:0.466398\ttrain-rmse:0.466178\teval-rmspe:0.359833\ttrain-rmspe:0.368091\n",
      "[297]\teval-rmse:0.462546\ttrain-rmse:0.462313\teval-rmspe:0.357492\ttrain-rmspe:0.365787\n",
      "[298]\teval-rmse:0.458773\ttrain-rmse:0.458521\teval-rmspe:0.355192\ttrain-rmspe:0.363458\n",
      "[299]\teval-rmse:0.455041\ttrain-rmse:0.454771\teval-rmspe:0.352914\ttrain-rmspe:0.361277\n",
      "[300]\teval-rmse:0.451164\ttrain-rmse:0.450884\teval-rmspe:0.350582\ttrain-rmspe:0.359059\n",
      "[301]\teval-rmse:0.447377\ttrain-rmse:0.447088\teval-rmspe:0.348277\ttrain-rmspe:0.356872\n",
      "[302]\teval-rmse:0.443741\ttrain-rmse:0.443441\teval-rmspe:0.346042\ttrain-rmspe:0.354742\n",
      "[303]\teval-rmse:0.44012\ttrain-rmse:0.439811\teval-rmspe:0.343813\ttrain-rmspe:0.352634\n",
      "[304]\teval-rmse:0.436526\ttrain-rmse:0.436209\teval-rmspe:0.341596\ttrain-rmspe:0.350479\n",
      "[305]\teval-rmse:0.433024\ttrain-rmse:0.432682\teval-rmspe:0.339427\ttrain-rmspe:0.348387\n",
      "[306]\teval-rmse:0.429595\ttrain-rmse:0.429234\teval-rmspe:0.337285\ttrain-rmspe:0.346265\n",
      "[307]\teval-rmse:0.426205\ttrain-rmse:0.42583\teval-rmspe:0.335161\ttrain-rmspe:0.344249\n",
      "[308]\teval-rmse:0.422799\ttrain-rmse:0.422413\teval-rmspe:0.333034\ttrain-rmspe:0.342235\n",
      "[309]\teval-rmse:0.419469\ttrain-rmse:0.419066\teval-rmspe:0.330951\ttrain-rmspe:0.340119\n",
      "[310]\teval-rmse:0.416173\ttrain-rmse:0.415756\teval-rmspe:0.32889\ttrain-rmspe:0.338169\n",
      "[311]\teval-rmse:0.412769\ttrain-rmse:0.412338\teval-rmspe:0.326777\ttrain-rmspe:0.336178\n",
      "[312]\teval-rmse:0.409512\ttrain-rmse:0.409073\teval-rmspe:0.324737\ttrain-rmspe:0.334251\n",
      "[313]\teval-rmse:0.406337\ttrain-rmse:0.405877\teval-rmspe:0.32274\ttrain-rmspe:0.332224\n",
      "[314]\teval-rmse:0.4032\ttrain-rmse:0.402725\teval-rmspe:0.32075\ttrain-rmspe:0.330357\n",
      "[315]\teval-rmse:0.400129\ttrain-rmse:0.399634\teval-rmspe:0.318804\ttrain-rmspe:0.328373\n",
      "[316]\teval-rmse:0.397038\ttrain-rmse:0.396527\teval-rmspe:0.316851\ttrain-rmspe:0.326489\n",
      "[317]\teval-rmse:0.393995\ttrain-rmse:0.393464\teval-rmspe:0.314922\ttrain-rmspe:0.324513\n",
      "[318]\teval-rmse:0.391001\ttrain-rmse:0.390445\teval-rmspe:0.313023\ttrain-rmspe:0.322704\n",
      "[319]\teval-rmse:0.388016\ttrain-rmse:0.387449\teval-rmspe:0.311124\ttrain-rmspe:0.320915\n",
      "[320]\teval-rmse:0.384992\ttrain-rmse:0.384415\teval-rmspe:0.309211\ttrain-rmspe:0.319095\n",
      "[321]\teval-rmse:0.382075\ttrain-rmse:0.381483\teval-rmspe:0.307359\ttrain-rmspe:0.317352\n",
      "[322]\teval-rmse:0.379202\ttrain-rmse:0.378598\teval-rmspe:0.305526\ttrain-rmspe:0.315637\n",
      "[323]\teval-rmse:0.376328\ttrain-rmse:0.375712\teval-rmspe:0.303687\ttrain-rmspe:0.313887\n",
      "[324]\teval-rmse:0.373521\ttrain-rmse:0.372876\teval-rmspe:0.301898\ttrain-rmspe:0.312143\n",
      "[325]\teval-rmse:0.370787\ttrain-rmse:0.370122\teval-rmspe:0.300145\ttrain-rmspe:0.310427\n",
      "[326]\teval-rmse:0.368052\ttrain-rmse:0.36737\teval-rmspe:0.298391\ttrain-rmspe:0.308623\n",
      "[327]\teval-rmse:0.365319\ttrain-rmse:0.364618\teval-rmspe:0.296645\ttrain-rmspe:0.306964\n",
      "[328]\teval-rmse:0.36261\ttrain-rmse:0.3619\teval-rmspe:0.294907\ttrain-rmspe:0.305344\n",
      "[329]\teval-rmse:0.359887\ttrain-rmse:0.35917\teval-rmspe:0.293156\ttrain-rmspe:0.303704\n",
      "[330]\teval-rmse:0.357146\ttrain-rmse:0.356416\teval-rmspe:0.291403\ttrain-rmspe:0.302066\n",
      "[331]\teval-rmse:0.354437\ttrain-rmse:0.353693\teval-rmspe:0.289668\ttrain-rmspe:0.300431\n",
      "[332]\teval-rmse:0.351867\ttrain-rmse:0.351103\teval-rmspe:0.288017\ttrain-rmspe:0.298877\n",
      "[333]\teval-rmse:0.349296\ttrain-rmse:0.348515\teval-rmspe:0.286357\ttrain-rmspe:0.297334\n",
      "[334]\teval-rmse:0.346703\ttrain-rmse:0.345913\teval-rmspe:0.284681\ttrain-rmspe:0.295795\n",
      "[335]\teval-rmse:0.344272\ttrain-rmse:0.343459\teval-rmspe:0.283107\ttrain-rmspe:0.294309\n",
      "[336]\teval-rmse:0.341878\ttrain-rmse:0.341044\teval-rmspe:0.281561\ttrain-rmspe:0.29269\n",
      "[337]\teval-rmse:0.339503\ttrain-rmse:0.338652\teval-rmspe:0.280024\ttrain-rmspe:0.291101\n",
      "[338]\teval-rmse:0.337147\ttrain-rmse:0.336274\teval-rmspe:0.278502\ttrain-rmspe:0.28952\n",
      "[339]\teval-rmse:0.334786\ttrain-rmse:0.333899\teval-rmspe:0.276969\ttrain-rmspe:0.288101\n",
      "[340]\teval-rmse:0.332489\ttrain-rmse:0.33158\teval-rmspe:0.275485\ttrain-rmspe:0.286533\n",
      "[341]\teval-rmse:0.330158\ttrain-rmse:0.329232\teval-rmspe:0.273976\ttrain-rmspe:0.285119\n",
      "[342]\teval-rmse:0.327844\ttrain-rmse:0.326909\teval-rmspe:0.272474\ttrain-rmspe:0.283742\n",
      "[343]\teval-rmse:0.325618\ttrain-rmse:0.324662\teval-rmspe:0.271026\ttrain-rmspe:0.282267\n",
      "[344]\teval-rmse:0.323462\ttrain-rmse:0.322485\teval-rmspe:0.269629\ttrain-rmspe:0.280953\n",
      "[345]\teval-rmse:0.321301\ttrain-rmse:0.3203\teval-rmspe:0.268209\ttrain-rmspe:0.279463\n",
      "[346]\teval-rmse:0.319004\ttrain-rmse:0.317991\teval-rmspe:0.266714\ttrain-rmspe:0.278076\n",
      "[347]\teval-rmse:0.316712\ttrain-rmse:0.315689\teval-rmspe:0.26522\ttrain-rmspe:0.276702\n",
      "[348]\teval-rmse:0.314606\ttrain-rmse:0.313562\teval-rmspe:0.263852\ttrain-rmspe:0.275183\n",
      "[349]\teval-rmse:0.312561\ttrain-rmse:0.311496\teval-rmspe:0.262518\ttrain-rmspe:0.273793\n",
      "[350]\teval-rmse:0.310453\ttrain-rmse:0.309372\teval-rmspe:0.261151\ttrain-rmspe:0.272535\n",
      "[351]\teval-rmse:0.308468\ttrain-rmse:0.307361\teval-rmspe:0.259866\ttrain-rmspe:0.271301\n",
      "[352]\teval-rmse:0.306431\ttrain-rmse:0.305318\teval-rmspe:0.258545\ttrain-rmspe:0.270091\n",
      "[353]\teval-rmse:0.304402\ttrain-rmse:0.303283\teval-rmspe:0.257225\ttrain-rmspe:0.268887\n",
      "[354]\teval-rmse:0.302498\ttrain-rmse:0.301357\teval-rmspe:0.255982\ttrain-rmspe:0.267726\n",
      "[355]\teval-rmse:0.300365\ttrain-rmse:0.299205\teval-rmspe:0.254593\ttrain-rmspe:0.26645\n",
      "[356]\teval-rmse:0.298511\ttrain-rmse:0.297323\teval-rmspe:0.253394\ttrain-rmspe:0.265332\n",
      "[357]\teval-rmse:0.296649\ttrain-rmse:0.295439\teval-rmspe:0.252191\ttrain-rmspe:0.264084\n",
      "[358]\teval-rmse:0.294856\ttrain-rmse:0.293624\teval-rmspe:0.251034\ttrain-rmspe:0.263003\n",
      "[359]\teval-rmse:0.293087\ttrain-rmse:0.291832\teval-rmspe:0.249893\ttrain-rmspe:0.261928\n",
      "[360]\teval-rmse:0.291294\ttrain-rmse:0.29002\teval-rmspe:0.248742\ttrain-rmspe:0.260871\n",
      "[361]\teval-rmse:0.289542\ttrain-rmse:0.288243\teval-rmspe:0.247602\ttrain-rmspe:0.25977\n",
      "[362]\teval-rmse:0.287772\ttrain-rmse:0.286456\teval-rmspe:0.246464\ttrain-rmspe:0.25856\n",
      "[363]\teval-rmse:0.286026\ttrain-rmse:0.284695\teval-rmspe:0.245335\ttrain-rmspe:0.257537\n",
      "[364]\teval-rmse:0.284326\ttrain-rmse:0.282979\teval-rmspe:0.24424\ttrain-rmspe:0.256456\n",
      "[365]\teval-rmse:0.28263\ttrain-rmse:0.281266\teval-rmspe:0.243146\ttrain-rmspe:0.255464\n",
      "[366]\teval-rmse:0.280883\ttrain-rmse:0.279507\teval-rmspe:0.242016\ttrain-rmspe:0.254433\n",
      "[367]\teval-rmse:0.279126\ttrain-rmse:0.277735\teval-rmspe:0.240876\ttrain-rmspe:0.253398\n",
      "[368]\teval-rmse:0.277526\ttrain-rmse:0.276116\teval-rmspe:0.239851\ttrain-rmspe:0.252325\n",
      "[369]\teval-rmse:0.275899\ttrain-rmse:0.274468\teval-rmspe:0.238804\ttrain-rmspe:0.251362\n",
      "[370]\teval-rmse:0.274312\ttrain-rmse:0.27287\teval-rmspe:0.237797\ttrain-rmspe:0.25045\n",
      "[371]\teval-rmse:0.272778\ttrain-rmse:0.271307\teval-rmspe:0.236827\ttrain-rmspe:0.249491\n",
      "[372]\teval-rmse:0.271204\ttrain-rmse:0.269713\teval-rmspe:0.235825\ttrain-rmspe:0.24843\n",
      "[373]\teval-rmse:0.269606\ttrain-rmse:0.268102\teval-rmspe:0.234783\ttrain-rmspe:0.247479\n",
      "[374]\teval-rmse:0.268069\ttrain-rmse:0.266539\teval-rmspe:0.233791\ttrain-rmspe:0.246572\n",
      "[375]\teval-rmse:0.266606\ttrain-rmse:0.26506\teval-rmspe:0.232866\ttrain-rmspe:0.24573\n",
      "[376]\teval-rmse:0.265131\ttrain-rmse:0.263569\teval-rmspe:0.231924\ttrain-rmspe:0.244878\n",
      "[377]\teval-rmse:0.263682\ttrain-rmse:0.262103\teval-rmspe:0.231007\ttrain-rmspe:0.244003\n",
      "[378]\teval-rmse:0.262307\ttrain-rmse:0.260697\teval-rmspe:0.230145\ttrain-rmspe:0.243116\n",
      "[379]\teval-rmse:0.260862\ttrain-rmse:0.259236\teval-rmspe:0.229216\ttrain-rmspe:0.242276\n",
      "[380]\teval-rmse:0.259519\ttrain-rmse:0.257867\teval-rmspe:0.228364\ttrain-rmspe:0.241443\n",
      "[381]\teval-rmse:0.258189\ttrain-rmse:0.256511\teval-rmspe:0.227538\ttrain-rmspe:0.24068\n",
      "[382]\teval-rmse:0.256775\ttrain-rmse:0.255087\teval-rmspe:0.226656\ttrain-rmspe:0.239875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[383]\teval-rmse:0.255496\ttrain-rmse:0.253787\teval-rmspe:0.225862\ttrain-rmspe:0.239143\n",
      "[384]\teval-rmse:0.254204\ttrain-rmse:0.252476\teval-rmspe:0.225056\ttrain-rmspe:0.238428\n",
      "[385]\teval-rmse:0.252853\ttrain-rmse:0.251111\teval-rmspe:0.224195\ttrain-rmspe:0.23765\n",
      "[386]\teval-rmse:0.251592\ttrain-rmse:0.249825\teval-rmspe:0.223403\ttrain-rmspe:0.236767\n",
      "[387]\teval-rmse:0.250244\ttrain-rmse:0.24846\teval-rmspe:0.222561\ttrain-rmspe:0.236008\n",
      "[388]\teval-rmse:0.249013\ttrain-rmse:0.247202\teval-rmspe:0.221796\ttrain-rmspe:0.235301\n",
      "[389]\teval-rmse:0.247744\ttrain-rmse:0.245922\teval-rmspe:0.221\ttrain-rmspe:0.234592\n",
      "[390]\teval-rmse:0.246529\ttrain-rmse:0.244688\teval-rmspe:0.220253\ttrain-rmspe:0.233919\n",
      "[391]\teval-rmse:0.245243\ttrain-rmse:0.243388\teval-rmspe:0.219448\ttrain-rmspe:0.23318\n",
      "[392]\teval-rmse:0.244068\ttrain-rmse:0.242199\teval-rmspe:0.21872\ttrain-rmspe:0.232549\n",
      "[393]\teval-rmse:0.242926\ttrain-rmse:0.241033\teval-rmspe:0.218025\ttrain-rmspe:0.231915\n",
      "[394]\teval-rmse:0.241814\ttrain-rmse:0.239894\teval-rmspe:0.217351\ttrain-rmspe:0.231297\n",
      "[395]\teval-rmse:0.240635\ttrain-rmse:0.238699\teval-rmspe:0.216626\ttrain-rmspe:0.230628\n",
      "[396]\teval-rmse:0.239459\ttrain-rmse:0.237499\teval-rmspe:0.215904\ttrain-rmspe:0.229947\n",
      "[397]\teval-rmse:0.238335\ttrain-rmse:0.236356\teval-rmspe:0.215219\ttrain-rmspe:0.229331\n",
      "[398]\teval-rmse:0.237125\ttrain-rmse:0.235143\teval-rmspe:0.214466\ttrain-rmspe:0.228651\n",
      "[399]\teval-rmse:0.236004\ttrain-rmse:0.234001\teval-rmspe:0.213785\ttrain-rmspe:0.22804\n",
      "[400]\teval-rmse:0.234948\ttrain-rmse:0.232922\teval-rmspe:0.213147\ttrain-rmspe:0.227429\n",
      "[401]\teval-rmse:0.233852\ttrain-rmse:0.231812\teval-rmspe:0.212475\ttrain-rmspe:0.226823\n",
      "[402]\teval-rmse:0.232731\ttrain-rmse:0.230676\teval-rmspe:0.211772\ttrain-rmspe:0.226191\n",
      "[403]\teval-rmse:0.231744\ttrain-rmse:0.229664\teval-rmspe:0.211189\ttrain-rmspe:0.225666\n",
      "[404]\teval-rmse:0.230671\ttrain-rmse:0.228576\teval-rmspe:0.210522\ttrain-rmspe:0.225077\n",
      "[405]\teval-rmse:0.229463\ttrain-rmse:0.227358\teval-rmspe:0.209745\ttrain-rmspe:0.224395\n",
      "[406]\teval-rmse:0.228317\ttrain-rmse:0.226204\teval-rmspe:0.209019\ttrain-rmspe:0.223771\n",
      "[407]\teval-rmse:0.227368\ttrain-rmse:0.225233\teval-rmspe:0.208466\ttrain-rmspe:0.22307\n",
      "[408]\teval-rmse:0.226324\ttrain-rmse:0.224178\teval-rmspe:0.207816\ttrain-rmspe:0.222501\n",
      "[409]\teval-rmse:0.225421\ttrain-rmse:0.22325\teval-rmspe:0.207277\ttrain-rmspe:0.221988\n",
      "[410]\teval-rmse:0.224492\ttrain-rmse:0.222296\teval-rmspe:0.206731\ttrain-rmspe:0.221482\n",
      "[411]\teval-rmse:0.223539\ttrain-rmse:0.221327\teval-rmspe:0.206172\ttrain-rmspe:0.220984\n",
      "[412]\teval-rmse:0.222572\ttrain-rmse:0.22034\teval-rmspe:0.205582\ttrain-rmspe:0.220334\n",
      "[413]\teval-rmse:0.221527\ttrain-rmse:0.219285\teval-rmspe:0.204917\ttrain-rmspe:0.219763\n",
      "[414]\teval-rmse:0.220705\ttrain-rmse:0.218435\teval-rmspe:0.204451\ttrain-rmspe:0.219142\n",
      "[415]\teval-rmse:0.219714\ttrain-rmse:0.21743\teval-rmspe:0.203819\ttrain-rmspe:0.218588\n",
      "[416]\teval-rmse:0.218761\ttrain-rmse:0.216461\teval-rmspe:0.203226\ttrain-rmspe:0.218075\n",
      "[417]\teval-rmse:0.217802\ttrain-rmse:0.215483\teval-rmspe:0.202649\ttrain-rmspe:0.217568\n",
      "[418]\teval-rmse:0.216842\ttrain-rmse:0.214516\teval-rmspe:0.202049\ttrain-rmspe:0.217057\n",
      "[419]\teval-rmse:0.215927\ttrain-rmse:0.213585\teval-rmspe:0.201454\ttrain-rmspe:0.216537\n",
      "[420]\teval-rmse:0.215152\ttrain-rmse:0.212785\teval-rmspe:0.201021\ttrain-rmspe:0.216147\n",
      "[421]\teval-rmse:0.214345\ttrain-rmse:0.211957\teval-rmspe:0.200556\ttrain-rmspe:0.215709\n",
      "[422]\teval-rmse:0.213568\ttrain-rmse:0.211154\teval-rmspe:0.200115\ttrain-rmspe:0.215322\n",
      "[423]\teval-rmse:0.212848\ttrain-rmse:0.210409\teval-rmspe:0.199708\ttrain-rmspe:0.214966\n",
      "[424]\teval-rmse:0.212065\ttrain-rmse:0.209608\teval-rmspe:0.199256\ttrain-rmspe:0.214548\n",
      "[425]\teval-rmse:0.211356\ttrain-rmse:0.208869\teval-rmspe:0.198871\ttrain-rmspe:0.214037\n",
      "[426]\teval-rmse:0.210632\ttrain-rmse:0.208123\teval-rmspe:0.198463\ttrain-rmspe:0.21365\n",
      "[427]\teval-rmse:0.209898\ttrain-rmse:0.207363\teval-rmspe:0.198059\ttrain-rmspe:0.21327\n",
      "[428]\teval-rmse:0.209108\ttrain-rmse:0.206547\teval-rmspe:0.197604\ttrain-rmspe:0.212797\n",
      "[429]\teval-rmse:0.2083\ttrain-rmse:0.205719\teval-rmspe:0.197113\ttrain-rmspe:0.212259\n",
      "[430]\teval-rmse:0.207552\ttrain-rmse:0.204961\teval-rmspe:0.196671\ttrain-rmspe:0.211889\n",
      "[431]\teval-rmse:0.206868\ttrain-rmse:0.204263\teval-rmspe:0.196304\ttrain-rmspe:0.211566\n",
      "[432]\teval-rmse:0.206068\ttrain-rmse:0.203442\teval-rmspe:0.195808\ttrain-rmspe:0.211114\n",
      "[433]\teval-rmse:0.205413\ttrain-rmse:0.202764\teval-rmspe:0.195453\ttrain-rmspe:0.210791\n",
      "[434]\teval-rmse:0.204754\ttrain-rmse:0.202081\teval-rmspe:0.195085\ttrain-rmspe:0.210488\n",
      "[435]\teval-rmse:0.204058\ttrain-rmse:0.201376\teval-rmspe:0.19468\ttrain-rmspe:0.210141\n",
      "[436]\teval-rmse:0.203403\ttrain-rmse:0.2007\teval-rmspe:0.194316\ttrain-rmspe:0.20982\n",
      "[437]\teval-rmse:0.202737\ttrain-rmse:0.200015\teval-rmspe:0.193934\ttrain-rmspe:0.20932\n",
      "[438]\teval-rmse:0.201976\ttrain-rmse:0.199235\teval-rmspe:0.193463\ttrain-rmspe:0.208908\n",
      "[439]\teval-rmse:0.201381\ttrain-rmse:0.19861\teval-rmspe:0.193147\ttrain-rmspe:0.208447\n",
      "[440]\teval-rmse:0.200783\ttrain-rmse:0.197995\teval-rmspe:0.19282\ttrain-rmspe:0.208156\n",
      "[441]\teval-rmse:0.200218\ttrain-rmse:0.197402\teval-rmspe:0.192522\ttrain-rmspe:0.207747\n",
      "[442]\teval-rmse:0.199678\ttrain-rmse:0.196838\teval-rmspe:0.192251\ttrain-rmspe:0.207496\n",
      "[443]\teval-rmse:0.199011\ttrain-rmse:0.196167\teval-rmspe:0.191853\ttrain-rmspe:0.207174\n",
      "[444]\teval-rmse:0.198387\ttrain-rmse:0.195527\teval-rmspe:0.191514\ttrain-rmspe:0.206876\n",
      "[445]\teval-rmse:0.197794\ttrain-rmse:0.194928\teval-rmspe:0.191193\ttrain-rmspe:0.206627\n",
      "[446]\teval-rmse:0.197241\ttrain-rmse:0.19435\teval-rmspe:0.190897\ttrain-rmspe:0.206307\n",
      "[447]\teval-rmse:0.196583\ttrain-rmse:0.19368\teval-rmspe:0.190514\ttrain-rmspe:0.205988\n",
      "[448]\teval-rmse:0.196079\ttrain-rmse:0.193145\teval-rmspe:0.190264\ttrain-rmspe:0.205684\n",
      "[449]\teval-rmse:0.195587\ttrain-rmse:0.192633\teval-rmspe:0.190026\ttrain-rmspe:0.205471\n",
      "[450]\teval-rmse:0.195067\ttrain-rmse:0.19209\teval-rmspe:0.189746\ttrain-rmspe:0.205235\n",
      "[451]\teval-rmse:0.194522\ttrain-rmse:0.19153\teval-rmspe:0.189452\ttrain-rmspe:0.204968\n",
      "[452]\teval-rmse:0.193945\ttrain-rmse:0.190937\teval-rmspe:0.189123\ttrain-rmspe:0.204688\n",
      "[453]\teval-rmse:0.193403\ttrain-rmse:0.190385\teval-rmspe:0.188818\ttrain-rmspe:0.204439\n",
      "[454]\teval-rmse:0.192774\ttrain-rmse:0.189751\teval-rmspe:0.188443\ttrain-rmspe:0.204132\n",
      "[455]\teval-rmse:0.192175\ttrain-rmse:0.189138\teval-rmspe:0.188088\ttrain-rmspe:0.203812\n",
      "[456]\teval-rmse:0.191739\ttrain-rmse:0.18868\teval-rmspe:0.187883\ttrain-rmspe:0.203604\n",
      "[457]\teval-rmse:0.191289\ttrain-rmse:0.188201\teval-rmspe:0.187635\ttrain-rmspe:0.203074\n",
      "[458]\teval-rmse:0.190845\ttrain-rmse:0.187733\teval-rmspe:0.187418\ttrain-rmspe:0.202687\n",
      "[459]\teval-rmse:0.190287\ttrain-rmse:0.187146\teval-rmspe:0.18709\ttrain-rmspe:0.202362\n",
      "[460]\teval-rmse:0.189848\ttrain-rmse:0.186688\teval-rmspe:0.186879\ttrain-rmspe:0.202137\n",
      "[461]\teval-rmse:0.189418\ttrain-rmse:0.186241\teval-rmspe:0.186682\ttrain-rmspe:0.201941\n",
      "[462]\teval-rmse:0.189009\ttrain-rmse:0.185807\teval-rmspe:0.186481\ttrain-rmspe:0.201751\n",
      "[463]\teval-rmse:0.188608\ttrain-rmse:0.185395\teval-rmspe:0.186298\ttrain-rmspe:0.2016\n",
      "[464]\teval-rmse:0.188127\ttrain-rmse:0.184902\teval-rmspe:0.186047\ttrain-rmspe:0.201382\n",
      "[465]\teval-rmse:0.18762\ttrain-rmse:0.184376\teval-rmspe:0.185767\ttrain-rmspe:0.201132\n",
      "[466]\teval-rmse:0.18716\ttrain-rmse:0.183893\teval-rmspe:0.185522\ttrain-rmspe:0.200914\n",
      "[467]\teval-rmse:0.18666\ttrain-rmse:0.183383\teval-rmspe:0.18525\ttrain-rmspe:0.200694\n",
      "[468]\teval-rmse:0.186195\ttrain-rmse:0.182905\teval-rmspe:0.184994\ttrain-rmspe:0.200478\n",
      "[469]\teval-rmse:0.185757\ttrain-rmse:0.182455\teval-rmspe:0.184766\ttrain-rmspe:0.200292\n",
      "[470]\teval-rmse:0.185358\ttrain-rmse:0.182041\teval-rmspe:0.184562\ttrain-rmspe:0.200116\n",
      "[471]\teval-rmse:0.184868\ttrain-rmse:0.181533\teval-rmspe:0.184262\ttrain-rmspe:0.199897\n",
      "[472]\teval-rmse:0.184502\ttrain-rmse:0.181139\teval-rmspe:0.184104\ttrain-rmspe:0.19972\n",
      "[473]\teval-rmse:0.183968\ttrain-rmse:0.180598\teval-rmspe:0.183789\ttrain-rmspe:0.199467\n",
      "[474]\teval-rmse:0.183534\ttrain-rmse:0.180144\teval-rmspe:0.183553\ttrain-rmspe:0.19912\n",
      "[475]\teval-rmse:0.183122\ttrain-rmse:0.179708\teval-rmspe:0.183341\ttrain-rmspe:0.198925\n",
      "[476]\teval-rmse:0.182717\ttrain-rmse:0.179292\teval-rmspe:0.183123\ttrain-rmspe:0.198632\n",
      "[477]\teval-rmse:0.182265\ttrain-rmse:0.178829\teval-rmspe:0.182863\ttrain-rmspe:0.19842\n",
      "[478]\teval-rmse:0.181832\ttrain-rmse:0.178374\teval-rmspe:0.182621\ttrain-rmspe:0.198206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[479]\teval-rmse:0.181466\ttrain-rmse:0.177996\teval-rmspe:0.182446\ttrain-rmspe:0.198059\n",
      "[480]\teval-rmse:0.181118\ttrain-rmse:0.177627\teval-rmspe:0.18229\ttrain-rmspe:0.197905\n",
      "[481]\teval-rmse:0.180443\ttrain-rmse:0.176935\teval-rmspe:0.181818\ttrain-rmspe:0.197487\n",
      "[482]\teval-rmse:0.180101\ttrain-rmse:0.176575\teval-rmspe:0.181658\ttrain-rmspe:0.197348\n",
      "[483]\teval-rmse:0.179754\ttrain-rmse:0.176208\teval-rmspe:0.181475\ttrain-rmspe:0.197181\n",
      "[484]\teval-rmse:0.179231\ttrain-rmse:0.175668\teval-rmspe:0.181144\ttrain-rmspe:0.196874\n",
      "[485]\teval-rmse:0.178754\ttrain-rmse:0.175185\teval-rmspe:0.180823\ttrain-rmspe:0.196607\n",
      "[486]\teval-rmse:0.178306\ttrain-rmse:0.174727\teval-rmspe:0.180554\ttrain-rmspe:0.196382\n",
      "[487]\teval-rmse:0.177859\ttrain-rmse:0.174271\teval-rmspe:0.180284\ttrain-rmspe:0.196147\n",
      "[488]\teval-rmse:0.177295\ttrain-rmse:0.173687\teval-rmspe:0.179894\ttrain-rmspe:0.195817\n",
      "[489]\teval-rmse:0.176985\ttrain-rmse:0.173362\teval-rmspe:0.179733\ttrain-rmspe:0.195693\n",
      "[490]\teval-rmse:0.176655\ttrain-rmse:0.173021\teval-rmspe:0.179566\ttrain-rmspe:0.195569\n",
      "[491]\teval-rmse:0.176061\ttrain-rmse:0.172421\teval-rmspe:0.179125\ttrain-rmspe:0.195197\n",
      "[492]\teval-rmse:0.175666\ttrain-rmse:0.17201\teval-rmspe:0.178896\ttrain-rmspe:0.194998\n",
      "[493]\teval-rmse:0.175362\ttrain-rmse:0.171686\teval-rmspe:0.178738\ttrain-rmspe:0.19487\n",
      "[494]\teval-rmse:0.175087\ttrain-rmse:0.171393\teval-rmspe:0.178619\ttrain-rmspe:0.194743\n",
      "[495]\teval-rmse:0.174728\ttrain-rmse:0.171023\teval-rmspe:0.17842\ttrain-rmspe:0.194582\n",
      "[496]\teval-rmse:0.174408\ttrain-rmse:0.170681\teval-rmspe:0.178258\ttrain-rmspe:0.194403\n",
      "[497]\teval-rmse:0.174082\ttrain-rmse:0.170342\teval-rmspe:0.178087\ttrain-rmspe:0.19427\n",
      "[498]\teval-rmse:0.173762\ttrain-rmse:0.170005\teval-rmspe:0.177906\ttrain-rmspe:0.193916\n",
      "[499]\teval-rmse:0.173501\ttrain-rmse:0.169728\teval-rmspe:0.177789\ttrain-rmspe:0.193804\n",
      "[500]\teval-rmse:0.173098\ttrain-rmse:0.169304\teval-rmspe:0.177533\ttrain-rmspe:0.193551\n",
      "[501]\teval-rmse:0.172664\ttrain-rmse:0.168859\teval-rmspe:0.177234\ttrain-rmspe:0.193313\n",
      "[502]\teval-rmse:0.172407\ttrain-rmse:0.168581\teval-rmspe:0.177124\ttrain-rmspe:0.193131\n",
      "[503]\teval-rmse:0.172107\ttrain-rmse:0.168273\teval-rmspe:0.17697\ttrain-rmspe:0.193008\n",
      "[504]\teval-rmse:0.171796\ttrain-rmse:0.167949\teval-rmspe:0.176809\ttrain-rmspe:0.192871\n",
      "[505]\teval-rmse:0.171464\ttrain-rmse:0.167595\teval-rmspe:0.176619\ttrain-rmspe:0.192667\n",
      "[506]\teval-rmse:0.17113\ttrain-rmse:0.167248\teval-rmspe:0.176418\ttrain-rmspe:0.192475\n",
      "[507]\teval-rmse:0.170803\ttrain-rmse:0.166899\teval-rmspe:0.176227\ttrain-rmspe:0.192295\n",
      "[508]\teval-rmse:0.170479\ttrain-rmse:0.16657\teval-rmspe:0.176047\ttrain-rmspe:0.192122\n",
      "[509]\teval-rmse:0.170068\ttrain-rmse:0.166149\teval-rmspe:0.175778\ttrain-rmspe:0.191881\n",
      "[510]\teval-rmse:0.169862\ttrain-rmse:0.165926\teval-rmspe:0.175707\ttrain-rmspe:0.191815\n",
      "[511]\teval-rmse:0.169556\ttrain-rmse:0.165603\teval-rmspe:0.175533\ttrain-rmspe:0.191639\n",
      "[512]\teval-rmse:0.1692\ttrain-rmse:0.165239\teval-rmspe:0.1753\ttrain-rmspe:0.191453\n",
      "[513]\teval-rmse:0.168971\ttrain-rmse:0.164998\teval-rmspe:0.17519\ttrain-rmspe:0.191367\n",
      "[514]\teval-rmse:0.168799\ttrain-rmse:0.164806\teval-rmspe:0.175146\ttrain-rmspe:0.191318\n",
      "[515]\teval-rmse:0.168442\ttrain-rmse:0.164433\teval-rmspe:0.174897\ttrain-rmspe:0.1911\n",
      "[516]\teval-rmse:0.168184\ttrain-rmse:0.164153\teval-rmspe:0.174756\ttrain-rmspe:0.190797\n",
      "[517]\teval-rmse:0.167773\ttrain-rmse:0.163734\teval-rmspe:0.174477\ttrain-rmspe:0.190572\n",
      "[518]\teval-rmse:0.167575\ttrain-rmse:0.16353\teval-rmspe:0.1744\ttrain-rmspe:0.190516\n",
      "[519]\teval-rmse:0.167284\ttrain-rmse:0.16323\teval-rmspe:0.174233\ttrain-rmspe:0.190386\n",
      "[520]\teval-rmse:0.167076\ttrain-rmse:0.163002\teval-rmspe:0.17415\ttrain-rmspe:0.190288\n",
      "[521]\teval-rmse:0.166771\ttrain-rmse:0.162696\teval-rmspe:0.173972\ttrain-rmspe:0.190139\n",
      "[522]\teval-rmse:0.16654\ttrain-rmse:0.162458\teval-rmspe:0.173857\ttrain-rmspe:0.190039\n",
      "[523]\teval-rmse:0.166184\ttrain-rmse:0.162087\teval-rmspe:0.173603\ttrain-rmspe:0.189767\n",
      "[524]\teval-rmse:0.165971\ttrain-rmse:0.161861\teval-rmspe:0.173498\ttrain-rmspe:0.189667\n",
      "[525]\teval-rmse:0.165749\ttrain-rmse:0.161637\teval-rmspe:0.173382\ttrain-rmspe:0.189588\n",
      "[526]\teval-rmse:0.165551\ttrain-rmse:0.161426\teval-rmspe:0.173292\ttrain-rmspe:0.189513\n",
      "[527]\teval-rmse:0.16539\ttrain-rmse:0.161243\teval-rmspe:0.173246\ttrain-rmspe:0.189464\n",
      "[528]\teval-rmse:0.165198\ttrain-rmse:0.161031\teval-rmspe:0.173153\ttrain-rmspe:0.189178\n",
      "[529]\teval-rmse:0.164853\ttrain-rmse:0.160679\teval-rmspe:0.172927\ttrain-rmspe:0.188994\n",
      "[530]\teval-rmse:0.16462\ttrain-rmse:0.16043\teval-rmspe:0.172803\ttrain-rmspe:0.188875\n",
      "[531]\teval-rmse:0.16443\ttrain-rmse:0.16023\teval-rmspe:0.172729\ttrain-rmspe:0.188814\n",
      "[532]\teval-rmse:0.164111\ttrain-rmse:0.159898\teval-rmspe:0.172505\ttrain-rmspe:0.188613\n",
      "[533]\teval-rmse:0.163941\ttrain-rmse:0.159722\teval-rmspe:0.172434\ttrain-rmspe:0.18856\n",
      "[534]\teval-rmse:0.163676\ttrain-rmse:0.159451\teval-rmspe:0.172276\ttrain-rmspe:0.188424\n",
      "[535]\teval-rmse:0.163496\ttrain-rmse:0.159247\teval-rmspe:0.172198\ttrain-rmspe:0.188314\n",
      "[536]\teval-rmse:0.163371\ttrain-rmse:0.159116\teval-rmspe:0.172177\ttrain-rmspe:0.188301\n",
      "[537]\teval-rmse:0.163214\ttrain-rmse:0.158941\teval-rmspe:0.172114\ttrain-rmspe:0.187978\n",
      "[538]\teval-rmse:0.162961\ttrain-rmse:0.158673\teval-rmspe:0.171956\ttrain-rmspe:0.187635\n",
      "[539]\teval-rmse:0.162817\ttrain-rmse:0.158511\teval-rmspe:0.171897\ttrain-rmspe:0.18757\n",
      "[540]\teval-rmse:0.162637\ttrain-rmse:0.158322\teval-rmspe:0.171819\ttrain-rmspe:0.1875\n",
      "[541]\teval-rmse:0.162381\ttrain-rmse:0.158062\teval-rmspe:0.171649\ttrain-rmspe:0.187346\n",
      "[542]\teval-rmse:0.162257\ttrain-rmse:0.157923\teval-rmspe:0.171621\ttrain-rmspe:0.187165\n",
      "[543]\teval-rmse:0.16199\ttrain-rmse:0.157646\teval-rmspe:0.171426\ttrain-rmspe:0.187023\n",
      "[544]\teval-rmse:0.16177\ttrain-rmse:0.157421\teval-rmspe:0.171289\ttrain-rmspe:0.186913\n",
      "[545]\teval-rmse:0.161558\ttrain-rmse:0.157198\teval-rmspe:0.171174\ttrain-rmspe:0.186755\n",
      "[546]\teval-rmse:0.161126\ttrain-rmse:0.156744\teval-rmspe:0.170852\ttrain-rmspe:0.186443\n",
      "[547]\teval-rmse:0.160855\ttrain-rmse:0.156474\teval-rmspe:0.17066\ttrain-rmspe:0.186271\n",
      "[548]\teval-rmse:0.160695\ttrain-rmse:0.156301\teval-rmspe:0.17059\ttrain-rmspe:0.186207\n",
      "[549]\teval-rmse:0.160331\ttrain-rmse:0.155928\teval-rmspe:0.17032\ttrain-rmspe:0.185969\n",
      "[550]\teval-rmse:0.160018\ttrain-rmse:0.155608\teval-rmspe:0.170109\ttrain-rmspe:0.185769\n",
      "[551]\teval-rmse:0.159721\ttrain-rmse:0.155298\teval-rmspe:0.169873\ttrain-rmspe:0.18556\n",
      "[552]\teval-rmse:0.159552\ttrain-rmse:0.155126\teval-rmspe:0.169795\ttrain-rmspe:0.185507\n",
      "[553]\teval-rmse:0.159385\ttrain-rmse:0.154945\teval-rmspe:0.169693\ttrain-rmspe:0.185384\n",
      "[554]\teval-rmse:0.159141\ttrain-rmse:0.154701\teval-rmspe:0.169545\ttrain-rmspe:0.185253\n",
      "[555]\teval-rmse:0.158957\ttrain-rmse:0.154505\teval-rmspe:0.169447\ttrain-rmspe:0.185127\n",
      "[556]\teval-rmse:0.158826\ttrain-rmse:0.154354\teval-rmspe:0.169401\ttrain-rmspe:0.185056\n",
      "[557]\teval-rmse:0.158613\ttrain-rmse:0.154132\teval-rmspe:0.169273\ttrain-rmspe:0.184942\n",
      "[558]\teval-rmse:0.15849\ttrain-rmse:0.153999\teval-rmspe:0.16923\ttrain-rmspe:0.184902\n",
      "[559]\teval-rmse:0.15832\ttrain-rmse:0.153812\teval-rmspe:0.169141\ttrain-rmspe:0.18481\n",
      "[560]\teval-rmse:0.158206\ttrain-rmse:0.15369\teval-rmspe:0.169103\ttrain-rmspe:0.184785\n",
      "[561]\teval-rmse:0.158011\ttrain-rmse:0.153492\teval-rmspe:0.168985\ttrain-rmspe:0.1847\n",
      "[562]\teval-rmse:0.157858\ttrain-rmse:0.153321\teval-rmspe:0.168913\ttrain-rmspe:0.184599\n",
      "[563]\teval-rmse:0.157713\ttrain-rmse:0.153161\teval-rmspe:0.168839\ttrain-rmspe:0.184495\n",
      "[564]\teval-rmse:0.157475\ttrain-rmse:0.152919\teval-rmspe:0.168666\ttrain-rmspe:0.184344\n",
      "[565]\teval-rmse:0.157312\ttrain-rmse:0.152748\teval-rmspe:0.168566\ttrain-rmspe:0.184223\n",
      "[566]\teval-rmse:0.157101\ttrain-rmse:0.152531\teval-rmspe:0.168413\ttrain-rmspe:0.184093\n",
      "[567]\teval-rmse:0.156983\ttrain-rmse:0.152401\teval-rmspe:0.168366\ttrain-rmspe:0.184046\n",
      "[568]\teval-rmse:0.156848\ttrain-rmse:0.152249\teval-rmspe:0.168299\ttrain-rmspe:0.183961\n",
      "[569]\teval-rmse:0.156712\ttrain-rmse:0.152106\teval-rmspe:0.168235\ttrain-rmspe:0.183908\n",
      "[570]\teval-rmse:0.156526\ttrain-rmse:0.151911\teval-rmspe:0.168134\ttrain-rmspe:0.183806\n",
      "[571]\teval-rmse:0.156407\ttrain-rmse:0.151789\teval-rmspe:0.168072\ttrain-rmspe:0.183764\n",
      "[572]\teval-rmse:0.156264\ttrain-rmse:0.151638\teval-rmspe:0.167992\ttrain-rmspe:0.183689\n",
      "[573]\teval-rmse:0.156066\ttrain-rmse:0.151438\teval-rmspe:0.167855\ttrain-rmspe:0.183578\n",
      "[574]\teval-rmse:0.155867\ttrain-rmse:0.15123\teval-rmspe:0.167712\ttrain-rmspe:0.183452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[575]\teval-rmse:0.155766\ttrain-rmse:0.151121\teval-rmspe:0.167679\ttrain-rmspe:0.1834\n",
      "[576]\teval-rmse:0.155578\ttrain-rmse:0.150921\teval-rmspe:0.167571\ttrain-rmspe:0.183267\n",
      "[577]\teval-rmse:0.155377\ttrain-rmse:0.150716\teval-rmspe:0.167444\ttrain-rmspe:0.183154\n",
      "[578]\teval-rmse:0.155254\ttrain-rmse:0.150586\teval-rmspe:0.167374\ttrain-rmspe:0.183\n",
      "[579]\teval-rmse:0.155143\ttrain-rmse:0.150463\teval-rmspe:0.167319\ttrain-rmspe:0.182902\n",
      "[580]\teval-rmse:0.154946\ttrain-rmse:0.150254\teval-rmspe:0.167172\ttrain-rmspe:0.182784\n",
      "[581]\teval-rmse:0.154715\ttrain-rmse:0.150015\teval-rmspe:0.166997\ttrain-rmspe:0.182421\n",
      "[582]\teval-rmse:0.154453\ttrain-rmse:0.149742\teval-rmspe:0.166804\ttrain-rmspe:0.182238\n",
      "[583]\teval-rmse:0.154342\ttrain-rmse:0.149622\teval-rmspe:0.166756\ttrain-rmspe:0.182187\n",
      "[584]\teval-rmse:0.154261\ttrain-rmse:0.149526\teval-rmspe:0.166725\ttrain-rmspe:0.182156\n",
      "[585]\teval-rmse:0.154163\ttrain-rmse:0.149417\teval-rmspe:0.166683\ttrain-rmspe:0.182121\n",
      "[586]\teval-rmse:0.154023\ttrain-rmse:0.149267\teval-rmspe:0.166596\ttrain-rmspe:0.182038\n",
      "[587]\teval-rmse:0.153931\ttrain-rmse:0.149169\teval-rmspe:0.166558\ttrain-rmspe:0.181836\n",
      "[588]\teval-rmse:0.153812\ttrain-rmse:0.149038\teval-rmspe:0.166502\ttrain-rmspe:0.181781\n",
      "[589]\teval-rmse:0.15368\ttrain-rmse:0.1489\teval-rmspe:0.166425\ttrain-rmspe:0.181684\n",
      "[590]\teval-rmse:0.153497\ttrain-rmse:0.148707\teval-rmspe:0.166311\ttrain-rmspe:0.181566\n",
      "[591]\teval-rmse:0.153341\ttrain-rmse:0.148545\teval-rmspe:0.166218\ttrain-rmspe:0.181298\n",
      "[592]\teval-rmse:0.153228\ttrain-rmse:0.148423\teval-rmspe:0.166137\ttrain-rmspe:0.181225\n",
      "[593]\teval-rmse:0.153116\ttrain-rmse:0.148299\teval-rmspe:0.166075\ttrain-rmspe:0.181163\n",
      "[594]\teval-rmse:0.153014\ttrain-rmse:0.148179\teval-rmspe:0.166026\ttrain-rmspe:0.181089\n",
      "[595]\teval-rmse:0.152892\ttrain-rmse:0.148052\teval-rmspe:0.165951\ttrain-rmspe:0.18101\n",
      "[596]\teval-rmse:0.152744\ttrain-rmse:0.1479\teval-rmspe:0.165859\ttrain-rmspe:0.180919\n",
      "[597]\teval-rmse:0.152614\ttrain-rmse:0.147762\teval-rmspe:0.165768\ttrain-rmspe:0.180841\n",
      "[598]\teval-rmse:0.152505\ttrain-rmse:0.147639\teval-rmspe:0.165699\ttrain-rmspe:0.180742\n",
      "[599]\teval-rmse:0.152316\ttrain-rmse:0.147438\teval-rmspe:0.16557\ttrain-rmspe:0.180629\n",
      "[600]\teval-rmse:0.152236\ttrain-rmse:0.147353\teval-rmspe:0.165537\ttrain-rmspe:0.180615\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-f34b9401a635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_non_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_non_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> 使用XGBoost建模...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mXGB_native\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_non_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-f622357982e4>\u001b[0m in \u001b[0;36mXGB_native\u001b[0;34m(train, test, features, features_non_numeric)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgoal\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrmspe_xg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_probs\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python36/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python36/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python36/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1045\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"=> 载入数据中...\")\n",
    "train,test,features,features_non_numeric = load_data()\n",
    "print(\"=> 处理数据与特征工程...\")\n",
    "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
    "print(\"=> 使用XGBoost建模...\")\n",
    "XGB_native(train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
