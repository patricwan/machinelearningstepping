# General Parameters, see comment for each definition
# choose the booster, can be gbtree or gblinear
booster = gbtree
# choose logistic regression loss function for binary classification
objective = binary:logistic

# Tree Booster Parameters
# step size shrinkage
eta = 0.3 
# minimum loss reduction required to make a further partition
gamma = 1.0 
# minimum sum of instance weight(hessian) needed in a child
min_child_weight = 1 
# maximum depth of a tree
max_depth = 6
# Maximum delta step we allow each tree's weight estimation to be.
# max_delta_step = 5
# subsample ratio of the training instance. 
#subsample = 0.5
# subsample ratio of columns when constructing each tree.
#colsample_bytree = 0.5

# Task Parameters
# the number of round to do boosting
num_round = 201
# 0 means do not save any model except the final round model
save_period = 10 
# The path of training data
# data = "cvr.train" 
# The path of validation data, used to monitor training process, here [test] sets name of the validation set
# eval[test] = "cvr.test"
eval_metric = "auc"
eval_metric = "map"
eval_metric = "rmse"
eval_metric = "logloss"
# evaluate on training data as well each round
eval_train = 1
# The path of test data 
# test:data = "cvr.test"
# Whether to create a binary buffer from text input. Doing so normally will speed up loading times
use_buffer = 0
