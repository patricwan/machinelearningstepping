{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wih  [[ 0.91091883  0.26716847  0.46100712  0.23920184]\n",
      " [ 0.40174993  0.49032743  0.60802533  0.66252232]\n",
      " [ 0.3877057   0.97102466  0.00521998  0.17621659]]\n"
     ]
    }
   ],
   "source": [
    "wih = np.random.rand(3, 4)\n",
    "print(\"wih \", wih)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network  [[{'weights': [0.40760475491443504, 0.5422075393626925, 0.20259945258895729, 0.001427447393968051]}, {'weights': [0.255958991871554, 0.8354290271798256, 0.27537204569612084, 0.1611306839641189]}, {'weights': [0.4140048945854735, 0.3275739627173835, 0.052306478064454764, 0.00692910788549117]}, {'weights': [0.07016596018616561, 0.10064982604457706, 0.6583023844554821, 0.4643003262060704]}], [{'weights': [0.7630521254988699, 0.6413872102021735, 0.754683132555904, 0.76301784303232, 0.7163220588145119]}, {'weights': [0.47959769966244326, 0.3570409490374943, 0.32196509520947514, 0.4961004217355921, 0.12461953845281959]}, {'weights': [0.4057771012018624, 0.47707821404025297, 0.7399458038395309, 0.7643301355281438, 0.31096925276604814]}, {'weights': [0.9835950811827853, 0.5035127686770803, 0.9671386239012435, 0.7018355368142125, 0.23953471350313826]}, {'weights': [0.6103298033524278, 0.7103409360123185, 0.9751089563870945, 0.9415913657842441, 0.329292284207936]}]]\n",
      "[[ 0.76440249  1.01623778  0.79140656  2.01323863  1.3789695 ]]\n",
      "(array([[ 0.76440249,  1.01623778,  0.79140656,  2.01323863,  1.3789695 ]]), array([[ 0.6823088 ,  0.73423912,  0.68813327,  0.88218006,  0.79882545]]), array([[ 1.95572045,  2.46796106,  0.98252804,  1.36694664,  3.04344892,\n",
      "         2.81557221]]), array([[ 0.87606906,  0.92186503,  0.72760955,  0.79688639,  0.95449885,\n",
      "         0.94351154]]))\n",
      "X_data  [[-1.        ]\n",
      " [-0.93103448]\n",
      " [-0.86206897]\n",
      " [-0.79310345]\n",
      " [-0.72413793]\n",
      " [-0.65517241]\n",
      " [-0.5862069 ]\n",
      " [-0.51724138]\n",
      " [-0.44827586]\n",
      " [-0.37931034]\n",
      " [-0.31034483]\n",
      " [-0.24137931]\n",
      " [-0.17241379]\n",
      " [-0.10344828]\n",
      " [-0.03448276]\n",
      " [ 0.03448276]\n",
      " [ 0.10344828]\n",
      " [ 0.17241379]\n",
      " [ 0.24137931]\n",
      " [ 0.31034483]\n",
      " [ 0.37931034]\n",
      " [ 0.44827586]\n",
      " [ 0.51724138]\n",
      " [ 0.5862069 ]\n",
      " [ 0.65517241]\n",
      " [ 0.72413793]\n",
      " [ 0.79310345]\n",
      " [ 0.86206897]\n",
      " [ 0.93103448]\n",
      " [ 1.        ]]\n",
      "y_data  [[-2.47172667]\n",
      " [-2.43026636]\n",
      " [-2.34026876]\n",
      " [-2.20998273]\n",
      " [-2.04748753]\n",
      " [-1.86053555]\n",
      " [-1.65642256]\n",
      " [-1.4418848 ]\n",
      " [-1.22302171]\n",
      " [-1.00524279]\n",
      " [-0.79323651]\n",
      " [-0.5909593 ]\n",
      " [-0.40164215]\n",
      " [-0.22781243]\n",
      " [-0.07132854]\n",
      " [ 0.06657513]\n",
      " [ 0.18523514]\n",
      " [ 0.28450019]\n",
      " [ 0.36466843]\n",
      " [ 0.42642298]\n",
      " [ 0.47076719]\n",
      " [ 0.49896111]\n",
      " [ 0.51246051]\n",
      " [ 0.51285937]\n",
      " [ 0.50183673]\n",
      " [ 0.48110852]\n",
      " [ 0.45238477]\n",
      " [ 0.41733244]\n",
      " [ 0.37754402]\n",
      " [ 0.33451183]]\n",
      "Step 500 error 26.658817\n",
      "Step 1000 error 26.658867\n",
      "Step 1500 error 26.658894\n",
      "Step 2000 error 26.658910\n",
      "Step 2500 error 26.658921\n",
      "Step 3000 error 26.658928\n",
      "Step 3500 error 26.658935\n",
      "Step 4000 error 26.658939\n",
      "Step 4500 error 26.658943\n",
      "Step 5000 error 26.658947\n",
      "Step 5500 error 26.658949\n",
      "Step 6000 error 26.658952\n",
      "Step 6500 error 26.658954\n",
      "Step 7000 error 26.658956\n",
      "Step 7500 error 26.658957\n",
      "Step 8000 error 26.658959\n",
      "Step 8500 error 26.658960\n",
      "Step 9000 error 26.658961\n",
      "Step 9500 error 26.658962\n",
      "Step 10000 error 26.658963\n",
      "Step 10500 error 26.658964\n",
      "Step 11000 error 26.658965\n",
      "Step 11500 error 26.658966\n",
      "Step 12000 error 26.658966\n",
      "Step 12500 error 26.658967\n",
      "Step 13000 error 26.658967\n",
      "Step 13500 error 26.658968\n",
      "Step 14000 error 26.658969\n",
      "Step 14500 error 26.658969\n",
      "Step 15000 error 26.658970\n",
      "Step 15500 error 26.658970\n",
      "Step 16000 error 26.658970\n",
      "Step 16500 error 26.658971\n",
      "Step 17000 error 26.658971\n",
      "Step 17500 error 26.658971\n",
      "Step 18000 error 26.658972\n",
      "Step 18500 error 26.658972\n",
      "Step 19000 error 26.658972\n",
      "Step 19500 error 26.658973\n",
      "Step 20000 error 26.658973\n",
      "Step 20500 error 26.658973\n",
      "Step 21000 error 26.658974\n",
      "Step 21500 error 26.658974\n",
      "Step 22000 error 26.658974\n",
      "Step 22500 error 26.658974\n",
      "Step 23000 error 26.658974\n",
      "Step 23500 error 26.658975\n",
      "Step 24000 error 26.658975\n",
      "Step 24500 error 26.658975\n",
      "Step 25000 error 26.658975\n",
      "Step 25500 error 26.658975\n",
      "Step 26000 error 26.658976\n",
      "Step 26500 error 26.658976\n",
      "Step 27000 error 26.658976\n",
      "Step 27500 error 26.658976\n",
      "Step 28000 error 26.658976\n",
      "Step 28500 error 26.658976\n",
      "Step 29000 error 26.658977\n",
      "Step 29500 error 26.658977\n",
      "Step 30000 error 26.658977\n",
      "Step 30500 error 26.658977\n",
      "Step 31000 error 26.658977\n",
      "Step 31500 error 26.658977\n",
      "Step 32000 error 26.658977\n",
      "Step 32500 error 26.658977\n",
      "Step 33000 error 26.658978\n",
      "Step 33500 error 26.658978\n",
      "Step 34000 error 26.658978\n",
      "Step 34500 error 26.658978\n",
      "Step 35000 error 26.658978\n",
      "Step 35500 error 26.658978\n",
      "Step 36000 error 26.658978\n",
      "Step 36500 error 26.658978\n",
      "Step 37000 error 26.658978\n",
      "Step 37500 error 26.658978\n",
      "Step 38000 error 26.658979\n",
      "Step 38500 error 26.658979\n",
      "Step 39000 error 26.658979\n",
      "Step 39500 error 26.658979\n",
      "Step 40000 error 26.658979\n",
      "Step 40500 error 26.658979\n",
      "Step 41000 error 26.658979\n",
      "Step 41500 error 26.658979\n",
      "Step 42000 error 26.658979\n",
      "Step 42500 error 26.658979\n",
      "Step 43000 error 26.658979\n",
      "Step 43500 error 26.658979\n",
      "Step 44000 error 26.658979\n",
      "Step 44500 error 26.658980\n",
      "Step 45000 error 26.658980\n",
      "Step 45500 error 26.658980\n",
      "Step 46000 error 26.658980\n",
      "Step 46500 error 26.658980\n",
      "Step 47000 error 26.658980\n",
      "Step 47500 error 26.658980\n",
      "Step 48000 error 26.658980\n",
      "Step 48500 error 26.658980\n",
      "Step 49000 error 26.658980\n",
      "Step 49500 error 26.658980\n",
      "Step 50000 error 26.658980\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "\n",
    "network = initialize_network(3,4,5)\n",
    "print(\"network \", network)\n",
    "\n",
    "def randomInitializeMatrix(row, column):\n",
    "    return np.random.rand(row, column)\n",
    "\n",
    "#Input an array, calculate sigmoid\n",
    "#np.array([1, 2, 3])  \n",
    "def sigmoid(inputArr):\n",
    "    return 1.0 / (1.0 + np.exp(-inputArr))\n",
    "\n",
    "#diff of sigmoid\n",
    "def diff_sigmoid(x):\n",
    "    fval = sigmoid(x)\n",
    "    return fval * (1 - fval)\n",
    "\n",
    "#print(sigmoid(8))\n",
    "#simpleArray = np.array([1, 2, 3]) \n",
    "#print(sigmoid(simpleArray))\n",
    "\n",
    "#firstOut = weight * data + bias\n",
    "def calcuateWBRes(weight, data, bias):\n",
    "    return  np.dot(data, weight)  + bias\n",
    "\n",
    "def forwardCalc(inputData, weight2, bias2, weight3, bias3):\n",
    "    hiddenIn = calcuateWBRes(weight2, inputData, bias2)\n",
    "    hiddenOut = sigmoid(hiddenIn)\n",
    "    \n",
    "    outIn = secondOut = calcuateWBRes(weight3,hiddenOut ,bias3)\n",
    "    outOut = sigmoid(outIn)\n",
    "    \n",
    "    return hiddenIn, hiddenOut, outIn, outOut\n",
    "\n",
    "def train(inputData, y_data, n_hidden, maxSteps, learningRate, inputNum):\n",
    "    n_input = inputData.shape[1]\n",
    "    n_output = y_data.shape[1]\n",
    "    \n",
    "    wih = np.random.rand(n_input, n_hidden)  # i*h\n",
    "    bih = np.random.rand(n_hidden)  # h\n",
    "        \n",
    "    who = np.random.rand(n_hidden, n_output)  # h*o\n",
    "    bho = np.random.rand(n_output)  # o\n",
    "    \n",
    "    # Initialize all deltas as zero.\n",
    "    delta_wih = np.zeros_like(wih)\n",
    "    delta_who = np.zeros_like(who)\n",
    "    delta_bih = np.zeros_like(bih)\n",
    "    delta_bho = np.zeros_like(bho)\n",
    "    \n",
    "    step = 0\n",
    "    while step < maxSteps:\n",
    "        step += 1\n",
    "        hiddenIn, hiddenOut, outIn, outOut = forwardCalc(inputData, wih, bih,who, bho)\n",
    "        errorC = np.sum(abs(outOut - y_data))\n",
    "        if (step % 500 ==0) :\n",
    "            print(\"Step %d error %f\" % (step,errorC))\n",
    "        \n",
    "        err_output = y_data - outOut            # n*oï¼Œ ouput layer, every cell's error\n",
    "        \n",
    "        #Formula 1 : calculate thetaOutLayer = deltaOut * diff(OutIn): \n",
    "        thetaOutlayer = -err_output * diff_sigmoid(outIn)\n",
    "        \n",
    "        #formula 3=> h to o, weight Delta from hidden to out layer\n",
    "        delta_who = learningRate * np.dot(hiddenOut.T, thetaOutlayer)\n",
    "        #formula 4 bias Delta\n",
    "        delta_bho = np.sum(learningRate * thetaOutlayer, axis=0) / inputNum\n",
    "        who -= delta_who\n",
    "        bho -= delta_bho\n",
    "        \n",
    "        #Formula2: calculate thetaHiddenLayer\n",
    "        thetaHiddenLayer = np.dot(thetaOutlayer, who.T) * diff_sigmoid(hiddenIn)\n",
    "        #Formula3: \n",
    "        delta_wih = learningRate * np.dot(inputData.T, thetaHiddenLayer)\n",
    "        delta_bih = np.sum(learningRate * thetaHiddenLayer, )\n",
    "        wih -= delta_wih\n",
    "        bih -= delta_bih\n",
    "    \n",
    "    return None\n",
    "\n",
    "testInputData = randomInitializeMatrix(4,1).T\n",
    "testWeights2 = randomInitializeMatrix(4,5)\n",
    "\n",
    "testBias2 = randomInitializeMatrix(1,5)\n",
    "\n",
    "firstRes= calcuateFirstRes(testWeights2, testInputData, testBias2)\n",
    "print(firstRes)\n",
    "\n",
    "testWeights3= randomInitializeMatrix(5,6)\n",
    "testBias3= randomInitializeMatrix(1,6)\n",
    "\n",
    "print(forwardCalc(testInputData,testWeights2,testBias2, testWeights3, testBias3))\n",
    "\n",
    "X_data = np.linspace(-1, 1, 30)\n",
    "X_data = np.transpose([X_data])\n",
    "y_data = np.exp(-X_data) * np.sin(2 * X_data)\n",
    "print(\"X_data \", X_data)\n",
    "print(\"y_data \", y_data)\n",
    "\n",
    "train(X_data, y_data, 3, 50000,0.2,30)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
