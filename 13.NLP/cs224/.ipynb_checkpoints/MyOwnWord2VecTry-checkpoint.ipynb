{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sample Matrix  [[-0.73999781  1.5097827   0.42724924  0.47239189  0.14242915]\n",
      " [-0.05197128  0.26032262 -0.68893622 -1.31929821  0.56058745]\n",
      " [ 0.40708553 -0.11049995  0.84741182  1.17568161 -0.3497789 ]\n",
      " [-0.62825102 -0.44822068 -0.43812542 -1.0488335   2.19182542]\n",
      " [-1.01141382  0.80935682 -0.95933124 -1.47236245 -0.92940679]\n",
      " [-0.38554662  0.87154693 -0.73522349  0.45451395 -0.03686511]\n",
      " [-0.8518525   0.52244339 -0.89284826  0.23310942  0.60865275]\n",
      " [ 0.09220161  0.06167303 -0.26012521 -0.60481862  1.66173033]\n",
      " [-1.13380177 -0.736506    0.38512413  1.06222358 -0.1714114 ]\n",
      " [ 2.45468834  0.15603602 -0.08819416 -1.58117221  0.81350953]\n",
      " [-0.25660641 -0.78759938  0.2515072  -0.42093123  0.95865426]\n",
      " [-1.3090383  -0.39294557  0.64528985  1.43916163 -0.62580705]\n",
      " [ 0.3093552   1.56392148  0.79318725  0.74632664 -0.02135193]\n",
      " [ 2.06123858 -0.81818813 -0.6989809  -0.00645059 -0.00528584]\n",
      " [-2.03386513  1.48590817  0.20430722  2.14627563 -0.63276194]\n",
      " [ 0.17372308 -1.64360002  0.92426708 -0.64837223  0.36508383]\n",
      " [-0.04824919 -0.33003312  0.39037336  0.12238058 -0.08682297]\n",
      " [ 1.33971866  0.04944091 -1.75749697 -1.33014571  1.42109742]\n",
      " [-0.09797787 -2.77941533  0.09342854 -2.52397542  0.60701185]\n",
      " [ 0.20911891 -0.67229674 -0.92529341 -0.34965324  0.67294763]]\n",
      "Sample Matrix After normalize  [[-0.41028618  0.83708759  0.23688511  0.26191411  0.07896877]\n",
      " [-0.03223179  0.16144809 -0.42726766 -0.81820848  0.34766773]\n",
      " [ 0.26273929 -0.07131838  0.54693268  0.75880308 -0.22575271]\n",
      " [-0.24286492 -0.17327004 -0.16936749 -0.40545078  0.84730068]\n",
      " [-0.42626082  0.34110381 -0.40431059 -0.62052784 -0.39169892]\n",
      " [-0.29953686  0.67711767 -0.57120598  0.3531186  -0.02864104]\n",
      " [-0.57165181  0.35059557 -0.5991628   0.15643251  0.408448  ]\n",
      " [ 0.051485    0.03443796 -0.14525284 -0.33772821  0.92790333]\n",
      " [-0.64045672 -0.41603412  0.21754715  0.60002396 -0.09682608]\n",
      " [ 0.80842944  0.05138905 -0.02904595 -0.52074479  0.26792202]\n",
      " [-0.18888469 -0.57974181  0.18513122 -0.30984209  0.70565311]\n",
      " [-0.60080462 -0.18034882  0.29616637  0.66052686 -0.28722442]\n",
      " [ 0.16021765  0.80996804  0.41079832  0.38652882 -0.01105834]\n",
      " [ 0.88645952 -0.35187128 -0.30060483 -0.00277415 -0.00227323]\n",
      " [-0.60255969  0.44022013  0.06052874  0.63586281 -0.18746417]\n",
      " [ 0.08538495 -0.80782992  0.45427756 -0.31867515  0.17943882]\n",
      " [-0.09019621 -0.61695823  0.72975723  0.22877615 -0.16230536]\n",
      " [ 0.45486401  0.01678628 -0.59670896 -0.45161379  0.4824939 ]\n",
      " [-0.02574589 -0.73035377  0.02455045 -0.6632312   0.15950599]\n",
      " [ 0.15064431 -0.48430666 -0.66655947 -0.25188192  0.48477554]]\n",
      "inputVectors  [[-0.41028618  0.83708759  0.23688511  0.26191411  0.07896877]\n",
      " [-0.03223179  0.16144809 -0.42726766 -0.81820848  0.34766773]\n",
      " [ 0.26273929 -0.07131838  0.54693268  0.75880308 -0.22575271]\n",
      " [-0.24286492 -0.17327004 -0.16936749 -0.40545078  0.84730068]\n",
      " [-0.42626082  0.34110381 -0.40431059 -0.62052784 -0.39169892]\n",
      " [-0.29953686  0.67711767 -0.57120598  0.3531186  -0.02864104]\n",
      " [-0.57165181  0.35059557 -0.5991628   0.15643251  0.408448  ]\n",
      " [ 0.051485    0.03443796 -0.14525284 -0.33772821  0.92790333]\n",
      " [-0.64045672 -0.41603412  0.21754715  0.60002396 -0.09682608]\n",
      " [ 0.80842944  0.05138905 -0.02904595 -0.52074479  0.26792202]]\n",
      "outputVectors  [[-0.18888469 -0.57974181  0.18513122 -0.30984209  0.70565311]\n",
      " [-0.60080462 -0.18034882  0.29616637  0.66052686 -0.28722442]\n",
      " [ 0.16021765  0.80996804  0.41079832  0.38652882 -0.01105834]\n",
      " [ 0.88645952 -0.35187128 -0.30060483 -0.00277415 -0.00227323]\n",
      " [-0.60255969  0.44022013  0.06052874  0.63586281 -0.18746417]\n",
      " [ 0.08538495 -0.80782992  0.45427756 -0.31867515  0.17943882]\n",
      " [-0.09019621 -0.61695823  0.72975723  0.22877615 -0.16230536]\n",
      " [ 0.45486401  0.01678628 -0.59670896 -0.45161379  0.4824939 ]\n",
      " [-0.02574589 -0.73035377  0.02455045 -0.6632312   0.15950599]\n",
      " [ 0.15064431 -0.48430666 -0.66655947 -0.25188192  0.48477554]]\n",
      "CenterWord  is\n",
      "context  ['schoolbag', 'schoolbag', 'my', 'my', 'my', 'nice']\n",
      "V, 10.000000 d 5.000000 \n",
      "output after softmax  [ 0.12376823  0.04083631  0.06132271  0.09282447  0.05273935  0.08841381\n",
      "  0.04624979  0.19372476  0.14212623  0.15799435]\n",
      "reshapeOutput  [[ 0.12376823]\n",
      " [ 0.04083631]\n",
      " [ 0.06132271]\n",
      " [ 0.09282447]\n",
      " [ 0.05273935]\n",
      " [ 0.08841381]\n",
      " [ 0.04624979]\n",
      " [ 0.19372476]\n",
      " [ 0.14212623]\n",
      " [ 0.15799435]]\n",
      "V, 10.000000 d 5.000000 \n",
      "output after softmax  [ 0.12376823  0.04083631  0.06132271  0.09282447  0.05273935  0.08841381\n",
      "  0.04624979  0.19372476  0.14212623  0.15799435]\n",
      "reshapeOutput  [[ 0.12376823]\n",
      " [ 0.04083631]\n",
      " [ 0.06132271]\n",
      " [ 0.09282447]\n",
      " [ 0.05273935]\n",
      " [ 0.08841381]\n",
      " [ 0.04624979]\n",
      " [ 0.19372476]\n",
      " [ 0.14212623]\n",
      " [ 0.15799435]]\n",
      "V, 10.000000 d 5.000000 \n",
      "output after softmax  [ 0.12376823  0.04083631  0.06132271  0.09282447  0.05273935  0.08841381\n",
      "  0.04624979  0.19372476  0.14212623  0.15799435]\n",
      "reshapeOutput  [[ 0.12376823]\n",
      " [ 0.04083631]\n",
      " [ 0.06132271]\n",
      " [ 0.09282447]\n",
      " [ 0.05273935]\n",
      " [ 0.08841381]\n",
      " [ 0.04624979]\n",
      " [ 0.19372476]\n",
      " [ 0.14212623]\n",
      " [ 0.15799435]]\n",
      "V, 10.000000 d 5.000000 \n",
      "output after softmax  [ 0.12376823  0.04083631  0.06132271  0.09282447  0.05273935  0.08841381\n",
      "  0.04624979  0.19372476  0.14212623  0.15799435]\n",
      "reshapeOutput  [[ 0.12376823]\n",
      " [ 0.04083631]\n",
      " [ 0.06132271]\n",
      " [ 0.09282447]\n",
      " [ 0.05273935]\n",
      " [ 0.08841381]\n",
      " [ 0.04624979]\n",
      " [ 0.19372476]\n",
      " [ 0.14212623]\n",
      " [ 0.15799435]]\n",
      "V, 10.000000 d 5.000000 \n",
      "output after softmax  [ 0.12376823  0.04083631  0.06132271  0.09282447  0.05273935  0.08841381\n",
      "  0.04624979  0.19372476  0.14212623  0.15799435]\n",
      "reshapeOutput  [[ 0.12376823]\n",
      " [ 0.04083631]\n",
      " [ 0.06132271]\n",
      " [ 0.09282447]\n",
      " [ 0.05273935]\n",
      " [ 0.08841381]\n",
      " [ 0.04624979]\n",
      " [ 0.19372476]\n",
      " [ 0.14212623]\n",
      " [ 0.15799435]]\n",
      "V, 10.000000 d 5.000000 \n",
      "output after softmax  [ 0.12376823  0.04083631  0.06132271  0.09282447  0.05273935  0.08841381\n",
      "  0.04624979  0.19372476  0.14212623  0.15799435]\n",
      "reshapeOutput  [[ 0.12376823]\n",
      " [ 0.04083631]\n",
      " [ 0.06132271]\n",
      " [ 0.09282447]\n",
      " [ 0.05273935]\n",
      " [ 0.08841381]\n",
      " [ 0.04624979]\n",
      " [ 0.19372476]\n",
      " [ 0.14212623]\n",
      " [ 0.15799435]]\n"
     ]
    }
   ],
   "source": [
    "#My Own Word2Vec try\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from FunctionAssign1_basic import softmax\n",
    "from FunctionAssign1_basic import sigmoid, sigmoid_grad\n",
    "\n",
    "def normalizeRows(x):\n",
    "    \"\"\" Row normalization function\n",
    "    Implement a function that normalizes each row of a matrix to have\n",
    "    unit length.\n",
    "    \"\"\"\n",
    "    x_square = x**2\n",
    "    x_square_sum = np.sqrt(x_square.sum(axis=1)).reshape((-1,1))\n",
    "    x /= x_square_sum\n",
    "    return x\n",
    "\n",
    "\n",
    "def softmaxCostAndGradient(predicted, target, outputVectors):\n",
    "    V,d = outputVectors.shape\n",
    "    print(\"V, %f d %f \"%(V,d))\n",
    "    \n",
    "    #a kind of forward prog got the output\n",
    "    output = softmax(np.dot(predicted,outputVectors.T))\n",
    "    print(\"output after softmax \", output)\n",
    "    #cross entropy cost\n",
    "    cost = (-1) * np.log(output[target])\n",
    "    \n",
    "    # 3(a)\n",
    "    reshapeOutput = output.reshape((-1,1))\n",
    "    print(\"reshapeOutput \", reshapeOutput)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sampleMatrix = np.random.randn(20,5)\n",
    "    print(\"Original Sample Matrix \", sampleMatrix)\n",
    "    print(\"Sample Matrix After normalize \", normalizeRows(sampleMatrix))\n",
    "    \n",
    "    tokens_dict = dict([(\"this\",0), (\"is\",1), (\"my\",2),(\"nice\",3),(\"schoolbag\",4)])\n",
    "    \n",
    "    grad = np.zeros(sampleMatrix.shape)\n",
    "    \n",
    "    N = sampleMatrix.shape[0]\n",
    "    N_half = int(N/2)\n",
    "    inputVectors = sampleMatrix[:N_half,:]\n",
    "    outputVectors = sampleMatrix[N_half:,:]\n",
    "    print(\"inputVectors \", inputVectors)\n",
    "    print(\"outputVectors \", outputVectors)\n",
    "    \n",
    "    tokens=[\"this\",\"is\", \"my\",\"nice\",\"schoolbag\"]\n",
    "    #Just test one round\n",
    "    centerword = tokens[random.randint(0,4)]\n",
    "    context = [tokens[random.randint(0,4)] for i in range(2*3)]\n",
    "    print(\"CenterWord \", centerword)\n",
    "    print(\"context \", context)\n",
    "    \n",
    "    cost = 0.0\n",
    "    #Delta V0\n",
    "    gradIn = np.zeros(inputVectors.shape)\n",
    "    #Delta Out\n",
    "    gradOut = np.zeros(outputVectors.shape)\n",
    "    \n",
    "    inputIndex = tokens_dict[centerword]\n",
    "    inputV0 = inputVectors[inputIndex]\n",
    "    \n",
    "    \n",
    "    for contextWord in context:\n",
    "        target = tokens_dict[contextWord]\n",
    "        softmaxCostAndGradient(inputV0, target,outputVectors)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
