{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# for sampling probability decay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Sampling Probability\n",
    "    # with decay => 'Curriculumn Learning'\n",
    "    sampling_probability_list = np.linspace(\n",
    "        start=0.0,\n",
    "        stop=1.0,\n",
    "        num=n_epoch,\n",
    "        dtype=np.float32)\n",
    "\n",
    "    # Checkpoint path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Sampling Probability\n",
    "        self.sampling_probability_list = config.sampling_probability_list\n",
    "        \n",
    "        # Checkpoint path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "\n",
    "            self.sampling_probability = tf.placeholder(\n",
    "                tf.float32,\n",
    "                shape=[],\n",
    "                name='sampling_probability')\n",
    "            # 0.0 ≤ sampling_probability ≤ 1.0\n",
    "            # 0.0: no sampling => `ScheduledEmbedidngTrainingHelper` is equivalent to `TrainingHelper`\n",
    "            # 1.0: always sampling => `ScheduledEmbedidngTrainingHelper` is equivalent to `GreedyEmbeddingHelper`\n",
    "            # Inceasing sampling over steps => Curriculum Learning\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maximum unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "\n",
    "                training_helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    sampling_probability=self.sampling_probability,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')                \n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state, test = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_length) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                # some sample_id are overwritten with '-1's\n",
    "                self.valid_predictions = tf.argmax(logits, axis=2, name='valid_predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "\n",
    "                batch_size = tf.shape(self.enc_inputs)[0:1]\n",
    "                start_tokens = tf.zeros(batch_size, dtype=tf.int32)\n",
    "\n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=1)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state, test = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print(f'Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "        \n",
    "    def train(self, sess, data, from_scratch=False, load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                input_batch_sent_lens = []\n",
    "                target_batch_sent_lens = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    input_batch_sent_lens.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    target_batch_sent_lens.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_valid_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: input_batch_sent_lens,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: target_batch_sent_lens,\n",
    "                        self.sampling_probability: self.sampling_probability_list[epoch]\n",
    "                    }\n",
    "                )\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_valid_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "                        \n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                print(f'Sampling probability: {self.sampling_probability_list[epoch]:.3f}')\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print(f'\\tInput: {input_sent}')\n",
    "                        print(f'\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print(f'\\tTarget: {target_sent}\\n')\n",
    "                print(f'\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "\n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "                \n",
    "        input_batch, target_batch = data\n",
    "        \n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "\n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are sucessufully built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "  1%|          | 6/801 [00:00<04:31,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Sampling probability: 0.000\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _PAD Leffe Leffe Leffe Leffe Leffe _GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: brown brown Leffe Leffe Leffe Leffe Leffe\n",
      "\tTarget: Nice to meet you too!\n",
      "\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _PAD Leffe Leffe Leffe Leffe\n",
      "\tTarget: I like Python.\n",
      "\n",
      "\tInput: See you later.\n",
      "\tPrediction: brown brown , , _GO\n",
      "\tTarget: Bye Bye.\n",
      "\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _PAD _PAD Leffe Leffe , Leffe Leffe Leffe Leffe\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _PAD _PAD Leffe Leffe , , _GO _GO _GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: South South Leffe Leffe\n",
      "\tTarget: Beer please!\n",
      "\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _PAD Beer Leffe Leffe\n",
      "\tTarget: Leffe brown!\n",
      "\n",
      "\tepoch loss: 13.83\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 410/801 [00:10<00:08, 46.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "Sampling probability: 0.500\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget: Nice to meet you too!\n",
      "\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget: I like Python.\n",
      "\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget: Bye Bye.\n",
      "\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget: Beer please!\n",
      "\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget: Leffe brown!\n",
      "\n",
      "\tepoch loss: 0.10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:19<00:00, 45.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "Sampling probability: 1.000\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget: Nice to meet you too!\n",
      "\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget: I like Python.\n",
      "\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget: Bye Bye.\n",
      "\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget: Beer please!\n",
      "\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget: Leffe brown!\n",
      "\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Saving model at ./ckpt_dir/epoch_801_sampling\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlk2UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO Hi this is Jaemin . . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO Nice to meet you too ! ! ! !\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO I like Python . . . . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO Bye Bye . . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO I live in Seoul , South Korea . .\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO I study industrial engineering . . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO Beer please ! ! ! ! ! ! !\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO Leffe brown ! ! ! ! ! ! !\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better performance than without scheduled sampling!\n",
    "- A word of caution: http://www.inference.vc/scheduled-sampling-for-rnns-scoring-rule-interpretation/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
