{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# for initial attention (not required ver1.2+)\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    attn_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Tokens\n",
    "    start_token = 0 # GO\n",
    "    end_token = 1 # PAD\n",
    "\n",
    "    # Checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.attn_size = config.attn_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Tokens\n",
    "        self.start_token = config.start_token\n",
    "        self.end_token = config.end_token\n",
    "        \n",
    "        # Checkpoint Path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            self.enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "            \n",
    "            # get dynamic batch_size\n",
    "            batch_size = tf.shape(self.enc_inputs)[0]\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "            \n",
    "            attn_mech = tf.contrib.seq2seq.LuongAttention(\n",
    "                num_units=self.attn_size,\n",
    "                memory=self.enc_outputs,\n",
    "                memory_sequence_length=self.enc_sequence_length,\n",
    "             #   normalize=False,\n",
    "                name='LuongAttention')\n",
    "\n",
    "            \n",
    "            dec_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell=dec_cell,\n",
    "                attention_mechanism=attn_mech,\n",
    "                attention_layer_size=self.attn_size,\n",
    "              #  attention_history=False, # (in ver 1.2)\n",
    "                name='Attention_Wrapper')\n",
    "            \n",
    "#             outputs = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "#                 dec_cell, batch_size, reuse=False\n",
    "#             )\n",
    "            \n",
    "            initial_state=dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size)\n",
    "\n",
    "#             initial_state = tf.contrib.seq2seq.AttentionWrapperState(\n",
    "#                 cell_state=self.enc_last_state,\n",
    "#                 attention=_zero_state_tensors(self.attn_size, batch_size, tf.float32),\n",
    "#                  time=0, alignments=(), \n",
    "#                 alignment_history=()\n",
    "#             )\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "        \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')\n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "            \n",
    "                start_tokens = tf.tile(tf.constant([self.start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "            \n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=self.end_token)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print('Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "              load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print('\\tInput: {input_sent}')\n",
    "                        print('\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print('\\tTarget:, {target_sent}')\n",
    "                print('\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "        \n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "        \n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "        \n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/801 [00:00<06:53,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: live live Beer Beer South live _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Python Python Python Python Python Python Python\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: engineering engineering Python Python Python\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: engineering Python Python Python _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: live live live Python Python Python Python Python Python\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Python Python Python Python Python live _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Python Python Python Python\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Bye Python Python Python\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 405/801 [00:13<00:13, 29.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:25<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n",
      "Saving model at {save_path}\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngQyPJEmSJEmSNJDhkSRJkiRJkgb6f80fTCmU1gtwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO Hi this is Jaemin . . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO Nice to meet you too ! ! ! !\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO I like Python Python too too too . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO Bye Bye Bye . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO I live in Seoul , South Korea Korea Korea\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO Hi study industrial engineering . . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO Beer please ! . . . . . .\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO Hi study industrial engineering . . . . .\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust inference without scheduled sampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
