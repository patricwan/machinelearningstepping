{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# for initial attention (not required ver1.2+)\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    attn_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Tokens\n",
    "    start_token = 0 # GO\n",
    "    end_token = 1 # PAD\n",
    "\n",
    "    # Checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.attn_size = config.attn_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Tokens\n",
    "        self.start_token = config.start_token\n",
    "        self.end_token = config.end_token\n",
    "        \n",
    "        # Checkpoint Path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            self.enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "            \n",
    "            # get dynamic batch_size\n",
    "            batch_size = tf.shape(self.enc_inputs)[0]\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "            \n",
    "            attn_mech = tf.contrib.seq2seq.LuongAttention(\n",
    "                num_units=self.attn_size,\n",
    "                memory=self.enc_outputs,\n",
    "                memory_sequence_length=self.enc_sequence_length,\n",
    "             #   normalize=False,\n",
    "                name='LuongAttention')\n",
    "\n",
    "            \n",
    "            dec_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell=dec_cell,\n",
    "                attention_mechanism=attn_mech,\n",
    "                attention_layer_size=self.attn_size,\n",
    "              #  attention_history=False, # (in ver 1.2)\n",
    "                name='Attention_Wrapper')\n",
    "            \n",
    "#             outputs = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "#                 dec_cell, batch_size, reuse=False\n",
    "#             )\n",
    "            \n",
    "            initial_state=dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size)\n",
    "\n",
    "#             initial_state = tf.contrib.seq2seq.AttentionWrapperState(\n",
    "#                 cell_state=self.enc_last_state,\n",
    "#                 attention=_zero_state_tensors(self.attn_size, batch_size, tf.float32),\n",
    "#                  time=0, alignments=(), \n",
    "#                 alignment_history=()\n",
    "#             )\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "        \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')\n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "            \n",
    "                start_tokens = tf.tile(tf.constant([self.start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "            \n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=self.end_token)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print('Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "              load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print('\\tInput: {input_sent}')\n",
    "                        print('\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print('\\tTarget:, {target_sent}')\n",
    "                print('\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "        \n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "        \n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "        \n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/801 [00:00<04:40,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Leffe Leffe Leffe Leffe Leffe Leffe _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Leffe Leffe Leffe Leffe Leffe brown Leffe\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Leffe Leffe Leffe Leffe Leffe\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Leffe Leffe Leffe Leffe _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Leffe Leffe Leffe Leffe brown brown brown brown brown\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Leffe Leffe Leffe Leffe Leffe Leffe _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Leffe Leffe Leffe Leffe\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Leffe Leffe Leffe Leffe\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 406/801 [00:10<00:10, 37.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:21<00:00, 37.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n",
      "Saving model at {save_path}\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO Hi this is Jaemin Jaemin . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO Nice meet you you you too ! ! !\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO I I Python Python . . . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO Bye Bye Bye . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO I live in Seoul , South Korea . Korea\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO I study industrial engineering . . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO Beer please ! ! ! ! ! ! !\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO Leffe brown ! ! ! ! ! ! !\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust inference without scheduled sampling!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
