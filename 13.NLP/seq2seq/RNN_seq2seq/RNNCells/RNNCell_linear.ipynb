{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.util import nest # for `nest.is_sequence`\n",
    "from tensorflow.contrib.rnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BasicRNNCell` is the most basic RNN cell class.\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell_impl.py\n",
    "\n",
    "- All other RNNCells have slightly different `__init__` and `__call__` s.\n",
    "\n",
    "- Most RNN functions work as below.\n",
    "\n",
    "```\n",
    "outputs = []\n",
    "cell = RNNCell(hidden_size)\n",
    "for i in range(rnn_steps):\n",
    "    output, state = cell(input, state) \n",
    "outputs.append(output)\n",
    "return  outputs, state\n",
    "```\n",
    "\n",
    "\n",
    "    1) Initialize an empty list \n",
    "    2) Create an RNNCell class\n",
    "    3) Run the RNNCell for rnn_steps times\n",
    "    4) Collect all the intermediate outputs in list\n",
    "    5) Return list of all outputs and the last state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicRNNCell(RNNCell):\n",
    "  \"\"\"The most basic RNN cell.\"\"\"\n",
    "\n",
    "  def __init__(self, num_units, input_size=None, activation=tf.nn.tanh, reuse=None):\n",
    "    if input_size is not None:\n",
    "      logging.warn(\"%s: The input_size parameter is deprecated.\", self)\n",
    "    self._num_units = num_units\n",
    "    self._activation = activation\n",
    "    self._reuse = reuse\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  def __call__(self, inputs, state, scope=None):\n",
    "    \"\"\"Most basic RNN: output = new_state = act(W * input + U * state + B).\"\"\"\n",
    "    with _checked_scope(self, scope or \"basic_rnn_cell\", reuse=self._reuse):\n",
    "      output = self._activation(\n",
    "          _linear([inputs, state], self._num_units, True))\n",
    "    return output, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What is `_linear`?\n",
    "- `_linear` is Tensorflow RNNCells' core 'linear mapping function'.\n",
    "- It internally creates weight variables (+ bias if `bias` argument is set as True)\n",
    "- It changes dimension of input variable into `output_size`\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\_linear(X, W) = \\sum_{i} X[i] * W[i]\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then let's look through `_linear`\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L1020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_BIAS_VARIABLE_NAME = \"biases\"\n",
    "_WEIGHTS_VARIABLE_NAME = \"weights\"\n",
    "\n",
    "def _linear(args, output_size, bias, bias_start=0.0):\n",
    "  \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
    "  Args:\n",
    "    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
    "    output_size: int, second dimension of W[i].\n",
    "    bias: boolean, whether to add a bias term or not.\n",
    "    bias_start: starting value to initialize the bias; 0 by default.\n",
    "  Returns:\n",
    "    A 2D Tensor with shape [batch x output_size] equal to\n",
    "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
    "  Raises:\n",
    "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
    "  \"\"\"\n",
    "  if args is None or (nest.is_sequence(args) and not args):\n",
    "    raise ValueError(\"`args` must be specified\")\n",
    "  if not nest.is_sequence(args):\n",
    "    args = [args]\n",
    "\n",
    "  # Calculate the total size of arguments on dimension 1.\n",
    "  total_arg_size = 0\n",
    "  shapes = [a.get_shape() for a in args]\n",
    "  for shape in shapes:\n",
    "    if shape.ndims != 2:\n",
    "      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n",
    "    if shape[1].value is None:\n",
    "      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n",
    "                       \"but saw %s\" % (shape, shape[1]))\n",
    "    else:\n",
    "      total_arg_size += shape[1].value\n",
    "\n",
    "  dtype = [a.dtype for a in args][0]\n",
    "\n",
    "  # Now the computation.\n",
    "  scope = tf.get_variable_scope()\n",
    "  with tf.variable_scope(scope) as outer_scope:\n",
    "    weights = tf.get_variable(\n",
    "        _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size], dtype=dtype)\n",
    "    if len(args) == 1:\n",
    "      res = tf.matmul(args[0], weights)\n",
    "    else:\n",
    "      res = tf.matmul(tf.concat(args, 1), weights)\n",
    "    if not bias:\n",
    "      return res\n",
    "    with tf.variable_scope(outer_scope) as inner_scope:\n",
    "      inner_scope.set_partitioner(None)\n",
    "      biases = tf.get_variable(\n",
    "          _BIAS_VARIABLE_NAME, [output_size],\n",
    "          dtype=dtype,\n",
    "          initializer=tf.constant_initializer(bias_start, dtype=dtype))\n",
    "    return tf.bias_add(res, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - Basic API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.constant([[1,2,3,4,5],\n",
    "             [2,4,6,8,10],\n",
    "             [3,4,5,6,7]], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_mapped = _linear(\n",
    "    args=x,\n",
    "    output_size=4,\n",
    "    bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51489446,  3.94604097,  0.93969094, -4.92853462],\n",
       "       [-1.02978893,  7.89208194,  1.87938187, -9.85706924],\n",
       "       [-0.71129123,  5.21109571,  3.1175112 , -8.20703003]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "x_mapped.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'weights:0' shape=(5, 4) dtype=float64_ref>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the name `weights` came from `_WEIGHTS_VARIABLE_NAME` above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - list of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Const:0' shape=(3, 5) dtype=float64>,\n",
       " <tf.Tensor 'Const:0' shape=(3, 5) dtype=float64>,\n",
       " <tf.Tensor 'Const:0' shape=(3, 5) dtype=float64>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.constant([[1,2,3,4,5],\n",
    "             [2,4,6,8,10],\n",
    "             [3,4,5,6,7]], dtype=tf.float64)\n",
    "x = [x, x, x]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_mapped = _linear(\n",
    "    args=x,\n",
    "    output_size=4,\n",
    "    bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.30220387, -4.29702178, -2.01037625,  3.16663845],\n",
       "       [-4.60440774, -8.59404357, -4.0207525 ,  6.33327691],\n",
       "       [-4.91712829, -6.13587478, -4.28061929,  3.8996834 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "x_mapped.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 - Custom Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.constant([[1,2],\n",
    "             [2,4],\n",
    "             [3,4]], dtype=tf.float32)\n",
    "x = [x, x, x]\n",
    "w = tf.get_variable('weights',\n",
    "                    initializer=tf.ones(shape=[6, 4]),\n",
    "                    dtype=tf.float32)\n",
    "scope = tf.get_variable_scope()\n",
    "scope.reuse_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_mapped = _linear(\n",
    "    args=x,\n",
    "    output_size=4,\n",
    "    bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.,  9.,  9.,  9.],\n",
       "       [18., 18., 18., 18.],\n",
       "       [21., 21., 21., 21.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "x_mapped.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `_linear` works as below.\n",
    "\n",
    "    1) Concatenate all the input by axis=1\n",
    "    \n",
    "    2) Multiply weight to all rows with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 2.],\n",
       "        [2., 4.],\n",
       "        [3., 4.]], dtype=float32), array([[1., 2.],\n",
       "        [2., 4.],\n",
       "        [3., 4.]], dtype=float32), array([[1., 2.],\n",
       "        [2., 4.],\n",
       "        [3., 4.]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x_.eval() for x_ in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 1., 2., 1., 2.],\n",
       "       [2., 4., 2., 4., 2., 4.],\n",
       "       [3., 4., 3., 4., 3., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(x, 1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.,  9.,  9.,  9.],\n",
       "       [18., 18., 18., 18.],\n",
       "       [21., 21., 21., 21.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.concat(x, 1), w).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
