{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# for initial attention (not required ver1.2+)\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    attn_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Tokens\n",
    "    start_token = 0 # GO\n",
    "    end_token = 1 # PAD\n",
    "\n",
    "    # Checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.attn_size = config.attn_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Tokens\n",
    "        self.start_token = config.start_token\n",
    "        self.end_token = config.end_token\n",
    "        \n",
    "        # Checkpoint Path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            self.enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "            \n",
    "            # get dynamic batch_size\n",
    "            batch_size = tf.shape(self.enc_inputs)[0]\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "            \n",
    "            attn_mech = tf.contrib.seq2seq.LuongAttention(\n",
    "                num_units=self.attn_size,\n",
    "                memory=self.enc_outputs,\n",
    "                memory_sequence_length=self.enc_sequence_length,\n",
    "             #   normalize=False,\n",
    "                name='LuongAttention')\n",
    "\n",
    "            \n",
    "            dec_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell=dec_cell,\n",
    "                attention_mechanism=attn_mech,\n",
    "                attention_layer_size=self.attn_size,\n",
    "              #  attention_history=False, # (in ver 1.2)\n",
    "                name='Attention_Wrapper')\n",
    "            \n",
    "#             outputs = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "#                 dec_cell, batch_size, reuse=False\n",
    "#             )\n",
    "            \n",
    "            initial_state=dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size)\n",
    "\n",
    "#             initial_state = tf.contrib.seq2seq.AttentionWrapperState(\n",
    "#                 cell_state=self.enc_last_state,\n",
    "#                 attention=_zero_state_tensors(self.attn_size, batch_size, tf.float32),\n",
    "#                  time=0, alignments=(), \n",
    "#                 alignment_history=()\n",
    "#             )\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "        \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')\n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "            \n",
    "                start_tokens = tf.tile(tf.constant([self.start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "            \n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=self.end_token)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print('Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "              load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print('\\tInput: {input_sent}')\n",
    "                        print('\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print('\\tTarget:, {target_sent}')\n",
    "                print('\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "        \n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "        \n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "        \n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/801 [00:00<05:39,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: Korea meet meet meet meet meet _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: meet meet meet meet meet meet meet\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: study study meet South meet\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: meet meet you meet _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: study study meet meet meet meet meet meet meet\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: meet meet meet meet meet meet _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: meet meet meet meet\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: meet meet meet meet\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 407/801 [00:10<00:09, 40.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:20<00:00, 38.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n",
      "Saving model at {save_path}\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3X+U5eddH/b3o9mLdSWDxuANsNcY\nE9IzOjELXLQpJrQNAuoxPwyXVYEQOwFC45bTUzClQxnKiRQijpxuCPQkPW1M+FVsqABNtkogLATE\n4UAx7YqVO8jWlvDDwrN2vAFNIdpb6+7o6R87M975cWdnduf+fr3OmePZ5/vduZ9dy+egN8/zfkqt\nNQAAAACwn7tGPQAAAAAA40t4BAAAAEBfwiMAAAAA+hIeAQAAANCX8AgAAACAvoRHAAAAAPQlPAIA\nuIVSyr8qpXzjqOcAABgF4REAMLZKKX9USvnSUc9Ra/2yWutPDOJnl1I+oZTyQ6WU50sp/76U8vub\nv371ID4PAOCohEcAwEwrpZwY4Wd/XJJfSfL6JG9K8glJviDJnyT5D2/j543szwIATC/hEQAwkUop\nX1lKeaaUsl5K+T9KKZ9907Pv3tzB8+ellPeVUr7mpmffVEr5zVLKD5ZS/iTJI5trv1FK+YellBdK\nKX9YSvmym37Pr5VS/vObfv9B735GKeXXNz/7X5dS/qdSyrv6/DH+VpLXJvmaWuv7aq0v11o/Umv9\n+7XWX9j8ebWU8pdu+vk/Xkp5dPP7LyqlfLCU8t+VUj6c5MdKKe8vpXzlTe+fKKVcLaV83uav37D5\n97VeSnlvKeWL7uS/BwBg+gmPAICJU0ppJ/nRJP9Fkk9K8k+TPFlKecXmK7+f5D9Ocl+Sv5fkXaWU\nT73pR3x+kj9I8slJvv+mtctJXp3kf0jyI6WU0meEg979qST/5+ZcjyT5mwf8Ub40yS/WWv/9rf/U\nfX1Kkk9M8ulJ3pbkp5N8w03PF5P8u1rr75RSWkl+Psmjm7/nv03yRCnl5B18PgAw5YRHAMAkeluS\nf1pr/e1a68ZmH9FHk7whSWqtP1trvbK5k+fxJL+XncfArtRa/3Gt9Xqttbu59oFa6w/XWjeS/ESS\nT82NcGk/+75bSnltkr+S5O/WWl+qtf5GkicP+HN8UpIP3dbfwMe8nOThWutHN/8sP5Xkq0op92w+\n/xu5ESglyVuT/EKt9Rc2/25+OcnFJF9+hzMAAFNMeAQATKJPT/Kdm0ev1ksp60k+LcmpJCml/K2b\njrStJ/ms3NgltOWP9/mZH976ptZ6bfPbV/b5/H7vnkrypzet9fusLX+SG8HTnbhaa/3/bprn3yR5\nf5I3bwZIX5UbgVJy4+/ta3f9vf1HxzADADDFlCoCAJPoj5N8f631+3c/KKV8epIfTvIlSX6r1rpR\nSnkmyc1H0OqA5vpQkk8spdxzU4D0aQe8/6+TPFpKubfW+mKfd64lueemX39Kkg/e9Ov9/ixbR9fu\nSvK+zUApufH39pO11r9ziz8HAMA2O48AgHHXKKXcfdPXidwIh/7LUsrnlxvuLaV8RSnl45PcmxuB\nytUkKaV8c27sPBq4WusHcuMY2COllI8rpXxBkjcf8Ft+MjcCnSdKKfeXUu4qpXxSKeV7SilbR8me\nSfI3SilzpZQ3Jflrhxjlf0vyxiTfmo/tOkqSd+XGjqTFzZ9392bp9muO+EcFAGaI8AgAGHe/kKR7\n09cjtdaLSf5Okn+S5IUk/ybJNyVJrfV9SX4gyW8l+bdJTif5zSHO+5YkX5AbR9IeTfJ4bvQx7VFr\n/WhulGY/l+SXk/xZbpRtvzrJb2++9u25EUCtb/7s87caoNb6odz48//Vzc/fWv/jJF+d5HtyI1z7\n4yRL8X8TAgAHKLUOatc2AACllMeTPFdrfXjUswAA3A7/XyYAgGNUSvkrpZTP3DyC9qbc2Olzy91C\nAADjSmE2AMDx+pQkK0k+KTeKrb+11npptCMBANw+x9YAAAAA6MuxNQAAAAD6mohja69+9avr6173\nulGPAQAAADA1nn766X9Xaz15q/cmIjx63etel4sXL456DAAAAICpUUr5wGHec2wNAAAAgL6ERwAA\nAAD0JTwCAAAAoC/hEQAAAAB9CY8AAAAA6Et4BAAAAEBfwiMAAAAA+hIeAQAAANCX8AgAAACAvoRH\nAAAAAPQlPAIAAACgL+ERAAAAAH0JjwAAAADoS3gEAAAAQF/CIwAAAAD6Eh4BAAAA0NfAwqNSyo+W\nUj5SSvndfZ59ZymlllJePajPBwAAAODODXLn0Y8nedPuxVLKpyV5Y5LnB/jZAAAAAByDgYVHtdZf\nT/Kn+zz6wSTflaQO6rMBAAAAOB5D7TwqpXx1krVa63sP8e7bSikXSykXr169OoTpAAAAANjtxLA+\nqJRyT5LvyY0ja7dUa31nkncmyZkzZyZ+l9L5S2t55Mlns97tba+96p5GHn7z69Npt0Y4GQAAAEB/\nw9x59JlJPiPJe0spf5TkNUl+p5TyKUOcYSTOX1rL0s++d0dwlCQvXOvl7Y8/k9d998/nC9/xqzl/\naW1EEwIAAADsb2jhUa11tdb6F2qtr6u1vi7JB5N8Xq31w8OaYVTOXbic3ssHb55aW+/m7Y8/k9f/\n3V8UIgEAAABjY2DhUSnlp5P8VpKFUsoHSynfMqjPGndX1ruHfvfFlza2dyO1v++XBEkAAADASA2s\n86jW+g23eP66QX32uDk138zaEQKkLVvH2i5+4E/zaOf0ACYDAAAAONhQb1ubVUuLC2ncVW7797/r\nPc/ne8+vHuNEAAAAAIcjPBqCTruVc1/7OZlvNm77Z7zrPc87xgYAAAAM3cCOrbFTp91Kp91KcuP2\ntXMXLh/5KNsL13pZXlnd/nkAAAAAg1ZqPfgWsHFw5syZevHixVGPMRDnL63lkSefzXq3d+jfM99s\n5JmH3zjAqQAAAIBpV0p5utZ65lbvObY2Yp12K888/Mb80Tu+Ij/09Z+bZuPW/5Wsd3s6kAAAAICh\nEB6NkU67lff//S/LW9/w2tyqXvvd73le/xEAAAAwcMKjMfRo53R+8Os/98CC7ZrkkSefHd5QAAAA\nwEwSHo2preNsr7qnf4C03u3ZfQQAAAAMlPBozD385tcfeITtO3/mvQIkAAAAYGCER2Ou027lLW94\nbd/nG7VmeWVVgAQAAAAMhPBoAjzaOX3g8bVubyPnLlwe4kQAAADArBAeTYiH3/z6NBtzfZ+vrXeH\nOA0AAAAwK4RHE6LTbuWxs6czV/ZvQCqJo2sAAADAsRMeTZBOu5Uf+LrP2bdAuyZ55Mlnhz0SAAAA\nMOWERxOm026l9nm23u3ZfQQAAAAcK+HRBGrNN/s+U5wNAAAAHCfh0QRaWlzo+2xtvWv3EQAAAHBs\nhEcTqNNu5VX3NPo+X15ZFSABAAAAx0J4NKEefvPr02zM7fus29twfA0AAAA4FidGPQC3p9NuJUne\n/vgz+z5fW+8OcxwAAABgStl5NME67Vbf8uySOLoGAAAA3DHh0YRbWlxI2We9xs1rAAAAwJ0THk24\nTruV2ueZo2sAAADAnRIeTQFH1wAAAIBBER5NAUfXAAAAgEERHk2Bg46uXXF0DQAAALgDwqMp0e/o\n2n3NxpAnAQAAAKaJ8GhKLC0upHHX3sNrL750Xe8RAAAAcNuER1Oi027llXef2LPe26h6jwAAAIDb\nJjyaIuvXevuur6137T4CAAAAbovwaIqc6tN7lCTLK6sCJAAAAODIhEdTZGlxIc3G3L7Pur0Nx9cA\nAACAI9tbksPE6rRbSZK3P/7Mvs+vrHeHOQ4AAAAwBew8mjKddiutPsfX7ms2hjwNAAAAMOmER1No\naXEhjbvKnvUXX7qu9wgAAAA4EuHRFOq0W3nl3XtPJPY2qt4jAAAA4EiER1Nq/Vpv33W9RwAAAMBR\nCI+m1Cm9RwAAAMAxEB5NKb1HAAAAwHEQHk0pvUcAAADAcRAeTTG9RwAAAMCdEh5NsX69R/3WAQAA\nAHYTHk2xpcWFNBtzO9ZKkgfvPzmagQAAAICJIzyaYp12Kw890MrNtdk1yRNPrynNBgAAAA5FeDTl\nnnruauqutW5vQ2k2AAAAcCjCoynXrxxbaTYAAABwGMKjKdevHPuuUhxdAwAAAG5JeDTl9ivNTpKN\nWrO8sipAAgAAAA4kPJpynXYrj509nblS9jzTfQQAAADcivBoBnTarbxcd9dm36D7CAAAADiI8GhG\n9Os+6rcOAAAAkAiPZsZ+3UclyYP3nxzNQAAAAMBEEB7NiE67lYceaOXm5qOa5Imn15RmAwAAAH0J\nj2bIU89dze7mI6XZAAAAwEGERzOkXzm20mwAAACgH+HRDFGaDQAAAByV8GiGKM0GAAAAjkp4NEOU\nZgMAAABHJTyaMUqzAQAAgKMQHs0YpdkAAADAUQiPZozSbAAAAOAohEczZr/S7GZjLkuLCyOaCAAA\nABhnAwuPSik/Wkr5SCnld29aO1dKea6U8n+XUv55KWV+UJ/P/jrtVh47ezrzzcb22t0NGSIAAACw\nv0GmBj+e5E271n45yWfVWj87yf+TZHmAn88BPnr95e3vX7jWy/LKqhvXAAAAgD0GFh7VWn89yZ/u\nWvulWuv1zV++J8lrBvX59HfuwuV0exs71ty4BgAAAOxnlOeV/naSf9XvYSnlbaWUi6WUi1evXh3i\nWNPPjWsAAADAYY0kPCql/PdJrid5d793aq3vrLWeqbWeOXny5PCGmwFuXAMAAAAOa+jhUSnlm5J8\nZZK31FrrsD8fN64BAAAAh3dimB9WSnlTku9K8tdqrdeG+dl8TKfdSnKj+2htvZu5UnZ0Hm09BwAA\nABjYzqNSyk8n+a0kC6WUD5ZSviXJP0ny8Ul+uZTyTCnlfxnU53OwTru1vQNpY3MD2Np6161rAAAA\nwA4D23lUa/2GfZZ/ZFCfx9EddOua3UcAAABAMtrb1hgxt64BAAAAtyI8mmFuXQMAAABuRXg0w9y6\nBgAAANyK8GiGddqtPHb2dOabje21uxv+kQAAAAA+RlJAPnr95e3vX7jWc+MaAAAAsE14NOMOunEN\nAAAAQHg049y4BgAAABxEeDTj3LgGAAAAHER4NOPcuAYAAAAc5MSoB2C0Ou1WkhvdR1fWuzk138zS\n4sL2OgAAADDbhEfsCZC2yrIFSAAAAIDwiJy/tJblldXtW9fW1rtZXllNIkACAACAWafziJy7cHk7\nONrS7W1s70ACAAAAZpfwiFxZ7x5pHQAAAJgdwiNyar55pHUAAABgdgiPyNLiQpqNuR1rzcZclhYX\nRjQRAAAAMC4UZrPntrVT880sLS4oywYAAABSaq2jnuGWzpw5Uy9evDjqMWbC+UtrQiQAAACYAaWU\np2utZ271np1HbDt/aS3LK6vbN6+trXezvLKaJAIkAAAAmFE6j9h27sLl7eBoS7e3kXMXLo9oIgAA\nAGDUhEdsu7LePdI6AAAAMP2ER2w7Nd880joAAAAw/YRHbFtaXEizMbdjrdmYy9LiwogmAgAAAEZN\nYTbbtkqx3bYGAAAAbBEescPuAGmrLFuABAAAALNJeMQO5y+tZXlldfvWtbX1bpZXVpMIkAAAAGAW\n6Txih3MXLm8HR1u6vY3tHUgAAADAbBEescOV9e6R1gEAAIDpJjxih1PzzSOtAwAAANNNeMQOS4sL\naTbmdqw1G3NZWlwY0UQAAADAKCnMZofdt62dmm9maXFBWTYAAADMKOERe+wOkLbKsgVIAAAAMHuE\nR+xx/tJalldWt29dW1vvZnllNYkACQAAAGaNziP2OHfh8nZwtKXb29jegQQAAADMDuERe1xZ7x5p\nHQAAAJhewiP2ODXfPNI6AAAAML2ER+yxtLiQZmNux1qzMZelxYURTQQAAACMisJs9th929qp+WaW\nFheUZQMAAMAMEh6xr90B0lZZtgAJAAAAZovwiH2dv7SW5ZXV7VvX1ta7WV5ZTSJAAgAAgFmi84h9\nnbtweTs42tLtbWzvQAIAAABmg/CIfV1Z7x5pHQAAAJhOwiP2dWq+eaR1AAAAYDoJj9jX0uJCmo25\nHWvNxlyWFhdGNBEAAAAwCgqz2dfu29ZOzTeztLigLBsAAABmTKm1jnqGWzpz5ky9ePHiqMeYWecv\nrQmRAAAAYMqUUp6utZ651Xt2HnGg85fWsryyun3z2tp6N8srq0kiQAIAAIAZoPOIA527cHk7ONrS\n7W3k3IXLI5oIAAAAGCbhEQe6st490joAAAAwXYRHHOjUfPNI6wAAAMB0ER5xoKXFhTQbczvWmo25\nLC0ujGgiAAAAYJgUZnOgrVJst60BAADAbBIecUu7A6StsmwBEgAAAEw/4RG3dP7SWpZXVrdvXVtb\n72Z5ZTWJAAkAAACmnc4jbunchcvbwdGWbm9jewcSAAAAML2ER9zSlfXukdYBAACA6SE84pZOzTeP\ntA4AAABMD+ERt7S0uJBmY27HWrMxl6XFhRFNBAAAAAyLwmxuafdta6fmm1laXFCWDQAAADNAeMSh\n7A6QtsqyBUgAAAAw3YRHHMr5S2tZXlndvnVtbb2b5ZXVJAIkAAAAmGY6jziUcxcubwdHW7q9je0d\nSAAAAMB0Glh4VEr50VLKR0opv3vT2ieWUn65lPJ7m//5qkF9Psfrynr3SOsAAADAdBjkzqMfT/Km\nXWvfneRXaq3/QZJf2fw1E+DUfPNI6wAAAMB0GFh4VGv99SR/umv5q5P8xOb3P5GkM6jP53gtLS6k\n2ZjbsdZszGVpcWFEEwEAAADDMOzOo0+utX5o8/sPJ/nkfi+WUt5WSrlYSrl49erV4UxHX512K4+d\nPZ35ZmN77e6GyiwAAACYdiP7t/9aa01SD3j+zlrrmVrrmZMnTw5xMg7y0esvb3//wrVelldWc/7S\n2ggnAgAAAAZp2OHRvy2lfGqSbP7nR4b8+dwBN64BAADA7Bl2ePRkkm/c/P4bk/zvQ/587oAb1wAA\nAGD2DCw8KqX8dJLfSrJQSvlgKeVbkrwjyX9aSvm9JF+6+WsmhBvXAAAAYPacGNQPrrV+Q59HXzKo\nz2SwlhYXsryyuuPomhvXAAAAYLoNLDxi+nTarSQ3uo/W1ruZK2VH59HWcwAAAGB6uGudI+m0W1la\nXEizMZeNeuOyvLX1rlvXAAAAYEoJjzgyt64BAADA7BAecWRuXQMAAIDZITziyNy6BgAAALNDeMSR\nbXUe3cytawAAADCdhEccWafdymNnT2e+2dheu7vhHyUAAACYRv6Nn9v20esvb3//wrWeG9cAAABg\nCgmPuC1uXAMAAIDZIDzitrhxDQAAAGaD8Ijb4sY1AAAAmA3CI27LfjeulSQP3n9yNAMBAAAAAyE8\n4rZ02q089EAr5aa1muSJp9eUZgMAAMAUER5x25567mrqrjWl2QAAADBdhEfcNqXZAAAAMP2ER9w2\npdkAAAAw/YRH3Dal2QAAADD9hEfcNqXZAAAAMP2ER9wRpdkAAAAw3YRH3BGl2QAAADDdhEfcEaXZ\nAAAAMN2ER9yR/Uqzk+TaS9f1HgEAAMAUEB5xRzrtVh47ezrzzcaO9Reu9bK8sipAAgAAgAknPOKO\nddqt3PuKE3vWFWcDAADA5BMecSwUZwMAAMB0Eh5xLBRnAwAAwHQSHnEs9ivOLkkevP/kaAYCAAAA\njoXwiGPRabfy0AOtlJvWapInnl5Tmg0AAAATTHjEsXnquaupu9aUZgMAAMBkEx5xbJRmAwAAwPQR\nHnFs+pVj39dsDHkSAAAA4LgIjzg2S4sLadxV9qy/+NJ1vUcAAAAwoYRHHJtOu5VX3n1iz3pvo+o9\nAgAAgAklPOJYrV/r7buu9wgAAAAmk/CIY9Wv96jfOgAAADDehEccq6XFhTQbc3vWr+k9AgAAgIkk\nPOJYddqtPHb2dOZ33bD2wrVelldWBUgAAAAwYYRHHLtOu5V7X7G3OLvb21CcDQAAABNGeMRA9CvI\nVpwNAAAAk0V4xED0K8i+b9dxNgAAAGC8CY8YiKXFhTTuKnvWX1ScDQAAABNFeMRAdNqtvPLuvb1H\nvY2q9wgAAAAmiPCIgVm/1tt3Xe8RAAAATA7hEQPTr/eo3zoAAAAwfoRHDMzS4kKajbkdayXJg/ef\nHM1AAAAAwJEJjxiYTruVhx5o5eba7JrkiafXlGYDAADAhBAeMVBPPXc1dddat7ehNBsAAAAmhPCI\ngepXjq00GwAAACaD8IiB6leOfV+zMeRJAAAAgNshPGKglhYX0rir7Fl/8aXreo8AAABgAgiPGKhO\nu5VX3n1iz3pvo+o9AgAAgAkgPGLg1q/19l3XewQAAADjT3jEwPXrPeq3DgAAAIwP4REDt7S4kGZj\nbs/6Nb1HAAAAMPaERwxcp93KY2dPZ37XDWsvXOtleWVVgAQAAABjTHjEUHTardz7ir3F2d3ehuJs\nAAAAGGPCI4amX0G24mwAAAAYX8IjhkZxNgAAAEwe4RFDs19xdkny4P0nRzMQAAAAcEvCI4am027l\noQdaKTet1SRPPL2mNBsAAADGlPCIoXrquaupu9aUZgMAAMD4Eh4xVEqzAQAAYLKMJDwqpXxHKeXZ\nUsrvllJ+upRy9yjmYPj6lWPf12wMeRIAAADgMIYeHpVSWkm+LcmZWutnJZlL8teHPQejsbS4kMZd\nZc/6iy9d13sEAAAAY2hUx9ZOJGmWUk4kuSfJlRHNwZB12q288u4Te9Z7G1XvEQAAAIyhoYdHtda1\nJP8wyfNJPpTk/621/tLu90opbyulXCylXLx69eqwx2SA1q/19l3XewQAAADjZxTH1l6V5KuTfEaS\nU0nuLaW8dfd7tdZ31lrP1FrPnDx5cthjMkD9eo/6rQMAAACjM4pja1+a5A9rrVdrrb0kK0n+6gjm\nYESWFhfSbMztWCtJHrxfSAgAAADjZhTh0fNJ3lBKuaeUUpJ8SZL3j2AORqTTbuWhB1q5uTa7Jnni\n6TWl2QAAADBmRtF59NtJfi7J7yRZ3ZzhncOeg9F66rmrqbvWur0NpdkAAAAwZvZeezUEtdaHkzw8\nis9mPPQrx1aaDQAAAONlFMfWQGk2AAAATAjhESOxX2l2klx76breIwAAABgjwiNGotNu5bGzpzPf\nbOxYf+FaL8srqwIkAAAAGBPCI0am027l3lfsrd1SnA0AAADjQ3jESCnOBgAAgPEmPGKkFGcDAADA\neBMeMVL7FWeXJA/ef3I0AwEAAAA7CI8YqU67lYceaKXctFaTPPH0mtJsAAAAGAPCI0buqeeupu5a\nU5oNAAAA40F4xMgpzQYAAIDxJTxi5JRmAwAAwPgSHjFySrMBAABgfAmPGDml2QAAADC+hEeMBaXZ\nAAAAMJ6ER4wFpdkAAAAwnoRHjAWl2QAAADCehEeMhf1Ks5uNuSwtLoxoIgAAACBJTox6AEhulGYn\nybkLl7O23s1cKTs6j7aeAwAAAMNl5xFjo9Nube9A2qg36rPX1rtZXll16xoAAACMiPCIsXLuwuV0\nexs71ty6BgAAAKMjPGKsuHUNAAAAxovwiLHi1jUAAAAYL8Ijxsp+t66VJA/ef3I0AwEAAMCMEx4x\nVjrtVh56oJVy01pN8sTTa0qzAQAAYAQOFR6VUj6zlPKKze+/qJTybaWU+cGOxqx66rmrqbvWlGYD\nAADAaBx259ETSTZKKX8pyTuTfFqSnxrYVMw0pdkAAAAwPg4bHr1ca72e5GuS/ONa61KSTx3cWMwy\npdkAAAAwPg4bHvVKKd+Q5BuT/MvNtcZgRmLW7Vea3WzMZWlxYUQTAQAAwOw6bHj0zUm+IMn311r/\nsJTyGUl+cnBjMcs67VYeO3s6882P5ZN3N3S7AwAAwCicOMxLtdb3Jfm2JCmlvCrJx9da/8EgB4OP\nXn95+/sXrvWyvLKa5Ea4BAAAAAzHYW9b+7VSyieUUj4xye8k+eFSyj8a7GjMsnMXLqfb29ix5sY1\nAAAAGL7DngW6r9b6Z0nOJvlfa62fn+RLBzcWs86NawAAADAeDhsenSilfGqSr8vHCrNhYNy4BgAA\nAOPhsOHR9yW5kOT3a63/VynlLyb5vcGNxazb78a1kuTB+0+OZiAAAACYUYcKj2qtP1tr/exa67du\n/voPaq0PDXY0Zlmn3cpDD7RSblqrSZ54ei3nL62NaiwAAACYOYctzH5NKeWfl1I+svn1RCnlNYMe\njtn21HNXU3etKc0GAACA4TrssbUfS/JkklObX/9icw0GRmk2AAAAjN5hw6OTtdYfq7Ve3/z68STK\nZxgopdkAAAAweocNj/6klPLWUsrc5tdbk/zJIAeD/Uqzk+TaS9f1HgEAAMCQHDY8+ttJvi7Jh5N8\nKMl/luSbBjQTJLlRmv3Y2dOZbzZ2rL9wrZfllVUBEgAAAAzBYW9b+0Ct9atqrSdrrX+h1tpJ4rY1\nBq7TbuXeV5zYs644GwAAAIbjsDuP9vPfHNsUcADF2QAAADA6dxIelWObAg6gOBsAAABG507Co3ps\nU8AB9ivOLkkevN+FfwAAADBoB4ZHpZQ/L6X82T5ff57k1JBmZMZ12q089EBrx1a3muSJp9eUZgMA\nAMCAHRge1Vo/vtb6Cft8fXytdW+LMQzIU89d3bPVTWk2AAAADN6dHFuDoelXjr2mNBsAAAAGSnjE\nROhXjl0SR9cAAABggIRHTISlxYV9r/eriaNrAAAAMEDCIyZCp93qe71fvyNtAAAAwJ0THjExWn2O\nrvU70gYAAADcOeERE2NpcSHNxtyOtWZjLkuLCyOaCAAAAKbfiVEPAIfVabeS3Og4urLezan5ZpYW\nF7bXAQAAgOMnPGKi7A6QtsqyBUgAAAAwGMIjJsr5S2tZXllNt7eRJFlb72Z5ZTWJAAkAAAAGQecR\nE+XchcvbwdGWbm9jewcSAAAAcLyER0yUK+vdI60DAAAAd0Z4xEQ5Nd880joAAABwZ4RHTJSlxYU0\nG3M71pqNuSwtLoxoIgAAAJhuCrOZKDfftra23s1cKTs6j5RmAwAAwPGy84iJ02m3tncgbdSa5GO3\nrp2/tDbi6QAAAGC6CI+YSG5dAwAAgOEYSXhUSpkvpfxcKeW5Usr7SylfMIo5mFxuXQMAAIDhGNXO\no/8xyS/WWu9P8jlJ3j+iOZivJfNJAAAgAElEQVRQbl0DAACA4Rh6eFRKuS/Jf5LkR5Kk1vpSrXV9\n2HMw2dy6BgAAAMMxip1Hn5HkapIfK6VcKqX8s1LKvbtfKqW8rZRysZRy8erVq8OfkrHWabfy2NnT\nmW82ttfubqjwAgAAgOM2in/bPpHk85L8z7XWdpIXk3z37pdqre+stZ6ptZ45efLksGdkQnz0+svb\n379wrefGNQAAADhmowiPPpjkg7XW39789c/lRpgER+LGNQAAABi8oYdHtdYPJ/njUspWOc2XJHnf\nsOdg8rlxDQAAAAbvxIg+979O8u5Syscl+YMk3zyiOZhgp+abWdsnKHLjGgAAAByfkTQM11qf2ewz\n+uxaa6fW+sIo5mCy7XfjWkny4P06sgAAAOC4uJ6KidVpt/LQA62Um9ZqkieeXlOaDQAAAMdEeMRE\ne+q5q6m71pRmAwAAwPERHjHRlGYDAADAYAmPmGj9yrGVZgMAAMDxEB4x0ZRmAwAAwGAJj5hoSrMB\nAABgsIRHTDyl2QAAADA4wiMmntJsAAAAGBzhERNPaTYAAAAMjvCIibdfaXaSXHvput4jAAAAuEPC\nIyZep93KY2dPZ77Z2LH+wrVelldWBUgAAABwB4RHTIVOu5V7X3Fiz7ribAAAALgzwiOmhuJsAAAA\nOH7CI6aG4mwAAAA4fsIjpka/4uz1ay/pPQIAAIDbJDxianTarTz0QGvP+osvbWTp594rQAIAAIDb\nIDxiqjz13NV913sbVXE2AAAA3AbhEVPloHJsxdkAAABwdMIjpspB5dh3leLoGgAAAByR8IipsrS4\nkMZdZd9nG7VmeWVVgAQAAABHIDxiqnTarZz72s/JfLOx7/Nub0P3EQAAAByB8Iip02m38szDb8z+\n+490HwEAAMBRCI+YWv36jw7qRQIAAAB2Eh4xtZYWF9JszO1YazbmsrS4MKKJAAAAYPKcGPUAMCid\nditJcu7C5VxZ7+bUfDNLiwvb6wAAAMCtCY+Yap12S1gEAAAAd8CxNQAAAAD6svOIqXf+0pqjawAA\nAHCbhEdMtfOX1rK8sppubyNJsrbezfLKapIIkAAAAOAQHFtjqp27cHk7ONrS7W3k3IXLI5oIAAAA\nJovwiKl2Zb17pHUAAABgJ+ERU+3UfPNI6wAAAMBOwiOm2tLiQpqNuR1rzcZclhYXRjQRAAAATBbh\nEVOt027lsbOnM99sbK/d3fCPPQAAAByWf4tmJnz0+svb379wrZflldWcv7Q2wokAAABgMgiPmHpu\nXAMAAIDbJzxi6rlxDQAAAG6f8Iip58Y1AAAAuH3CI6befjeulSQP3n9yNAMBAADABBEeMfU67VYe\neqCVctNaTfLE02tKswEAAOAWhEfMhKeeu5q6a01pNgAAANya8IiZoDQbAAAAbo/wiJmgNBsAAABu\nj/CImbBfaXaSXHvput4jAAAAOIDwiJnQabfy2NnTmW82dqy/cK2X5ZVVARIAAAD0ITxiZnTardz7\nihN71hVnAwAAQH/CI2aK4mwAAAA4GuERM6VfQfZ9u46zAQAAADcIj5gpS4sLadxV9qy/qDgbAAAA\n9iU8YqZ02q288u69vUe9jZpHnnx2BBMBAADAeBMeMXPWr/X2X+/27D4CAACAXYRHzJx+vUdJ3LoG\nAAAAuwiPmDlLiwt9n7l1DQAAAHYSHjFzOu1WXnXP/reruXUNAAAAdhIeMZMefvPr3boGAAAAhyA8\nYiYddOua3iMAAAD4GOERM6vfrWtr6127jwAAAGCT8IiZddCta8srqwIkAAAAiPCIGba0uJBmY27f\nZ93ehuNrAAAAkGRv6QvMiE67lSR5++PP7Pv8ynp3mOMAAADAWLLziJnWabfS6nN87b5mY8jTAAAA\nwPgRHjHzlhYX0rir7Fl/8aXreo8AAACYecIjZl6n3cor7957grO3UfUeAQAAMPNGFh6VUuZKKZdK\nKf9yVDPAlvVrvX3X9R4BAAAw60a58+jbk7x/hJ8P20716T3qtw4AAACzYiThUSnlNUm+Isk/G8Xn\nw25LiwtpNuZ2rDUbc1laXBjRRAAAADAe9ha9DMcPJfmuJB/f74VSytuSvC1JXvva1w5pLGZVp91K\nkpy7cDlX1rs5Nd/M0uLC9joAAADMqqGHR6WUr0zykVrr06WUL+r3Xq31nUnemSRnzpypQxqPGdZp\nt4RFAAAAsMsodh59YZKvKqV8eZK7k3xCKeVdtda3jmAW2OH8pTW7jwAAAOAmQ+88qrUu11pfU2t9\nXZK/nuRXBUeMg/OX1rK8spq19W5qkrX1bpZXVnP+0tqoRwMAAICRGeVtazBWzl24nG5vY8dat7eR\ncxcuj2giAAAAGL1RFWYnSWqtv5bk10Y5A2y5st490joAAADMAjuPYNOp+ea+6/c1G0OeBAAAAMaH\n8Ag2LS0upHFX2bP+4kvX9R4BAAAws4RHsKnTbuWVd+89ydnbqHqPAAAAmFnCI7jJ+rXevut6jwAA\nAJhVwiO4Sb/eo37rAAAAMO2ER3CTpcWFNBtze9av6T0CAABgRgmP4CaddiuPnT2d+V03rL1wrZfv\nePyZfO/51RFNBgAAAKMhPIJdOu1W7n3F3uLsmuTd73neDiQAAABmivAI9tGvILsmbl4DAABgpgiP\nYB8HFWSvuXkNAACAGSI8gn0sLS6k9HlWEkfXAAAAmBnCI9hHp93KW97w2n2fOboGAADALBEeQR+P\ndk73fba23rX7CAAAgJkgPIIDtA7oPlpeWRUgAQAAMPWER3CApcWFNBtz+z7r9jYcXwMAAGDqnRj1\nADDOOu1WkuTtjz+z7/Mrbl4DAABgytl5BLfQabf6Hl87dcCxNgAAAJgGwiM4hP2OrzUbc1laXBjR\nRAAAADAcjq3BIWwdXzt34XKurHdzar6ZpcWF7XUAAACYVsIjOKTdAdJWWbYACQAAgGkmPIJDOn9p\nLcsrq+n2NpIka+vdLK+sJhEgAQAAML10HsEhnbtweTs42tLtbeSRJ58d0UQAAAAweMIjOKQr6919\n19e7vZy/tDbkaQAAAGA4hEdwSKfmm32fbfUfAQAAwLQRHsEhLS0u9H221mdXEgAAAEw64REcUqfd\nyqvuafR93v6+X3J8DQAAgKkjPIIjePjNr0/p8+yFa70sr6wKkAAAAJgqwiM4gk67lXrA825vQ/8R\nAAAAU0V4BEfUOqA4O+l/KxsAAABMIuERHNHS4kKajbm+zw+6lQ0AAAAmjfAIjqjTbuWxs6cz39xb\nnt1szB14KxsAAABMGuER3IZOu5VnHn5jfujrPzet+WZKbhxne+zs6XTarVGPBwAAAMfmxKgHgEnW\nabeERQAAAEw1O48AAAAA6MvOI7hD5y+t5dyFy7my3s2p+WaWFhfsRgIAAGBqCI/gDpy/tJblldV0\nextJkrX1bpZXVpNEgAQAAMBUcGwN7sC5C5e3g6Mt3d5GHnny2RFNBAAAAMdLeAR34Mp6d9/19W4v\n5y+tDXkaAAAAOH7CI7gDp+abfZ+du3B5iJMAAADAYAiP4A4sLS70fba23s0XvuNX7UACAABgogmP\n4A502q286p5G3+dbBdoCJAAAACaV8Aju0MNvfn0ad5W+z7u9DUfYAAAAmFjCI7hDnXYrr7z7xIHv\n9CvWBgAAgHEnPIJjsH6td+Dzg4q1AQAAYJwJj+AYHBQOlSQP3n9yeMMAAADAMRIewTFYWlxIszG3\n77Oa5Imn15RmAwAAMJGER3AMOu1WHjt7Oq0+O5CUZgMAADCphEdwTDrtVn7zu784/e5dW1OaDQAA\nwAQSHsEx69d/VBJH1wAAAJg4wiM4ZkuLC/vuPqqJo2sAAABMHOERHLNOu5Xa59kVR9cAAACYMMIj\nGIB+xdn9jrQBAADAuBIewQAsLS6k2ZjbsdZszGVpcWFEEwEAAMDtER7BAHTarTx29nTmm43ttbsb\n/ucGAADA5PFvszBAH73+8vb3L1zrZXll1Y1rAAAATBThEQzIuQuX0+1t7Fjr9jbynT/zXgESAAAA\nE0N4BAPS72a1jVrzHY8/k+89vzrkiQAAAODohEcwIAfdrFaTvPs9z9uBBAAAwNgTHsGA7Hfj2s1q\nkkeefHZ4AwEAAMBtEB7BgGzduDZXSt931rs9u48AAAAYa8IjGKBOu5Uf+LrPSf/46EaxNgAAAIwr\n4REMWKfdylve8Nq+z9fWu3YfAQAAMLaGHh6VUj6tlPJUKeV9pZRnSynfPuwZYNge7ZzOq+5p9H2+\nvLIqQAIAAGAsjWLn0fUk31lr/ctJ3pDkvyql/OURzAFD9fCbX9+3QLvb23B8DQAAgLE09PCo1vqh\nWuvvbH7/50nen6Q17Dlg2LYKtPu5st4d4jQAAABwOCPtPCqlvC5JO8lv7/PsbaWUi6WUi1evXh32\naDAQnXYrrfnmvs9O9VkHAACAURpZeFRKeWWSJ5K8vdb6Z7uf11rfWWs9U2s9c/LkyeEPCAOytLiw\n5/haSfLg/f45BwAAYPyMJDwqpTRyIzh6d611ZRQzwKh02q089EAr5aa1muTd73k+33t+dVRjAQAA\nwL5GcdtaSfIjSd5fa/1Hw/58GAdPPXc1ddfaVoDk1jUAAADGySh2Hn1hkr+Z5ItLKc9sfn35COaA\nkelXjl0Tt64BAAAwVkZx29pv1FpLrfWza62fu/n1C8OeA0bpoHLstfVuvvAdv2oHEgAAAGNhpLet\nwaxaWlzY0Xm029p6N8srqwIkAAAARk54BCPQabfylje89sAAqdvbyNsff8YuJAAAAEZKeAQj8mjn\ndH7w6z83883Gge/ZhQQAAMAoCY9gxD56/eVbvtPtbSjSBgAAYCSERzBC5y5cTre3cah3+93QBgAA\nAIMkPIIROkogdNANbQAAADAowiMYocMGQiU3bmgDAACAYRMewQgtLS6k2Zi75XtvecNr02m3hjAR\nAAAA7CQ8ghHqtFt57OzptDZ3IJV93rn34+by7vc8ny98x6+6cQ0AAIChK7XWUc9wS2fOnKkXL14c\n9RgwcOcvreXchcu5st7Nfc1GXnzpenobH/vfaMmNXUiPdk6PbkgAAACmQinl6VrrmVu9Z+cRjJFO\nu5Xf/O4vzh++4yty7ytO7AiOkqQmefd7nrcDCQAAgKERHsGY6ncTW01y7sLl4Q4DAADAzBIewZg6\n6Ca2fsESAAAAHDfhEYyppcWFfQu0k4ODJQAAADhOwiMYU512K295w2v3BEjNxlyWFhdGMhMAAACz\nR3gEY+zRzun84Nd/blrzzZQkrflmHjt7Op12a9SjAQAAMCNOjHoA4GBbQdG5C5dzZb27XZYtQAIA\nAGAYhEcw5s5fWsvyymq6vY0kydp6N8srq0kESAAAAAyeY2sw5s5duLwdHG3p9jbynT/z3py/tDai\nqQAAAJgVwiMYc1fWu/uub9Sa73j8mXzv+dUhTwQAAMAsER7BmDs13+z7rCZ593uetwMJAACAgREe\nwZhbWlxIszHX93lN8siTzw5vIAAAAGaK8AjGXKfdymNnT2eulL7vrHd7dh8BAAAwEG5bgwmwdava\ndzz+TGqfdx558tnt985fWsu5C5dzZb2bU/PNLC0uuJkNAACA2yI8ggnRabdy8QN/mne95/l9n693\ne/mLyz+fl2tSku2QaW29m+WV1e2fAQAAAEfh2BpMkEc7p/Oqexp9n7+8mRjt3p3U7W3k3IXLgxsM\nAACAqSU8ggnz8Jtff1u/78p695gnAQAAYBYIj2DCdNqtA3cf9XNqvjmAaQAAAJh2wiOYQA+/+fVp\nNuYO/X6zMZelxYUBTgQAAMC0UpgNE2ir+PqRJ5/Nerd3y/e7vY38vX/x7I7fO6n+//buP8iuurzj\n+PthE2UBy/JrmGZjFEYaBg1JYIeGwTqAStBaWakFLEypY8tMh45iayxxmIIWCza1oJWxwyCtiiKC\ncaXiGClhRocRZMMCATWKFJCNApYsqFlhCU//uGfhZtmT3SW79+495/2ayew933P23mfz3B87n/2e\n7/FKcpIkSZLUWs48kjpU/8pe7r7wJM5atYSYxvHbto+x5oZ7GBganvPa5srA0DBr129meGSU5MUr\nyXXyzyRJkiRJ853hkdThLu5fxmWnr6Cne+p1kMZ2ZEdfdW3dhi2Mju3YacwryUmSJEnS3DI8kipg\nfBbS5aevoHeKhbE7+aprZbV38s8kSZIkSfOd4ZFUIf0re7nt/BN3GSB18lXXymrv5J9JkiRJkuY7\nwyOpgtasXsrCPSZfCemEww9qcTWzZ83qpS+5ypxXkpMkSZKkuWV4JFVQ/8pe1v3ZcroXvvQl/rVN\nwx27wHT/yl4uOXUZvT3dBNDb080lpy7zamuSJEmSNIciM9tdw5T6+vpycHCw3WVIHee4SzcyPMl6\nQF0RfPK05dMKXQaGhlm3YQtbR0ZZ1NPNmtVLDWskSZIkqQIiYlNm9k11nDOPpAorW0h6RyYfvO5u\nLhjYvMvvHxgaZu36zQyPjJLA8Mgoa9dv7tiZS5IkSZKkmVvQ7gIkzZ1FPd2TzjwCSOCa2x/hmtsf\noad7IREwsn1sp9lF6zZsYXRsx07fNzq2g3Ubtjj7SJIkSZJqwplHUoVNtsD0ZEZGx9i2fewls4vK\nZi6VjUuSJEmSqsfwSKqw8QWmu2LyK6+VGZ9dtKine9L9ZeOSJEmSpOoxPJIqrn9lL588bTkzi48a\ns4smm7nUvbCLNauXzl6BkiRJkqR5zfBIqoH+lb2cuWrJjL5nj2K20iWnLqO3p5sAenu6ueTUZa53\nJEmSJEk1Yngk1cTF/cs4a9WSac9AGr8i2+DDT7Jm9VIW9XSzdWSUdRu2eLU1SZIkSaqRyMx21zCl\nvr6+HBwcbHcZUiUMDA2zbsOW0quwTUf3wi5nIEmSJElSh4uITZnZN9VxC1pRjKT5o39l7wuhz8DQ\nMBfdeD8jo2Mzuo/xBbUNjyRJkiSp+gyPpBprDpKOu3TjjGYjbd2NmUuSJEmSpM7hmkeSAFizeumM\nrsi2b/fCKY8ZGBrmuEs3csj5N3HcpRtdK0mSJEmSOpDhkSRg5ldkGxkd44KBzaX7B4aGWbt+M8Mj\noyQwPDLK2vWbDZAkSZIkqcMYHkl6wfgV2abrmtsf4bXn38TKj33nJaHQug1bGB3bsdPY6NgOLrrx\n/lmpVZIkSZLUGoZHknZycf8yLj99BT3TOC1t3LbtY5x33d07zUQqWxNpZHTM2UeSJEmS1EEiM9td\nw5T6+vpycHCw3WVItTXTxbT326sRPG3bPvlV3Hp7urnt/BNnpTZJkiRJ0ssTEZsys2+q45x5JGlK\nM11Me9v2sdLgCLxSmyRJkiR1EsMjSVMaX0x7JgHSrkznSm2SJEmSpPnB8EjStFzcv4zLZrgWUpnf\nPvuc6x5JkiRJUodwzSNJMzYwNMza9fcyOvb8bt/Xfnst5MI/eT39K3tnoTJJkiRJ0nRNd80jwyNJ\nL9vA0DAX3Xg/I6Pl6xvNlGGSJEmSJLWG4ZGklpnNmUgTGSZJkiRJ0twwPJLUcnMxE6mMoZIkSZIk\n7R7DI0ltNTA0zLoNW9g6Msq+3Qt5+ndjPD/Hbzd7BDyf0NvTzZrVSw2WJEmSJGkXDI8kzSsDQ8Os\nuf4exuY6QXoZpjuLqTkQW2RAJUmSJKnDGR5JmndaeVpbu8z27CcDK0mSJElzZV6HRxFxMvApoAu4\nKjMv3dXxhkdSNdUhTJIkSZJUPVVZg3W64dGCVhTTLCK6gCuAtwKPAndGxI2Z+cNW1yKpvfpX9r7w\nZjs+w2Z4ZLTNVUmSJEnSrm3bPsaaG+4B6PgAaTpaHh4BxwAPZOaDABHxFeAUwPBIqrHmIAmclSRJ\nkiRpfhvbkazbsMXwaI70Aj9v2n4U+MOJB0XEOcA5AEuWLGlNZZLmjYlh0kSGS5IkSZLabWtNzpxo\nR3g0LZl5JXAlNNY8anM5kuaZycIlAyVJkiRJrbSop7vdJbREO8KjYeDVTduLizFJ2i1TzVaaqHmd\npQCmSqnHr6Q2nWMlSZIkVdvCrmDN6qXtLqMl2hEe3QkcFhGH0AiNzgD+vA11SKq5mYZN0zFXs58M\nriRJkqT5oypXW5uulodHmflcRPwtsAHoAq7OzPtbXYckzYW5CKQkSZIkqZ3asuZRZn4L+FY7HluS\nJEmSJEnTt0e7C5AkSZIkSdL8ZXgkSZIkSZKkUoZHkiRJkiRJKmV4JEmSJEmSpFKGR5IkSZIkSSpl\neCRJkiRJkqRShkeSJEmSJEkqZXgkSZIkSZKkUoZHkiRJkiRJKmV4JEmSJEmSpFKGR5IkSZIkSSpl\neCRJkiRJkqRShkeSJEmSJEkqZXgkSZIkSZKkUoZHkiRJkiRJKmV4JEmSJEmSpFKGR5IkSZIkSSpl\neCRJkiRJkqRShkeSJEmSJEkqFZnZ7hqmFBFPAA+3u45ZciDwq3YXoZaz7/Vl7+vL3teXva8ve19f\n9r6e7Ht9Van3r8nMg6Y6qCPCoyqJiMHM7Gt3HWot+15f9r6+7H192fv6svf1Ze/ryb7XVx1772lr\nkiRJkiRJKmV4JEmSJEmSpFKGR613ZbsLUFvY9/qy9/Vl7+vL3teXva8ve19P9r2+atd71zySJEmS\nJElSKWceSZIkSZIkqZThkSRJkiRJkkoZHrVIRJwcEVsi4oGIOL/d9Wh2RcTVEfF4RNzXNLZ/RNwc\nET8tvu5XjEdEfLp4LtwbEUe1r3Ltroh4dUTcGhE/jIj7I+IDxbj9r7CI2DMifhAR9xR9/2gxfkhE\n3FH097qIeEUx/spi+4Fi/2vbWb92X0R0RcRQRHyz2Lb3NRARD0XE5oi4OyIGizHf72sgInoi4oaI\n+HFE/CgijrX31RcRS4vX+/i/pyPiPHtffRHxweJ3vPsi4trid79af9YbHrVARHQBVwBvA44A3hMR\nR7S3Ks2y/wJOnjB2PnBLZh4G3FJsQ+N5cFjx7xzgsy2qUXPjOeDvM/MIYBVwbvH6tv/V9gxwYmYu\nB1YAJ0fEKuATwGWZ+TpgG/C+4vj3AduK8cuK49TZPgD8qGnb3tfHCZm5IjP7im3f7+vhU8C3M/Nw\nYDmN17+9r7jM3FK83lcARwPbga9j7ystInqB9wN9mfkGoAs4g5p/1hsetcYxwAOZ+WBmPgt8BTil\nzTVpFmXmd4EnJwyfAny+uP15oL9p/AvZcDvQExG/35pKNdsy8xeZeVdx+9c0fpnsxf5XWtG/3xSb\nC4t/CZwI3FCMT+z7+PPhBuDNEREtKlezLCIWA38MXFVsB/a+zny/r7iI2Bd4E/A5gMx8NjNHsPd1\n82bgZ5n5MPa+DhYA3RGxANgL+AU1/6w3PGqNXuDnTduPFmOqtoMz8xfF7V8CBxe3fT5UVDFFdSVw\nB/a/8orTlu4GHgduBn4GjGTmc8Uhzb19oe/F/qeAA1pbsWbR5cCHgeeL7QOw93WRwHciYlNEnFOM\n+X5ffYcATwD/WZyuelVE7I29r5szgGuL2/a+wjJzGPhX4BEaodFTwCZq/llveCS1QGYmjV84VVER\nsQ/wNeC8zHy6eZ/9r6bM3FFMY19MY4bp4W0uSS0QEe8AHs/MTe2uRW3xxsw8isapKedGxJuad/p+\nX1kLgKOAz2bmSuC3vHiaEmDvq65Y2+adwPUT99n76inWsDqFRnC8CNibly5RUjuGR60xDLy6aXtx\nMaZqe2x8mmrx9fFi3OdDxUTEQhrB0Zcyc30xbP9rojh14VbgWBrT0xcUu5p7+0Lfi/37Av/X4lI1\nO44D3hkRD9E4Df1EGmuh2PsaKP4aTWY+TmPdk2Pw/b4OHgUezcw7iu0baIRJ9r4+3gbclZmPFdv2\nvtreAvxvZj6RmWPAehqf/7X+rDc8ao07gcOK1dlfQWPK441trklz70bg7OL22cA3msb/orgawyrg\nqaZpr+owxfnMnwN+lJn/1rTL/ldYRBwUET3F7W7grTTWu7oVeHdx2MS+jz8f3g1sLP5SqQ6TmWsz\nc3FmvpbG5/nGzDwTe195EbF3RLxq/DZwEnAfvt9XXmb+Evh5RCwtht4M/BB7Xyfv4cVT1sDeV90j\nwKqI2Kv4XX/8NV/rz/qo4M80L0XE22mskdAFXJ2ZH29zSZpFEXEtcDxwIPAYcCEwAHwVWAI8DJyW\nmU8Wb0CfoTH1cTvw3swcbEfd2n0R8Ubge8BmXlz/5CM01j2y/xUVEUfSWBixi8YfYr6amR+LiENp\nzEbZHxgCzsrMZyJiT+CLNNbEehI4IzMfbE/1mi0RcTzwocx8h72vvqLHXy82FwBfzsyPR8QB+H5f\neRGxgsYi+a8AHgTeS/H+j72vtCIsfgQ4NDOfKsZ83VdcRHwUOJ3GlZWHgL+isbZRbT/rDY8kSZIk\nSZJUytPWJEmSJEmSVMrwSJIkSZIkSaUMjyRJkiRJklTK8EiSJEmSJEmlDI8kSZIkSZJUyvBIkiRV\nXkQcHBFfjogHI2JTRHw/It5V7Ds+Ir45xfdfFBEfmuFj/mYGx54XEXvN5P4lSZJaxfBIkiRVWkQE\nMAB8NzMPzcyjgTOAxe2tbCfnAYZHkiRpXjI8kiRJVXci8Gxm/sf4QGY+nJn/PvHAiNg/IgYi4t6I\nuD0ijmzavbyYsfTTiPjr4vh9IuKWiLgrIjZHxCm7KiQi9o6ImyLinoi4LyJOj4j3A4uAWyPi1uK4\nk4rHuisiro+IfYrxhyLiX4rH+kFEvG73/3skSZJ2zfBIkiRV3euBu6Z57EeBocw8EvgI8IWmfUfS\nCKKOBf4xIhYBvwPelZlHAScAnyxmOpU5Gdiamcsz8w3AtzPz08BW4ITMPCEiDgQuAN5S3O8g8HdN\n9/FUZi4DPgNcPs2fS5Ik6WUzPJIkSbUSEVcUM3/unGT3G4EvAmTmRuCAiPi9Yt83MnM0M38F3Aoc\nAwTwzxFxL/A/QC9w8C4efjPw1oj4RET8UWY+Nckxq4AjgNsi4m7gbOA1Tfuvbfp67DR+ZEmSpN2y\noN0FSJIkzbH7gT8d39sn/EsAAAFqSURBVMjMc4vZPYMzvJ+cZPtM4CDg6Mwci4iHgD1L7yDzJxFx\nFPB24OKIuCUzPzbhsABuzsz3TKOOiTVJkiTNOmceSZKkqtsI7BkRf9M0VrY49fdoBEJExPHArzLz\n6WLfKRGxZ0QcABwP3AnsCzxeBEcnsPMMoZcoTnXbnpnXAOuAo4pdvwZeVdy+HThufD2jYp2kP2i6\nm9Obvn5/V48nSZI0G5x5JEmSKi0zMyL6gcsi4sPAE8BvgX+Y5PCLgKuL09C20zhlbNy9NE5XOxD4\np8zcGhFfAv47IjbTmMn04ynKWQasi4jngTFgPNC6Evh2RGwt1j36S+DaiHhlsf8C4CfF7f2K+p4B\nymYnSZIkzZrIdLazJElSJyhOi+sr1l2SJElqCU9bkyRJkiRJUilnHkmSJEmSJKmUM48kSZIkSZJU\nyvBIkiRJkiRJpQyPJEmSJEmSVMrwSJIkSZIkSaUMjyRJkiRJklTq/wHYAKfSH7I/QAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO Hi this this is Jaemin . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO Nice to meet you too ! ! ! !\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO I like Python . . . . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO Bye Bye Bye . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO I live in Seoul , South Korea . .\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO I study industrial engineering . . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO Beer please ! ! ! ! ! . .\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO Leffe brown ! ! ! . . . .\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust inference without scheduled sampling!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
