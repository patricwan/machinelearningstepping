{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# for initial attention (not required ver1.2+)\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    attn_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Tokens\n",
    "    start_token = 0 # GO\n",
    "    end_token = 1 # PAD\n",
    "\n",
    "    # Checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.attn_size = config.attn_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Tokens\n",
    "        self.start_token = config.start_token\n",
    "        self.end_token = config.end_token\n",
    "        \n",
    "        # Checkpoint Path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            self.enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "            \n",
    "            # get dynamic batch_size\n",
    "            batch_size = tf.shape(self.enc_inputs)[0]\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "            \n",
    "            attn_mech = tf.contrib.seq2seq.LuongAttention(\n",
    "                num_units=self.attn_size,\n",
    "                memory=self.enc_outputs,\n",
    "                memory_sequence_length=self.enc_sequence_length,\n",
    "             #   normalize=False,\n",
    "                name='LuongAttention')\n",
    "\n",
    "            \n",
    "            dec_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell=dec_cell,\n",
    "                attention_mechanism=attn_mech,\n",
    "                attention_layer_size=self.attn_size,\n",
    "              #  attention_history=False, # (in ver 1.2)\n",
    "                name='Attention_Wrapper')\n",
    "            \n",
    "#             outputs = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "#                 dec_cell, batch_size, reuse=False\n",
    "#             )\n",
    "            \n",
    "            initial_state=dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size)\n",
    "\n",
    "#             initial_state = tf.contrib.seq2seq.AttentionWrapperState(\n",
    "#                 cell_state=self.enc_last_state,\n",
    "#                 attention=_zero_state_tensors(self.attn_size, batch_size, tf.float32),\n",
    "#                  time=0, alignments=(), \n",
    "#                 alignment_history=()\n",
    "#             )\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "        \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')\n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "            \n",
    "                start_tokens = tf.tile(tf.constant([self.start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "            \n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=self.end_token)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=initial_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print('Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "              load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print('\\tInput: {input_sent}')\n",
    "                        print('\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print('\\tTarget:, {target_sent}')\n",
    "                print('\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "        \n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "        \n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "        \n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/801 [00:01<09:40,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: South South South South South South _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: South South South South South South South\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: South South South South South\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: South South South South _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: South South South South South South South South South\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: South South South South South South _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: South South South South\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: South South South South\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 410/801 [00:12<00:08, 43.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:22<00:00, 36.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, {target_sent}\n",
      "\tInput: {input_sent}\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, {target_sent}\n",
      "\tepoch loss: {epoch_loss:.2f}\n",
      "\n",
      "Saving model at {save_path}\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqa//Bw3czUE9i5rgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO Hi this is Jaemin . . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO Nice to meet you too ! ! . .\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO I like Python . . . . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO Bye Bye . . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO I live in Seoul , South Korea . .\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO I study ! . . . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO Beer please ! ! ! . . . .\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO Leffe brown ! . . . . . .\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}_attention')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust inference without scheduled sampling!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
