{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# for sampling probability decay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Sampling Probability\n",
    "    # with decay => 'Curriculumn Learning'\n",
    "    sampling_probability_list = np.linspace(\n",
    "        start=0.0,\n",
    "        stop=1.0,\n",
    "        num=n_epoch,\n",
    "        dtype=np.float32)\n",
    "\n",
    "    # Checkpoint path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Sampling Probability\n",
    "        self.sampling_probability_list = config.sampling_probability_list\n",
    "        \n",
    "        # Checkpoint path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "\n",
    "            self.sampling_probability = tf.placeholder(\n",
    "                tf.float32,\n",
    "                shape=[],\n",
    "                name='sampling_probability')\n",
    "            # 0.0 ≤ sampling_probability ≤ 1.0\n",
    "            # 0.0: no sampling => `ScheduledEmbedidngTrainingHelper` is equivalent to `TrainingHelper`\n",
    "            # 1.0: always sampling => `ScheduledEmbedidngTrainingHelper` is equivalent to `GreedyEmbeddingHelper`\n",
    "            # Inceasing sampling over steps => Curriculum Learning\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maximum unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "\n",
    "                training_helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    sampling_probability=self.sampling_probability,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')                \n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_length) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                # some sample_id are overwritten with '-1's\n",
    "                self.valid_predictions = tf.argmax(logits, axis=2, name='valid_predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "\n",
    "                batch_size = tf.shape(self.enc_inputs)[0:1]\n",
    "                start_tokens = tf.zeros(batch_size, dtype=tf.int32)\n",
    "\n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=1)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print(f'Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "        \n",
    "    def train(self, sess, data, from_scratch=False, load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                input_batch_sent_lens = []\n",
    "                target_batch_sent_lens = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    input_batch_sent_lens.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    target_batch_sent_lens.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_valid_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: input_batch_sent_lens,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: target_batch_sent_lens,\n",
    "                        self.sampling_probability: self.sampling_probability_list[epoch]\n",
    "                    }\n",
    "                )\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_valid_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "                        \n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                print(f'Sampling probability: {self.sampling_probability_list[epoch]:.3f}')\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print(f'\\tInput: {input_sent}')\n",
    "                        print(f'\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print(f'\\tTarget: {target_sent}\\n')\n",
    "                print(f'\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "\n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "                \n",
    "        input_batch, target_batch = data\n",
    "        \n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "\n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are sucessufully built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "  1%|          | 6/801 [00:00<04:40,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Sampling probability: 0.000\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: I . I South . . _GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: to I . I South Leffe Leffe\n",
      "\tTarget: Nice to meet you too!\n",
      "\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: I I ! Leffe Leffe\n",
      "\tTarget: I like Python.\n",
      "\n",
      "\tInput: See you later.\n",
      "\tPrediction: to South South . _GO\n",
      "\tTarget: Bye Bye.\n",
      "\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: I I South . . Leffe Leffe Leffe Leffe\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\n",
      "\tInput: What is your major?\n",
      "\tPrediction: I I industrial industrial South Leffe _GO _GO _GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: I I South .\n",
      "\tTarget: Beer please!\n",
      "\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: I I I .\n",
      "\tTarget: Leffe brown!\n",
      "\n",
      "\tepoch loss: 13.46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 406/801 [00:11<00:09, 42.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "Sampling probability: 0.500\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget: Nice to meet you too!\n",
      "\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget: I like Python.\n",
      "\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget: Bye Bye.\n",
      "\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget: Beer please!\n",
      "\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget: Leffe brown!\n",
      "\n",
      "\tepoch loss: 0.08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:21<00:00, 37.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "Sampling probability: 1.000\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget: Hi this is Jaemin.\n",
      "\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget: Nice to meet you too!\n",
      "\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget: I like Python.\n",
      "\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget: Bye Bye.\n",
      "\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget: I live in Seoul, South Korea.\n",
      "\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget: I study industrial engineering.\n",
      "\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget: Beer please!\n",
      "\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget: Leffe brown!\n",
      "\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Saving model at ./ckpt_dir/epoch_801_sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3X+U5ed9F/b3s7MT68p2NHa8kOx1\nZLuhZ3SOWeyLF1BQf6Ak9RiIncuKxAS7JEBxyx+FGHeolvogJXUqtUPq9EBPi1Pyo9ikiqNlqtSB\nSUDm5ODGaVcZiY1sTQOEKL7r4CXRQNBepLuzT/+Yncnsztz5sTv33rlzX69z9mTm+X5n72c3sk/0\nzvO8n1JrDQAAAADs5MSoBwAAAADg6BIeAQAAANCX8AgAAACAvoRHAAAAAPQlPAIAAACgL+ERAAAA\nAH0JjwAA9lBK+XullO8a9RwAAKMgPAIAjqxSyr8opXzLqOeotf7hWuuPDeL3LqV8dSnlB0spL5ZS\n/m0p5Z/d+P5Ng/g8AICDEh4BABOtlHJyhJ/9VUn+YZK3J3lPkq9O8o1JfiPJ77+N329kfxYA4PgS\nHgEAY6mU8q2llGdLKaullP+7lPJ7tjx7+MYOnt8qpXyhlPLHtjz77lLK50opHy+l/EaSR2+s/eNS\nyl8rpbxUSvmVUsof3vIz/6iU8p9t+fnd3n1bKeXnbnz2Pyil/M+llE/2+WP8qST3JvljtdYv1Fqv\n11q/Umv9b2utP33j96ullN+15ff/0VLKx258/YdKKV8qpfzXpZRfT/IjpZQvllK+dcv7J0spV0op\nv/fG9/ff+PtaLaU8V0r5Q3fyvwcA4PgTHgEAY6eU0kryw0n+8yRfk+RvJnmqlPKaG6/8syT/YZJ7\nknxvkk+WUr5uy2/xB5L88yS/M8n3b1lbSfKmJP9Dkr9VSil9Rtjt3b+T5P+5MdejSf7TXf4o35Lk\n79da/+3ef+q+vjbJG5O8JcmHkvx4ku/c8nwuyb+qtf5iKaWZ5DNJPnbjZ/6rJE+WUk7dwecDAMec\n8AgAGEcfSvI3a62/UGtdu9FH9EqS+5Ok1vrpWuvlGzt5nkjyy7n5GNjlWutfr7Veq7V2b6z9aq31\nh2qta0l+LMnXZT1c2smO75ZS7k3y+5L81Vrrq7XWf5zkqV3+HF+T5Mu39Tfw264neaTW+sqNP8vf\nSfK+UsrdN57/yawHSknywSQ/XWv96Rt/Nz+b5GKSP3KHMwAAx5jwCAAYR29J8pEbR69WSymrSb4+\nyekkKaX8qS1H2laT/O6s7xLa8Gs7/J6/vvFFrfXqjS9f1+fz+717Oslvblnr91kbfiPrwdOduFJr\n/Xdb5vmnSb6Y5L03AqT3ZT1QStb/3r79lr+3/+AQZgAAjjGligDAOPq1JN9fa/3+Wx+UUt6S5IeS\nfHOSn6+1rpVSnk2y9QhaHdBcX07yxlLK3VsCpK/f5f1/kORjpZTX1lpf7vPO1SR3b/n+a5N8acv3\nO/1ZNo6unUjyhRuBUrL+9/a3a61/bo8/BwDAJjuPAICjbrqUcteWXyezHg79F6WUP1DWvbaU8kdL\nKa9P8tqsBypXkqSU8qezvvNo4Gqtv5r1Y2CPllK+qpTyjUneu8uP/O2sBzpPllLuK6WcKKV8TSnl\nr5RSNo6SPZvkT5ZSpkop70nyH+9jlP8jybuT/Pn89q6jJPlk1nckzd34/e66Ubr95gP+UQGACSI8\nAgCOup9O0t3y69Fa68Ukfy7J30jyUpJ/muS7k6TW+oUkP5Dk55P8yyRnknxuiPN+IMk3Zv1I2seS\nPJH1PqZtaq2vZL00+4UkP5vk32S9bPtNSX7hxmt/MesB1OqN33txrwFqrV/O+p//D974/I31X0vy\nbUn+StbDtV9LMh//NyEAsItS66B2bQMAUEp5IskLtdZHRj0LAMDt8P9lAgA4RKWU31dK+YYbR9De\nk/WdPnvuFgIAOKoUZgMAHK6vTXIhyddkvdj6z9dal0c7EgDA7XNsDQAAAIC+HFsDAAAAoK+xOLb2\npje9qb71rW8d9RgAAAAAx8Yzzzzzr2qtp/Z6byzCo7e+9a25ePHiqMcAAAAAODZKKb+6n/cGdmyt\nlPLDpZSvlFJ+aYdnHyml1FLKmwb1+QAAAADcuUF2Hv1okvfculhK+fok707y4gA/GwAAAIBDMLDw\nqNb6c0l+c4dHH0/yl5O45g0AAADgiBvqbWullG9L0qm1PrePdz9USrlYSrl45cqVIUwHAAAAwK2G\nFh6VUu5O8leS/NX9vF9r/USt9Wyt9eypU3sWfwMAAAAwAMPcefQNSd6W5LlSyr9I8uYkv1hK+doh\nzgAAAADAAZwc1gfVWi8l+R0b398IkM7WWv/VsGYAAAAA4GAGtvOolPLjSX4+yWwp5UullD87qM8C\nAAAAYDAGtvOo1vqdezx/66A+GwAAAIDDMdTb1gAAAAAYL8IjAAAAAPoSHgEAAADQl/AIAAAAgL6E\nRwAAAAD0JTwCAAAAoC/hEQAAAAB9CY8AAAAA6Et4BAAAAEBfwiMAAAAA+hIeAQAAANDXyVEPMCkW\nlzt59Knns9rtba694e7pPPLet6fdao5wMgAAAID+Sq111DPs6ezZs/XixYujHuO2LS53Mv/p59K7\n3v/vujnTyPzcrCAJAAAAGIpSyjO11rN7vic8GrwHHn86ndXuvt4tSWqESQAAAMBg7Tc80nk0BJf3\nGRwl68FRknRWu/nwE8/mo4uXBjMUAAAAwD4Ij4bg9Ezjtn6uJvnk518UIAEAAAAjIzwagvm52Uyf\nKLf98wIkAAAAYFSER0PQbjWz8O3vyExj+rZ/j09+/sW0vu9nsrjcOcTJAAAAAHanMHsEFpc7WVha\n2XeJ9lYlyQfuvzcfa585/MEAAACAibHfwuyTwxiGm7Vbzc1b1BaXO3n0qeez2u3t62drkk99/sWc\nfcsb3cQGAAAADJydR0fMRxcv5ZOff3HP92Ya03n2kXcPYSIAAADgONrvziOdR0fMx9pn8sH7781e\n9dqr3Z7+IwAAAGDghEdH0MfaZ/Lx979zz4LtR596fkgTAQAAAJNKeHREtVvNPPvIu/PB++/t+47d\nRwAAAMCgCY+OuI+1z+QNd/ffgfSRn3hOgAQAAAAMjPBoDDzy3rf3fbZWa85fuCRAAgAAAAZCeDQG\n2q3mrruPur01/UcAAADAQAiPxsQj7317GtNTfZ/rPwIAAAAGQXg0JtqtZh47dyZTpfR9Z2FpZYgT\nAQAAAJPg5KgHYP/arWaS5HueeHbH553V7jDHAQAAACaAnUdjZrf+o5I4ugYAAAAcKuHRGHrkvW/P\nTofXahxdAwAAAA6X8GgMtVvN1D7POqtdu48AAACAQyM8GlPNmUbfZ+cvXBIgAQAAAIdCeDSm5udm\n05ie2vFZt7fm+BoAAABwKNy2NqbcvAYAAAAMg51HY6zdavY9vubmNQAAAOAwCI/G3PzcrJvXAAAA\ngIERHo253W5eu+zoGgAAAHCHhEfHQL+ja/c0poc8CQAAAHDcCI+Ogfm52Uyf2H547eVXr+k9AgAA\nAO6I8OgYaLeaed1d2y/O661VvUcAAADAHREeHROrV3s7rus9AgAAAO6E8OiYOK33CAAAABgA4dEx\nofcIAAAAGATh0TGh9wgAAAAYBOHRMaL3CAAAADhswqNjpF/v0YlSHF0DAAAAbovw6BiZn5tNY3pq\n2/parTl/4ZIACQAAADgw4dEx0m4189i5M5kq24uzu7013UcAAADAgQmPjpl2q5nrte74TPcRAAAA\ncFDCo2OoX/dRv3UAAACAfoRHx9BO3UclyYP3nRrNQAAAAMDYEh4dQ+1WMw+9q5mtzUc1yZPPdJRm\nAwAAAAciPDqmPvvCldzafKQ0GwAAADgo4dEx1a8cW2k2AAAAcBDCo2OqXzn2PY3pIU8CAAAAjDPh\n0TE1Pzeb6RNl2/rLr17TewQAAADsm/DomGq3mnndXSe3rffWqt4jAAAAYN+ER8fY6tXejut6jwAA\nAID9Eh4dY/16j/qtAwAAANxKeHSMzc/NpjE9ddNaSfLgfadGMxAAAAAwdoRHx1i71cxD72pma212\nTfLkMx2l2QAAAMC+CI+Ouc++cCX1lrVub01pNgAAALAvwqNjrl85ttJsAAAAYD8GFh6VUn64lPKV\nUsovbVlbKKW8UEr5J6WUv1tKmRnU57NOaTYAAABwJwa58+hHk7znlrWfTfK7a62/J8n/l+T8AD+f\n7Fya3Zieyvzc7IgmAgAAAMbJwMKjWuvPJfnNW9Z+ptZ67ca3n0/y5kF9PuvarWYeO3cmzRs7jaZK\n2ew8UpoNAAAA7GWUnUd/Jsnf6/ewlPKhUsrFUsrFK1euDHGs46fdam7uQFqr6/XZndVuzl+4JEAC\nAAAAdjWS8KiU8t8kuZbkU/3eqbV+otZ6ttZ69tSpU8Mb7phaWFpJt7d205pb1wAAAIC9nBz2B5ZS\nvjvJtyb55lrrrbfIMyBuXQMAAABux1B3HpVS3pPkLyd5X6316jA/e9K5dQ0AAAC4HQMLj0opP57k\n55PMllK+VEr5s0n+RpLXJ/nZUsqzpZT/dVCfz812unWtJHnwPkcCAQAAgP4Gdmyt1vqdOyz/rUF9\nHrtrt5q5+Ku/mU99/sVsnBWsSZ58ppOzb3lj2q3mKMcDAAAAjqhR3rbGkH32hSu5tWRKaTYAAACw\nG+HRBFGaDQAAAByU8GiCKM0GAAAADkp4NEGUZgMAAAAHJTyaIO1WMw+9q5myZW2jNHtxuTOqsQAA\nAIAjTHg0YZRmAwAAAAchPJowSrMBAACAgxAeTRil2QAAAMBBCI8mzE6l2Y3pqczPzY5oIgAAAOAo\nEx5NmHarmcfOnclMY3pz7a5p/xgAAAAAO5MaTKhXrl3f/Pqlq72cv3DJjWsAAADANsKjCbSwtJJu\nb+2mNTeuAQAAADsRHk0gN64BAAAA+yU8mkBuXAMAAAD2S3g0gdy4BgAAAOzXyVEPwPC1W80k691H\nndVupkq5qfNo4zkAAACAnUcTqt1qbu5AWqs1SdJZ7bp1DQAAALiJ8GiCuXUNAAAA2IvwaIK5dQ0A\nAADYi/Bogrl1DQAAANiL8GiC7XTrWkny4H2nRjMQAAAAcOQIjyZYu9XMQ+9qpmxZq0mefKajNBsA\nAABIIjyaeJ994UrqLWtKswEAAIANwqMJpzQbAAAA2I3waMIpzQYAAAB2IzyacEqzAQAAgN0Ijyac\n0mwAAABgN8IjlGYDAAAAfQmPUJoNAAAA9CU8Qmk2AAAA0JfwiB1LsxvTU5mfmx3RRAAAAMBRcXLU\nAzB67VYzSbKwtJLLq92cnmlkfm52cx0AAACYXKXWW6uSj56zZ8/WixcvjnqMibC43BEiAQAAwAQo\npTxTaz2713t2HrFpcbmT8xcupdtbS5J0Vrs5f+FSkgiQAAAAYELpPGLTwtLKZnC0odtby8LSyogm\nAgAAAEZNeMSmy6vdA60DAAAAx5/wiE2nZxoHWgcAAACOP+ERm+bnZtOYnrpprSR58L5ToxkIAAAA\nGDnhEZvarWYeelczZctaTfLkM50sLndGNRYAAAAwQsIjbvLZF66k3rKmNBsAAAAml/CImyjNBgAA\nALYSHnGTfuXY9zSmhzwJAAAAcBQIj7jJ/Nxspk+Ubesvv3pN7xEAAABMIOERN2m3mnndXSe3rffW\nqt4jAAAAmEDCI7ZZvdrbcV3vEQAAAEwe4RHb9Os96rcOAAAAHF/CI7aZn5tNY3rqprXG9FTm52ZH\nNBEAAAAwKsIjtmm3mnns3JnMbLlh7a5p/6gAAADAJJII0Ncr165vfv3S1V7OX7jkxjUAAACYMMIj\ndrSwtJJub+2mtW5vzY1rAAAAMGGER+yo381qblwDAACAySI8YkduXAMAAAAS4RF97HTjWpJcffWa\n3iMAAACYIMIjdrTTjWuJ4mwAAACYNMIj+mq3mnnta05uW1ecDQAAAJNDeMSuFGcDAADAZBMesat+\nBdn33HKcDQAAADiehEfsan5uNtMnyrb1lxVnAwAAwEQQHrGrdquZ1921vfeot1b1HgEAAMAEEB6x\np9WrvR3X9R4BAADA8Sc8Yk96jwAAAGByCY/Yk94jAAAAmFzCI/ak9wgAAAAml/CIfdF7BAAAAJNp\nYOFRKeWHSylfKaX80pa1N5ZSfraU8ss3/ucbBvX5HC69RwAAADCZBrnz6EeTvOeWtYeT/MNa67+f\n5B/e+J4xoPcIAAAAJtPAwqNa688l+c1blr8tyY/d+PrHkrQH9fkcLr1HAAAAMJmG3Xn0O2utX77x\n9a8n+Z39XiylfKiUcrGUcvHKlSvDmY5d6T0CAACAyTOywuxaa01Sd3n+iVrr2Vrr2VOnTg1xMvrp\n13vUbx0AAAAYf8MOj/5lKeXrkuTG//zKkD+fOzA/N5vG9NRNa43pqczPzY5oIgAAAGDQhh0ePZXk\nu258/V1J/s8hfz53oN1q5rFzZ9K8sdNoqpR0e2tZWFpRmg0AAADH1MDCo1LKjyf5+SSzpZQvlVL+\nbJLHk/wnpZRfTvItN75njLRbzc0dSGt1/dRhZ7Wb8xcuCZAAAADgGNp+fdYhqbV+Z59H3zyoz2Q4\nFpZW0u2t3bS2sQOp3WqOaCoAAABgEEZWmM346ne7mlvXAAAA4PgRHnFgbl0DAACAySE84sDcugYA\nAACTQ3jEgW3cujbTmN5cu2vaP0oAAABwHPk3fm7bK9eub3790tVePvzEs/no4qURTgQAAAAcNuER\nt2WnG9dqkk99/sUsLndGMxQAAABw6IRH3JZ+N6vVrAdLAAAAwPEgPOK27HazWr9gCQAAABg/wiNu\ny/zcbEqfZ/dsKdIGAAAAxpvwiNvSbjXzgfvv3fHZy69e03sEAAAAx4TwiNv2sfaZvOHu7buMemtV\n7xEAAAAcE8Ij7sjq1d6O63qPAAAA4HgQHnFH+hVnnyjF0TUAAAA4BoRH3JH5udk0pqe2ra/VmvMX\nLgmQAAAAYMwJj7gj7VYzj507k6my/e61bm9N9xEAAACMOeERd6zdauZ6rTs+030EAAAA4014xKHo\n133Ubx0AAAAYD8IjDsVO3UclyYP3nRrNQAAAAMChEB5xKNqtZh56VzNbm49qkief6SjNBgAAgDEm\nPOLQfPaFK7m1+UhpNgAAAIw34RGHpl85ttJsAAAAGF/CIw6N0mwAAAA4foRHHJqdSrMb01OZn5sd\n0UQAAADAnRIecWjarWYeO3cmM43pzbW7pv0jBgAAAOPMv9lz6F65dn3z65eu9nL+wiU3rgEAAMCY\nEh5xqBaWVtLtrd201u2t5SM/8ZwACQAAAMaQ8IhD1e9mtbVa7UACAACAMSQ84lDtdrNat7eWhaWV\nIU4DAAAA3CnhEYdqpxvXtuq3MwkAAAA4moRHHKqNG9emStnx+W47kwAAAICjR3jEoWu3mvmB73jH\nth1IjempzM/NjmgqAAAA4HYIjxiIjR1IM43pzbVuby3f+1PPK80GAACAMSI8YqBefuXaTd+/dLWX\n+Z98ToAEAAAAY0J4xMAsLK2kd71uW++tVbeuAQAAwJgQHjEwu92s5tY1AAAAGA/CIwZmt5vV3LoG\nAAAA40F4xMDMz81m+kTZtj49Vdy6BgAAAGPi5KgH4Phqt5pJkkefej6r3V6S5A13T+eR97598xkA\nAABwtAmPGKh2qykoAgAAgDEmPGIoFpc7WVhayeXVbk7PNDI/NytUAgAAgDEgPGLgFpc7OX/hUrq9\ntSRJZ7Wb8xcuJYkACQAAAI44hdkM3MLSymZwtKHbW8tHfuK5LC53RjQVAAAAsB/CIwbu8mp3x/W1\nWnP+wiUBEgAAABxhwiMG7vRMo++zbm8tC0srQ5wGAAAAOAjhEQM3PzebxvRU3+f9diYBAAAAoyc8\nYuDarWYeO3cmU6Xs+Hy3nUkAAADAaAmPGIp2q5kf+I53bNuB1Jieyvzc7IimAgAAAPYiPGJoNnYg\nzTSmN9fumvaPIAAAABxl/s2doXvl2vXNr1+62suHn3g2H128NMKJAAAAgH6ERwzVwtJKur21m9Zq\nkk99/sUsLndGMxQAAADQl/CIoep3s1rNerAEAAAAHC3CI4Zqt5vV+gVLAAAAwOgIjxiq+bnZlD7P\n7tlSpA0AAAAcDcIjhqrdauYD99+747PVbi+t7/sZ3UcAAABwhAiPGLqPtc/kDXfvvMvopau9nL9w\nSYAEAAAAR4TwiJFYvdrr+6zbW1OeDQAAAEeE8IiR2K04O1GeDQAAAEeF8IiRmJ+bTWN6qu/zvcIl\nAAAAYDiER4xEu9XMY+fOZKbPDWtXX72m9wgAAACOAOERI9NuNfPsI+/OD77/ndtCJMXZAAAAcDQI\njxi5dquZ177m5LZ1xdkAAAAwesIjjoROn4JsxdkAAAAwWsIjRm5xuZPS55nibAAAABgt4REjt7C0\nkrrDesn6rWwAAADA6IwkPCqlfLiU8nwp5ZdKKT9eSrlrFHNwNPQ7mlaTfPiJZ/PA408rzgYAAIAR\nGXp4VEppJvkLSc7WWn93kqkkf2LYc3B07HY0rWa9D8nNawAAADAaozq2djJJo5RyMsndSS6PaA6O\ngPm52TSmp3Z9x81rAAAAMBpDD49qrZ0kfy3Ji0m+nORf11p/5tb3SikfKqVcLKVcvHLlyrDHZIja\nrWYeO3cmzT3Ksd28BgAAAMM3imNrb0jybUneluR0kteWUj5463u11k/UWs/WWs+eOnVq2GMyZO1W\nM597+Jt2DZDcvAYAAADDN4pja9+S5FdqrVdqrb0kF5L8wRHMwRG02+4iN68BAADA8I0iPHoxyf2l\nlLtLKSXJNyf54gjm4Ajqt7topjGddqs55GkAAACAUXQe/UKSn0zyi0ku3ZjhE8Oeg6Npp/LsxvRU\nHn3f20c0EQAAAEy2k6P40FrrI0keGcVnc7Rt7C5aWFrJ5dVuTs80Mj83a9cRAAAAjMhIwiPYTbvV\nFBYBAADAESE84shaXO7YgQQAAAAjJjziSFpc7uT8hUvp9taSJJ3Vbs5fuJQkAiQAAAAYolHctgZ7\nWlha2QyONnR7a1lYWhnRRAAAADCZhEccSZdXuwdaBwAAAAZDeMSRdHqmcaB1AAAAYDCERxxJ83Oz\naUxP3bRWkjx436nRDAQAAAATSnjEkdRuNfPQu5opW9Zqkief6WRxuTOqsQAAAGDiCI84sj77wpXU\nW9a6vbV8zxPP5oHHnxYiAQAAwBAIjziydivH7qx2c/7CJQESAAAADJjwiCNrr3Lsbm8tC0srQ5oG\nAAAAJpPwiCNrp9LsW+22OwkAAAC4cydHPQD00241kyTf88Szfd/Za3cSAAAAcGfsPOJIa7eaae4S\nEF199ZreIwAAABgg4RFH3m7H11662lOcDQAAAAMkPOLIa7eaeezcmb47kBRnAwAAwOAIjxgL7VYz\nn3v4m/o+V5wNAAAAgyE8YmwsLndS+jxTnA0AAACDITxibCwsraTusF6y3osEAAAAHD7hEWOj39G0\nmvVjbQAAAMDhEx4xNvodTetXpA0AAADcOeERY2N+bjaN6amb1hrTU46sAQAAwACdHPUAsF8bR9MW\nllZyebWb0zONzM/NOrIGAAAAA1Rq3amC+Gg5e/ZsvXjx4qjH4IhZXO7k0aeez2q3t7n2hrun88h7\n3y5QAgAAgD2UUp6ptZ7d6z07jxhLi8udzH/6ufSu3xx+vnS1l/mffC6JEm0AAAA4DDqPGEsLSyvb\ngqMNvbWahaWVIU8EAAAAx5PwiLF0ebV7R88BAACA/REeMZZOzzTu6DkAAACwP8IjxtL83GymT5S+\nzx+879QQpwEAAIDjS3jEWGq3mln49ndkpjG94/Mnn+lkcbkz5KkAAADg+BEeMbbarWaefeTdae5w\nRK3bW1OaDQAAAIdAeMTY61eOrTQbAAAA7pzwiLHXrxxbaTYAAADcuX2FR6WUbyilvObG13+olPIX\nSikzgx0N9md+bjaN6alt61dfvab3CAAAAO7QfncePZlkrZTyu5J8IsnXJ/k7A5sKDqDdauaxc2e2\nlWe/dLWX8xcuCZAAAADgDuw3PLpea72W5I8l+eu11vkkXze4seBg2q1mXvuak9vWFWcDAADAndlv\neNQrpXxnku9K8n/dWNv5jnQYEcXZAAAAcPj2Gx796STfmOT7a62/Ukp5W5K/Pbix4OD6FmSXOLoG\nAAAAt2lf4VGt9Qu11r9Qa/3xUsobkry+1vrfD3g2OJD5udlMnyjb1mtN5n/yOQESAAAA3Ib93rb2\nj0opX11KeWOSX0zyQ6WU/3Gwo8HBtFvNvO6u7b1HSdJbq/nITwiQAAAA4KD2e2ztnlrrv0lyLsn/\nXmv9A0m+ZXBjwe1Zvdrr+2ytVrevAQAAwAHtNzw6WUr5uiTfkd8uzIYjp2/v0Q1uXwMAAICD2W94\n9H1JlpL8s1rr/1tK+feS/PLgxoLb06/3aCu3rwEAAMD+7VwQc4ta66eTfHrL9/88yUODGgpuV7vV\nTJI8+tTzWe3ufIRtr91JAAAAwG/bb2H2m0spf7eU8pUbv54spbx50MPB7Wi3mnn2kXfnB9//zjSm\np256VpI8eN+p0QwGAAAAY2i/x9Z+JMlTSU7f+PVTN9bgyGq3mnnoXc1sPcRWkzz5TEdpNgAAAOzT\nfsOjU7XWH6m1Xrvx60eT2L7BkffZF66k3rKmNBsAAAD2b7/h0W+UUj5YSpm68euDSX5jkIPBYehX\njq00GwAAAPZnv+HRn0nyHUl+PcmXk/zxJN89oJng0PQrx76nMT3kSQAAAGA87Ss8qrX+aq31fbXW\nU7XW31Frbcdta4yB+bnZTJ8o29ZffvWa3iMAAADYh/3uPNrJXzq0KWBA2q1mXnfXyW3rvbWq9wgA\nAAD24U7Co+3bOeAIWr3a23G9o/cIAAAA9nQn4dGtl1jBkdSv96gkjq4BAADAHnYNj0opv1VK+Tc7\n/PqtJKeHNCPckfm52R23ydXE0TUAAADYw67hUa319bXWr97h1+trrduLZOAIareafbfJXXZ0DQAA\nAHZ1J8fWYGw0+xxd63ekDQAAAFgnPGIizM/NpjE9tW396qvX9B4BAADALoRHTIR2q5nHzp3JTGP6\npvWXrvZy/sIlARIAAAD0ITwW8k+DAAAgAElEQVRiYrRbzbz2Ndururq9tTz61PMjmAgAAACOPuER\nE6VfQfZqt2f3EQAAAOxAeMRE2a0ge2FpZYiTAAAAwHgQHjFR5udm+z7rtysJAAAAJpnwiInSbjXz\nhrund3x2T2PndQAAAJhkwiMmziPvfXumT5Rt66vdXj66eGkEEwEAAMDRJTxi4rRbzbzuru23riXJ\npz7/ouJsAAAA2GIk4VEpZaaU8pOllBdKKV8spXzjKOZgcq1e7e24XqM4GwAAALYa1c6j/ynJ36+1\n3pfkHUm+OKI5mFC73brWWe3mbQ9/Jg88/rRdSAAAAEy8oYdHpZR7kvxHSf5WktRaX621rg57Dibb\n/Nxstrce/baa9RDp/IVLAiQAAAAm2ih2Hr0tyZUkP1JKWS6l/G+llNfe+lIp5UOllIullItXrlwZ\n/pQca+1WMx+4/95dA6Qk6fbWHGMDAABgoo0iPDqZ5Pcm+V9qra0kLyd5+NaXaq2fqLWerbWePXXq\n1LBnZAJ8rH0mH3//OzPTmN71vcur3SFNBAAAAEfPKMKjLyX5Uq31F258/5NZD5Ng6NqtZl77mp1v\nXttwzx7hEgAAABxnQw+Paq2/nuTXSimzN5a+OckXhj0HbNhrZ9HLr17TewQAAMDEGtVta/9lkk+V\nUv5Jkncm+e9GNAfsevNakvTWqt4jAAAAJtZIwqNa67M3+ox+T621XWt9aRRzQLJ+89pe9B4BAAAw\nqUa18wiOjHarmTfcvXuv0V67kwAAAOC4Eh5Bkkfe+/Y0pqd2fNaYntrX7iQAAAA4jna/ZgomRLvV\nTJIsLK2ks9rNVClZqzXNmUbm52Y3nwMAAMCkER7BDe1WU0gEAAAAt3BsDQAAAIC+hEcAAAAA9CU8\nAgAAAKAvnUewT4vLnSwsreTyajenFWkDAAAwIYRH0MfWsOiexnRefvVaems1SdJZ7eb8hUtJIkAC\nAADgWHNsDXawuNzJ+QuX0lntpiZZ7fY2g6MN3d5aFpZWRjMgAAAADInwCHawsLSSbm9tz/cur3aH\nMA0AAACMjvAIdrDfUOj0TGPAkwAAAMBoCY9gB/sJhRrTU5mfmx3CNAAAADA6wiPYwfzcbMouz5sz\njTx27oyybAAAAI494RHsoN1qpvZ5VpJ87uFvEhwBAAAwEYRH0Eezz9G1E6XkbQ9/Jg88/nQWlztD\nngoAAACGS3gEfczPzaYxPbVtfa3W1CSd1W7OX7gkQAIAAOBYEx5BH+1WMw+9q7lr91G3t5aFpZWh\nzQQAAADDJjyCXXz2hSt9u482XF7tDmUWAAAAGAXhEexiP8HQ6T7dSAAAAHAcCI9gF3sFQyXJg/ed\nGs4wAAAAMALCI9hFv9LsDTXJk890lGYDAABwbJVa92p0Gb2zZ8/WixcvjnoMJtTicicLSyu5vNrN\niVKytsN/ZqZKyfVac3qmkfm52bRbzRFMCgAAAPtXSnmm1np2r/dODmMYGGftVnMzDHrbw5/Z8Z2N\nQKmz2s35C5c2fw4AAADGnWNrcAD7Kcfu9taysLQyhGkAAABg8IRHcAB7dSBt2M8tbQAAADAOHFuD\nA9g4irZXB9J+digBAADAOBAewQFt7UBaXO7k/IVL6fbWNp83pqcyPzc7qvEAAADgUDm2Bneg3Wrm\nsXNnMtOY3ly7a9p/rAAAADg+/FsuHIJXrl3f/Pqlq718+Iln89HFSyOcCAAAAA6HY2twGxaXO7v2\nHtUkn/r8izn7ljduHnEDAACAcWTnERzQRs9RZ7WbmuxYmJ2sB0gLSytDnQ0AAAAOm/AIDmhhaeWm\nguzdXF7tDngaAAAAGCzhERzQQQKh0zONAU4CAAAAgyc8ggPabyDUmJ7K/NzsgKcBAACAwRIewQHN\nz82mMT216zvNmUYeO3dGWTYAAABjz21rcEAbgdCjTz2f1W7vpmeN6ak89K5mPvvClXz4iWfz6FPP\np5Rk9Wovp2camZ+bFSgBAAAwVoRHcBvarWbarWYWlztZWFrJ5dVuTs808uB9p/LkM53NQu2t4VJn\ntZvzFy5t/jwAAACMA+ER3IGNEGnDA48/vetNbN3eWhaWVoRHAAAAjA2dR3CI9nMT20FuawMAAIBR\nEx7BIdrPTWz7va0NAAAAjgLhERyivW5ia0xPZX5udogTAQAAwJ3ReQSHaKPLaKNE+57GtNvWAAAA\nGGvCIzhkt5ZoAwAAwDgTHsEALC53Nncf2XEEAADAOBMewSFbXO7k/IVL6fbWkiSd1W7OX7i0+Vyo\nBAAAwDgRHsEhW1ha2QyONnR7a3n0qefzyrXrO4ZKAiQAAACOKretwSG7vNrdcX2129sxVFpYWhnG\nWAAAAHBbhEdwyE7PNA70fr+wCQAAAI4C4REcsvm52UyfKPt+/6BhEwAAAAyT8AgOWbvVzOvu2l+d\nWGN6KvNzswOeCAAAAG6f8AgGYPVqb8937p4+kbumT+TDTzybBx5/OovLnc1ni8udPPD403nbw5/Z\n9gwAAACGyW1rMACnZxrp7NFl1O1dz9Xe9SQ337yWJOcvXHIrGwAAAEeCnUcwAPNzs2lMT+36Tr3l\n+42b1xaWVtzKBgAAwJFh5xEMwMYOoYWllT13IG2127tuZQMAAGAU7DyCAWm3mvncw9+UH3z/O7ft\nQtrtLrZ+z9zKBgAAwCgIj2DA2q1mHjt3Js2ZRkqS5kwjH7j/3r7H2mq2B0huZQMAAGBUHFuDIWi3\nmtvKrs++5Y35niee3fH9muQNd09n9Wovp2camZ+bVZYNAADASAiPYAQWlzt7FmD/u971fPz97xQa\nAQAAMFKOrcGQLS53cv7CpT2LtN2wBgAAwFFg5xEMycZuo4PcvuaGNQAAAEZNeARDsLHbqNtbO9DP\nuWENAACAUXNsDYZgYWnlwMGRG9YAAAA4Cuw8giHY7/GzkvWb1ppuWAMAAOCIGFl4VEqZSnIxSafW\n+q2jmgOG4fRMY19dRxvB0ece/qYdn2/0Jl1e7ea0gAkAAIAhGOWxtb+Y5Isj/HwYmvm52TSmp/b1\nbr9dSltvaatJOqvdnL9wKYvLnUOcFAAAAG42kp1HpZQ3J/mjSb4/yV8axQwwTBu7g7buGrr66rW8\ndLW37d2tJdlbdxqdKCVrtd70bre3loWlFbuPAAAAGJhRHVv7wSR/Ocnr+71QSvlQkg8lyb333juk\nsWBw2q3mTSHPTjewNaan8uB9p/LA40+ns9rd7EBKsi042rDfPiUAAAC4HUM/tlZK+dYkX6m1PrPb\ne7XWT9Raz9Zaz546dWpI08HwtFvNPHbuTJozjZSsdx099K5mnnyms9mPtHNcdLOtO5UAAADgsI1i\n59EDSd5XSvkjSe5K8tWllE/WWj84gllgpG7djfTA40/ftBNpLyXJg/cJVwEAABicoe88qrWer7W+\nudb61iR/IsnTgiNYd9AjaDXJk890lGYDAAAwMKO8bQ24xV5H0MoOaxul2QAAADAIIw2Paq3/qNb6\nraOcAY6SB+87tWNAtKFfB5LSbAAAAAbFziM4IhaXO3nymc62gGjqxG5x0jql2QAAAAyK8AiOiIWl\nlR3Lsteu737nWmN6KvNzs4MaCwAAgAk3itvWgB0c9OhZyfqOo/m52ZtubAMAAIDDJDyCI+L0TCOd\nfQZIJcnH3/9OoREAAAAD59gaHBHzc7NpTE/dtDbdp++oJnn0qefzwONP520PfyYPPP50Fpc7Q5gS\nAACASSM8giOi3WrmsXNn0pxppCRpzjSy8O3v6Pv+areXzmo3NUlntZvzFy4JkAAAADh0jq3BEdJu\nNbcdRVtYWtnXcbZuby0LSyuOsgEAAHCo7DyCI26n42z9HLR0GwAAAPZi5xEccRs7iRaWVnJ5tZvT\nM41cffVaXrra2/bu6ZnGsMcDAADgmBMewRi49Tjb4nIn5y9cSre3trnWmJ7K/NzsKMYDAADgGBMe\nwRjaaTfS/NysviMAAAAOnfAIxtRO5doAAABw2IRHcIwsLnfsRgIAAOBQCY9gDO0UEiW5qQeps9rN\n+QuXkkSABAAAwG0THsGYubUsu7Pazfynn8tarbleb36321vLwtKK8AgAAIDbJjyCMbOwtHLTLWtJ\n0rs1Ndri8mp30CMBAABwjJ0Y9QDAwRw0DDo90xjQJAAAAEwC4RGMmYOEQY3pqc0+JAAAALgdwiMY\nM/Nzs2lMT+3r3Yfe1dR3BAAAwB0RHsGYabeaeezcmTRnGilJZhrTfd/95OdfzAOPP53F5c7wBgQA\nAOBYUZgNY6jdunlH0Vsf/kzfdzur3Zy/cGnz5wAAAOAghEdwDDRnGunsUqTd7a3l0aeez8LSSi6v\ndnN6ppH5uVlhEgAAAHsSHsGYW1zu5OVXru353mq3l9VuL4ndSAAAAOyfziMYY4vLnZy/cGkzFDqI\nbm8tC0srA5gKAACA40R4BGNsYWkl3d7atvWyz5+/vMtRNwAAAEgcW4Ox1i/8qVm/hW2vHUmnZxpJ\n1ncw6UMCAABgJ8IjGGOn+xRlzzSm88q163v+/NVXr+Wji5fy5DOdzR1M+pAAAADYyrE1GGPzc7Np\nTE/dtNaYnkop2fE4261eutrLpz7/4rZ39SEBAACwQXgEY6zdauaxc2fSnGmkJGnONPLYuTNZvbr/\nAu3aZ72z2s3icudQ5gQAAGB8ObYGY67dam47XrawtLLjcbaDcnwNAAAAO4/gGJqfm933jWu7cXwN\nAAAA4REcQ+1WMx+4/95tAdL0iZLpqYPFSv1udAMAAGAyCI/gmPpY+0w+/v533tSHtPDt78jCH3/H\ngX6f0zONwQwIAADAWNB5BMfYTn1Iyf47kRrTU5mfmx3EaAAAAIwJO49gAs3PzWb6xPbjaydK8oa7\np2+6uU1ZNgAAwGSz8wgmULvVzPf+1PN56WrvpvXrNbn7q05m+a++e0STAQAAcNTYeQQTavWW4GiD\ngmwAAAC2svMIJtTpmcaOvUf3NKazuNzJwtJKLq92c3qmkQfvO5XPvnBl8/v5uVnH2QAAACZEqbWO\neoY9nT17tl68eHHUY8Cxsrjcyfynn0vv+s3/HXCiJFMnSnpr/f+7oTE9pQ8JAABgzJVSnqm1nt3r\nPTuPYILcuqPoq06eSO/VtZveuV6T67sER0nS7a1lYWlFeAQAADABhEcwIRaXOzl/4VK6vfWwaKcj\nawdxpz8PAADAeFCYDRNiYWllMzg6DCXrgRQAAADHm51HMCH2e4va9ImStVpzfY86tJrk/IV/ctMx\nOEXaAAAAx4+dRzAhTs80dlyfaUynOdNISdKcaeT9v//rs98a/W7vejqr3dSsH2Ob//RzaX3fz+Rt\nD38mDzz+tJ1JAAAAx4CdRzAh5udmb+o8StZvTXv0fW/f3C200Yt0u5cw9q7XvHS1l2Q9TDp/4VKS\n2I0EAAAwxuw8ggnRbjXz2LkzN+0yeuzcmZuCncPuRdq4lQ0AAIDxZecRTJB2q7nrLqD99iIdxCB+\nTwAAAIbHziNgU79epKP2ewIAADA8wiNg0/zcbBrTU7u+Uw7w+zWmpzI/N3tnQwEAADBSwiNg0069\nSB+8/96bvv/4+9+Z5j5vbru1UwkAAIDxo/MIuMlevUhJcvFXfzOf+vyL2XopW0my2u3lta85mY+/\n/51CIwAAgGPCziPgQBaXO3nymc5NwVGSze87q92cv3Api8udYY8GAADAAAiPgANZWFpJt7e26zvd\n3loWllaGNBEAAACDJDwCDuTyavdQ3wMAAOBo03kEHMjpmUY6+wiGapJvOP/TWas1zZlG5udm9SAB\nAACMITuPgAOZn5tNY3pqX++u1fUmpM5qN9/zxLNpfd/P6EICAAAYM8Ij4EDarWYeO3cmzZlGSpLm\nTCMfvP/eNGcae/7sS1d7yrQBAADGjGNrwIG1W80dj6C97eHPbLuF7VYbZdqOsAEAAIwH4RFwaPbb\nh7S1THtxuZOFpZVcXu3mtG4kAACAI0d4BByKxeVOXn7l2r7evacxvfkz5y9cSre3lmS9G+n8hUtJ\nIkACAAA4IoRHwB27NQTay8uvXtvccXTrzxzkWJtdSwAAAIMnPALu2E4hUJKUZMcOpN5a3Qx9dtJv\nfSu7lgAAAIbDbWvAHesX9uxWnt1Z7Wbm7ukdn53ex81t/XYtPfrU83v+LAAAAPsnPALu2H7Cnp38\n66u9bWuN6anMz80mWd9d9MDjT+dtD38mDzz+dBaXO5vv9QusVru9m94DAADgzgiPgDs2PzebxvTU\nTWtlHz93/ZbvS5KH3tVMu9XcPJbWWe2m5rePpW0EQ7sFVgtLKweaHwAAgP6GHh6VUr6+lPLZUsoX\nSinPl1L+4rBnAA5Xu9XMY+fOpDnTSEnSnGnkA/ffuy1Q2ktN8tkXrmRxuZOP/MRzfcu0k2zuTtrJ\nfjqTAAAA2J9RFGZfS/KRWusvllJen+SZUsrP1lq/MIJZgEPSbjW3FVWffcsbN4uxT5SStbpbC9K6\njR1G/d7dCIbarWa+96eez0s7HH273WN0AAAAbDf0nUe11i/XWn/xxte/leSLSVyNBMdQu9XM5x7+\npvzK4380P/Ad79jXTqRSsuPNbRu2BkOPvPft237PrZ1JAAAA3LlR7DzaVEp5a5JWkl/Y4dmHknwo\nSe69996hzgUcvo1dSd/z/7d3/8Fx3/Wdx19vrb+J1wl4k+Bh8OYHZkqdCVViJT4aRlwnDgWnpCWq\n4UhytOU6vWOmQ6dNjqrn9DwQuHBWT0dDe+30hgGuv9LU+eGqKWYwHPJce2lDY0c2IhBTEkLImhJz\n8YY22sZr6X1/7Pe7Wq2+3/0hrXZX+30+ZjzWfr/f3f1IH2lX89L78/4cOJ54TTBkKi8kVydlg4x2\nXblFoxPTOlUsaWsuq3dfl9eRp05Xb4/v3r6sAgoAAAAAsHLmLSwjWZMnNrtQ0v+R9HF3P9jo2p07\nd/rRo0e7MzAAa2p0YlqFFfQkypjp9h+/TA8fKyypTMoGGe3fM0xgBAAAAABtMrNj7r6z2XU92W3N\nzAJJD0u6r1lwBGCwxO3M1opPvPcaHXnqdMMm2gAAAACAzuvFbmsm6TOSvuHuv93t5wfQe+dvWHzp\nGbLm1+eygcZG8om7qK12d7WpmYJGJ6a1be8hjU5Ma2qmsKrHAwAAAIBB0ovKo1FJPy/pRjM7Hv57\nZw/GAaDLpmYKuuvgrIqlxR3SGrQ4klRZlnb3u94kKXkXtdXsrhaNqVAsybW42xsBEgAAAABU9GK3\ntf/r7ubuV7v7jvDf57s9DgDdN3n4ZMOd1OplzJb0M4pb8la/u1q7VURxY2IpHAAAAAAs6uluawDS\npZ3lZUMmvTq7QXceOK7JwyeX7KI2efhk7O5qURVRFAZFVUSSEhtqr9VSOAAAAAAYFIRHALpmay4b\nu9NaLhtIUnU526ZgSOUF15m5yu36ECgpCGpURZR0n6QxrWYpHAAAAAAMEsIjAF0zvnv7ksogabGn\nUW24MzoxvSzQKZXndfcjTzasOooLgaTlVURTM4Xq42zOBgoypvL8YvOl+qVwAAAAAJBmhEcAuqbZ\nsrNI0pKxYqlcrU6qrUaSpPEHTyQ+b20VUf3StmKprGDIdNGmQMW5cuKYWlUbTK32sQAAAACgHxAe\nAeiqRsvOIklLyerVNrYuJ2zbZtKSKqK4pW3lBdem8zZo5sPvaPqcjcKhlfRcAgAAAIB+1/Xd1gCg\nmbhd1ZIUiqWGQZNraXCzmgbZUThUKJbkWgyHoh3d2LkNAAAAwCAiPALQd8ZG8tq/Z1j5DjStrn+M\npEbYrTTIbhYOsXMbAAAAgEHEsjUAfSla3hbXPLtVQca068ot1cfImGneXaZKRVKk1QbZzcIhdm4D\nAAAAMIioPALQ11ZatXPRpkC3/qvL9PCxxV3Y5r0SGXnddfv3DLfUk6hZ1VLccjt2bgMAAACw3hEe\nAehr7VTt5HNZPTtxs56duFkzH36Hjjx1etkys3r/Ul6QVOlnNDoxrW17D2l0Yrrax6hWXDhkqvQ+\nGp2YlqTqcjsLx9NqMAUAAAAA/YplawD62vju7Ut2MJOkYMgkk8rzizVEcRU+rVQtlcrzuuPA8SVL\n2ZJ2SYs+njx8UoViKfY++/cM69G9N7b9eQIAAABAvzL3+O2t+8nOnTv96NGjvR4GgB6Zmilo8vBJ\nnSqWtDWXrYZE9ceicCe6fqW9kiK5bKALzt8Q+xxJvZjyueyKwqO4z5GKJQAAAABrycyOufvOZtdR\neQSg70XNs+OO15uaKSyrVFqpYqmsYqksaXk1Uid3Vqsfc1LlEwAAAAD0Aj2PAAyUycMnOxIcxSmV\n5zV5+KSk5F5Mm7NB248bN+ba5wIAAACAXiI8AjBQVro7W7uPP757e6X3Up1iqax9U7NLjjVrxt3J\nKiYAAAAA6DTCIwADpdXd2bLBkJZHP81tzgbV/kTlhfiecfc99lw1IIqWpBWKJbkWl6TVBkhJY25n\npzkAAAAAWCs0zAYwUFrpeRS3W1urhkzKDFnT+0aNs5Maa9c2496cDfTy2XPLdo/bv2eYnkcAAAAA\n1gwNswGkUhS2RLutZcw07179P5/Lau7sOZ2ZK6/o8RdcWmghdIqWnCUtPattxl0slRUMmS7aFKg4\nV2a3NQAAAAB9hcojAKmzbe8hrfUrX1RZFFd1lCSqVgIAAACAbmi18oieRwBSJ6mX0Ep6IMUJhkwv\nnz3XVnAkqe3rAQAAAKAbWLYGIHXGd29f1hcpG2T07uvyOvLUaZ0qlrQ1l9WuK7fo4WOFhv2TpEpY\ndOHGDTozV1bGLLGRdmTIKsvf6pmkfVOz1TFszgYyE0vZAAAAAPQU4RGA1KntixQFRUnBzM4rLtaH\nHjih+QZLfCf/zTWS1LRRdyQpW3JVdmqLTkc9kaTFXdqqz9nC2AEAAACgE+h5BABNNOqR1GxXtU7L\nZQO9cm5hWdUUO7MBAAAAaBc9jwCgQxr1SBrfvV1S8q5qnVYslZdVN5XK85o8fLIrzw8AAAAgfQiP\nAKCJ8d3blQ0yS46ZpPddf3m12icpYOoWmm0DAAAAWCuERwDQxNhIXvv3DCufy8pUWap27607dM/Y\ncPWauICpXUOr2O7NJE3NFFb1/AAAAAAQh4bZANCCsZF8w55CtU24C8WSMmaad5dJif2SakXXr5SH\nz03fIwAAAACdRsNsAFhDUzOFaqCUFCS1GjC1Is/uawAAAABa1GrDbCqPAGAN1VYs1QZJ7VYmtapQ\nLOmug7PV524mGtOpYklbCZ4AAAAAxKDyCAB6ZHRies0aXedzWT2698Ylx+qDol1XbtHDxwpLdm8L\nhkwXbtyg4lyZMAkAAAAYcK1WHtEwGwB65FSD4CjfZPc2U+MG2/WPPTVT0F0HZ1UoluSqVCjd99hz\nS4IjSSovuM7MlavX3HnguPZNzTb5TAAAAAAMMsIjAOiRrQkBUVQ11ChAckkLDQpH6x978vDJZUFR\nK3WnLum+x55b0U5uUzMFjU5Ma9veQxqdmGY3OAAAAGCdIjwCgB4Z371d2SCz5Fg2yGh89/bE862a\nO3tuSWizmuVxLulDD5xoK/yJq3S66+AsARIAAACwDhEeAUCPjI3ktX/PsPK5rEyViqP9e4arPYbq\nz2eswTq1GpkhW7L07I4Dx1c91nn3tsKfuEqnUnlek4dPrnosAAAAALqLhtkAsE5s23uo4VKzaAe3\ntRTXiFta3ow7qdLJJH174uY1HSMAAACA1rTaMHtDNwYDAFi9pFAmlw30yrmFZZU+a6H2+aPAqFAs\nybTYQ6n+dq2kPk8AAAAA+hfhEQCsE+O7t+uug7NLQqJskJGZOhocBUOVCqakhtw/+p8/L3dXeWHx\nWP2lLi0LkGr7OdWqr1oa3729unQPAAAAQO/R8wgA1omkHknFuXJHn6e84Hr1xiDx/Nn5pcFREpcS\n+zlFaKwNAAAA9D96HgHAOjc6Mb2q3dTWioWlR42qiUY+9kWdiQm/knorAQAAAOgceh4BQEqM796u\nOw8cb9hMu1ZSP6JOi/42USiWNP7gCX30r55Uca5cDZMkxQZHknSqD8MwAAAAIK2oPAKAAbBvalb3\nPfbcklAoColy2UBmqgY3/VCllA0y2hgMJYZHuWygC87fENsHiR5JAAAAQGdQeQQAKXLP2LB2XnFx\nS6FKO8vcssGQSq00OGpTqTzfsMl3sVRWsVQJlqI+SJHapuG15wiQAAAAgLVB5REApEzUpLo2vAmG\nTDKpPL/4npANMtq/Z1iSdPcjT1bDnDhDpsTd2Toln8tKUmzw1ahSCQAAAEA8Ko8AALGiUKW+Sinu\nWHTt2Eg+sWIpH17bTt+llWhULZVUqTQ2kq8ucysUS8qYad69OuaVBkz9unSuX8cFAACA9Y3KIwBA\nS+IqlqLqpLGRfGzfpV7KZQNJalgxddGmQB/5mTe1FbA0+zr0Sr+OCwAAAP2r1cqjoW4MBgCw/o2N\n5LV/z7DyuaxMlYqj2mDinrFh3Xvrjur5XDZQkLGejbe2GinJmbmy7jo4q6mZQsuPO3n45LJ+TaXy\nvCYPn1zRODulX8cFAACA9Y9lawCAlo2N5BtWsdSfr10y1q+igCVu3HHLv04lfC5Jx7ulX8cFAACA\n9Y/wCACwZmrDpJGPfVFn5hpXAvVKbbhVv/yrvofS1lw2NgzbGjb07pV+HRcAAADWP8IjAEBXFPs0\nOIq8fu8h5XNZzZ0913D518uvnFt232yQqTYdjzM1U1iyY91Kei01M757e2zPo0bjAgAAAFpBeAQA\n6IqkyphsMCTJlgU2kmRSVxtwN1peVyiWYneUqw2C4pa7SdL4gydUXli855m5ssYfOiFJTQOkVndQ\nS9pFj2bZAAAAWC12WwMAdEWj3cAk6UMPnNB8zHtSxiz2eD/J57J6/SVZ/e3TLy4Jl4KhytgXEoaf\nz2X16N4bY8/VVytF2EENAAAAndLqbmtUHgEAuqJZZcydB47H3m/evesVSO0qFEuxVUvlpNSo5n7R\nTm+1X5ddV27Rw8cKsd0k6GQAAA6jSURBVNVYcQ2+G2m1cmmt7t+ubj8fAAAAmqPyCADQF0YnpmMD\nmHwYptz32HMrCpAsTJ6G+rSCKRgyyaTy/OLYmoVlJunbEzc3fexG1V6tBDL7pmaXfd3XsvJpteMF\nAABAe1qtPBrqxmAAAGhmfPd2ZYPMkmNRw+d7xoZ17607lM9lZZJy2UBBxlp7YK8ELZ947zXLHr8f\nlBd8SXAkNa+yclXCtqhqaWqmoNGJaW3be0ijE9PaNzWr0Ylp3XHgeMPm341MzRRiA7tW778Sk4dP\nrni8AAAAWDtUHgEA+kY7S5bqr507e05nYnZ0q+0rVHuf/n/3a82mYCg2gGomqug68tTp2K93UiWY\n1HrlU7u27T0UOy9r9XwAAABp12rlEeERAGAgtLvkqVE4kmbR7nFxO8tFGjX6Xo1GSxfX4vkAAADS\njmVrAIBUGRvJa/+e4erStnwu27BXTtwyuWghXMYaL4n75K079HPXX96BUfefM3Nl3XnguDadl7zE\nr1AsNVw2Fx1vV6OliwAAAOgdKo8AAKnVaJlcK1UwUzMF3f3IkyqWKsvlLtoU6KrXvUp/+/SLA7Ms\nbjXy4ddUSt5lr34OGi2lAwAAQGexbA0AgFVYzc5ftYHI5mwgM6k4V66GIyvdOW6QXHBeRjsu27ws\naIv7GseFdB/5mTdJSg6lAAAA0BzhEQAAq9ROA+927JuabStACoZMMrXdFHs9y5hpfoW/o0Th0thI\nvuU5XKu5BgAA6GeERwAA9LEorCgUS9WgpNEyL0lLqm/QGZuCIZXnF1ReWHo8GDJduHFDtWKsE2ES\nARUAAOg3hEcAAAyg+iVxZ8/Nay5MPi7aFOjmq1+nI0+dXhJK5bKBXj57LlWVS+uBSXrf9Zdr5xUX\nx4ZKhE0AAGCtER4BAICqZqHTVa97lR59+sXE+5uU+j5Ng2JTMKTzg8ySqipJsX2lCKsAABhshEcA\nAKAt9Y2ph0xa8MVd08ZG8g37Na2mTxHQDwjNAABp09fhkZndJOl3JGUkfdrdJxpdT3gEAED/aLac\nqj6EkpJ7CwEAAKxHg/IHh74Nj8wsI+mbkt4u6XlJj0u63d2/nnQfwiMAAAZDXKPwXDaQmXRmrlw9\nFv1fu1yuleV1AAAA3RJkTJPvuWZdB0ithkcbujGYOm+W9C13f0aSzOzPJd0iKTE8AgAAg2FsJN+R\nXcvi+vNIqgZT9T2aNgVDklTt8wQAALBa5XnX5OGT6zo8alUvwqO8pO/W3H5e0o/XX2RmH5D0AUm6\n/PLLuzMyAADQ9xoFUO388ha3/E5a2jia0AkAADRyqljq9RC6ohfhUUvc/VOSPiVVlq31eDgAAGDA\nJIVQnf7rYX1ItevKLfrcie8ta0yetKMdARYAAP1ray7b6yF0RS/Co4Kky2puXxoeAwAAGDhxIdU9\nY8M9GUttz6nasCoKsGr7TyWFWQAAoCLIWLVyedD1Ijx6XNIbzWybKqHRbZL+bQ/GAQAAkCqd6Dk1\nqOJ2CQQAIMmg7LbWqq6HR+5+zsx+RdJhSRlJn3X3J7s9DgAAACBCsAYAQLKe9Dxy989L+nwvnhsA\nAAAAAACtG+r1AAAAAAAAANC/CI8AAAAAAACQiPAIAAAAAAAAiQiPAAAAAAAAkIjwCAAAAAAAAIkI\njwAAAAAAAJCI8AgAAAAAAACJCI8AAAAAAACQiPAIAAAAAAAAiQiPAAAAAAAAkIjwCAAAAAAAAIkI\njwAAAAAAAJCI8AgAAAAAAACJCI8AAAAAAACQiPAIAAAAAAAAiQiPAAAAAAAAkIjwCAAAAAAAAIkI\njwAAAAAAAJCI8AgAAAAAAACJzN17PYamzOy0pO/0ehwd8hpJP+j1INB1zHt6MffpxdynF3OfXsx9\nejH36cS8p9cgzf0V7r6l2UXrIjwaJGZ21N139noc6C7mPb2Y+/Ri7tOLuU8v5j69mPt0Yt7TK41z\nz7I1AAAAAAAAJCI8AgAAAAAAQCLCo+77VK8HgJ5g3tOLuU8v5j69mPv0Yu7Ti7lPJ+Y9vVI39/Q8\nAgAAAAAAQCIqjwAAAAAAAJCI8AgAAAAAAACJCI+6xMxuMrOTZvYtM9vb6/Ggs8zss2b2gpl9rebY\nxWb2JTP7h/D/i8LjZma/G34vfNXMru3dyLFaZnaZmR0xs6+b2ZNm9mvhceZ/gJnZRjP7ezM7Ec77\nR8Pj28zsK+H8HjCz88Lj54e3vxWef30vx4/VM7OMmc2Y2efC28x9CpjZs2Y2a2bHzexoeIzX+xQw\ns5yZPWRmT5nZN8zsLcz94DOz7eHPe/Tvh2Z2B3M/+MzszvB3vK+Z2f3h736pfq8nPOoCM8tI+n1J\nPyXpKkm3m9lVvR0VOuwPJd1Ud2yvpC+7+xslfTm8LVW+D94Y/vuApD/o0hixNs5J+pC7XyXpekkf\nDH++mf/B9oqkG939Gkk7JN1kZtdL+i1J97r7j0g6I+mXwut/SdKZ8Pi94XVY335N0jdqbjP36bHL\n3Xe4+87wNq/36fA7kr7g7ldKukaVn3/mfsC5+8nw532HpOskzUn6CzH3A83M8pJ+VdJOd/8xSRlJ\ntynl7/WER93xZknfcvdn3P2spD+XdEuPx4QOcve/lvRi3eFbJP1R+PEfSRqrOf7HXvGYpJyZva47\nI0Wnufv33P2J8ON/UuWXybyY/4EWzt8/hzeD8J9LulHSQ+Hx+nmPvh8ekvQ2M7MuDRcdZmaXSrpZ\n0qfD2ybmPs14vR9wZrZZ0k9I+owkuftZdy+KuU+bt0l62t2/I+Y+DTZIyprZBkmbJH1PKX+vJzzq\njryk79bcfj48hsH2Wnf/XvjxP0p6bfgx3w8DKixRHZH0FTH/Ay9ctnRc0guSviTpaUlFdz8XXlI7\nt9V5D8+/JOmS7o4YHfRJSb8haSG8fYmY+7RwSV80s2Nm9oHwGK/3g2+bpNOS/le4XPXTZnaBmPu0\nuU3S/eHHzP0Ac/eCpP8u6TlVQqOXJB1Tyt/rCY+ALnB3V+UXTgwoM7tQ0sOS7nD3H9aeY/4Hk7vP\nh2Xsl6pSYXplj4eELjCzn5b0grsf6/VY0BNvdfdrVVma8kEz+4nak7zeD6wNkq6V9AfuPiLpZS0u\nU5LE3A+6sLfNuyQ9WH+OuR88YQ+rW1QJjrdKukDLW5SkDuFRdxQkXVZz+9LwGAbb96My1fD/F8Lj\nfD8MGDMLVAmO7nP3g+Fh5j8lwqULRyS9RZXy9A3hqdq5rc57eH6zpP/X5aGiM0YlvcvMnlVlGfqN\nqvRCYe5TIPxrtNz9BVX6nrxZvN6nwfOSnnf3r4S3H1IlTGLu0+OnJD3h7t8PbzP3g+0nJX3b3U+7\ne1nSQVXe/1P9Xk941B2PS3pj2J39PFVKHh/p8Ziw9h6R9P7w4/dL+sua478Q7sZwvaSXaspesc6E\n65k/I+kb7v7bNaeY/wFmZlvMLBd+nJX0dlX6XR2R9J7wsvp5j74f3iNpOvxLJdYZd7/L3S9199er\n8n4+7e7vE3M/8MzsAjN7VfSxpHdI+pp4vR947v6Pkr5rZtvDQ2+T9HUx92lyuxaXrEnM/aB7TtL1\nZrYp/F0/+plP9Xu9DeDn1JfM7J2q9EjISPqsu3+8x0NCB5nZ/ZJukPQaSd+X9BFJU5IekHS5pO9I\neq+7vxi+AP2eKqWPc5J+0d2P9mLcWD0ze6ukv5E0q8X+J7+pSt8j5n9AmdnVqjRGzKjyh5gH3P1j\nZvYGVapRLpY0I+nn3P0VM9so6U9U6Yn1oqTb3P2Z3owenWJmN0j6dXf/aeZ+8IVz/BfhzQ2S/szd\nP25ml4jX+4FnZjtUaZJ/nqRnJP2iwtd/MfcDLQyLn5P0Bnd/KTzGz/2AM7OPSrpVlZ2VZyT9e1V6\nG6X2vZ7wCAAAAAAAAIlYtgYAAAAAAIBEhEcAAAAAAABIRHgEAAAAAACARIRHAAAAAAAASER4BAAA\nAAAAgESERwAAYOCZ2WvN7M/M7BkzO2Zmf2dmPxueu8HMPtfk/neb2a+3+Zz/3Ma1d5jZpnYeHwAA\noFsIjwAAwEAzM5M0Jemv3f0N7n6dpNskXdrbkS1xhyTCIwAA0JcIjwAAwKC7UdJZd/+f0QF3/467\n/4/6C83sYjObMrOvmtljZnZ1zelrwoqlfzCz/xBef6GZfdnMnjCzWTO7pdFAzOwCMztkZifM7Gtm\ndquZ/aqkrZKOmNmR8Lp3hM/1hJk9aGYXhsefNbP/Fj7X35vZj6z+ywMAANAY4REAABh0b5L0RIvX\nflTSjLtfLek3Jf1xzbmrVQmi3iLpw2a2VdK/SPpZd79W0i5JnwgrnZLcJOmUu1/j7j8m6Qvu/ruS\nTkna5e67zOw1kvZJ+snwcY9K+o81j/GSuw9L+j1Jn2zx8wIAAFgxwiMAAJAqZvb7YeXP4zGn3yrp\nTyTJ3aclXWJmrw7P/aW7l9z9B5KOSHqzJJP0X83sq5L+t6S8pNc2ePpZSW83s98ys3/t7i/FXHO9\npKskPWpmxyW9X9IVNefvr/n/LS18ygAAAKuyodcDAAAAWGNPSnp3dMPdPxhW9xxt83E85vb7JG2R\ndJ27l83sWUkbEx/A/Ztmdq2kd0q6x8y+7O4fq7vMJH3J3W9vYRz1YwIAAOg4Ko8AAMCgm5a00cx+\nueZYUnPqv1ElEJKZ3SDpB+7+w/DcLWa20cwukXSDpMclbZb0Qhgc7dLSCqFlwqVuc+7+p5ImJV0b\nnvonSa8KP35M0mjUzyjsk/SjNQ9za83/f9fo+QAAADqByiMAADDQ3N3NbEzSvWb2G5JOS3pZ0n+K\nufxuSZ8Nl6HNqbJkLPJVVZarvUbSf3H3U2Z2n6S/MrNZVSqZnmoynGFJk2a2IKksKQq0PiXpC2Z2\nKux79O8k3W9m54fn90n6ZvjxReH4XpGUVJ0EAADQMeZOtTMAAMB6EC6L2xn2XQIAAOgKlq0BAAAA\nAAAgEZVHAAAAAAAASETlEQAAAAAAABIRHgEAAAAAACAR4REAAAAAAAASER4BAAAAAAAgEeERAAAA\nAAAAEv1/+C/ydq413tIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO Hi this is Jaemin . . . . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO Nice to meet you too ! ! ! !\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO I like Python . . . . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO Bye Bye . . . . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO I live in Seoul , South Korea . .\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO I study industrial engineering . . . . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO Beer please ! ! ! ! ! . .\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO Leffe brown ! ! ! . . . .\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}_sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better performance than without scheduled sampling!\n",
    "- A word of caution: http://www.inference.vc/scheduled-sampling-for-rnns-scoring-rule-interpretation/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
