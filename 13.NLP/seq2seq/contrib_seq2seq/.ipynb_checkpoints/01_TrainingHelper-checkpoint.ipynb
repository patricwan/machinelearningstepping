{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Checkpoint Path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            enc_outputs, self.enc_last_state= tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "        \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')\n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "            \n",
    "                batch_size = tf.shape(self.enc_inputs)[0:1]\n",
    "                start_tokens = tf.zeros(batch_size, dtype=tf.int32)\n",
    "            \n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=1)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print(f'Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "              load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "                print(\"input_batch_tokens \" , input_batch_tokens)\n",
    "                print(\"enc_sentence_lengths \", enc_sentence_lengths)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "                print(\"target_batch_tokens \" , target_batch_tokens)\n",
    "                print(\"dec_sentence_lengths \", dec_sentence_lengths)\n",
    "    \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print(f'\\tInput: {input_sent}')\n",
    "                        print(f'\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print(f'\\tTarget:, {target_sent}')\n",
    "                print(f'\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "        \n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "        \n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "        \n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/801 [00:00<04:39,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: ! in Python Hi Python Python _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: ! ! ! ! Hi Hi Beer\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: ! ! ! Python Hi\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: ! Python Python Python _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: ! ! ! Beer Beer Beer Beer Beer Hi\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: ! ! Hi Hi Hi Hi _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: ! ! ! !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: ! ! Hi Hi\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 13.49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 405/801 [00:08<00:07, 51.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:16<00:00, 48.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Saving model at ./ckpt_dir/epoch_801\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSZJGMjySJEmSJEnSSP8PRGUAhHPOC+UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO _GO Hi this is is Jaemin Jaemin . .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO _GO Nice to to you you you too too\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO _GO I I like Python Python . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO _GO Bye Bye Bye Bye . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO _GO I I study industrial engineering Korea Korea Korea\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO _GO I I study industrial engineering engineering engineering .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO _GO Beer please please ! ! ! ! !\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO _GO Leffe Leffe brown industrial . . . .\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem:\n",
    "\n",
    "### Prediction during training was good enough, but the performance went poor during inference.\n",
    "\n",
    "### There is a discrepancy between during training and inference\n",
    "#### - Training: decoder inputs are ground truth tokens.\n",
    "#### - Inference: decoder inputs are token generated by the model itself.\n",
    "#### => First few poorly generated tokens can guide the model in wrong way.\n",
    "\n",
    "## We can solve this issue with '[Scheduled Sampling with Curriculm learning](https://arxiv.org/abs/1506.03099)'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
