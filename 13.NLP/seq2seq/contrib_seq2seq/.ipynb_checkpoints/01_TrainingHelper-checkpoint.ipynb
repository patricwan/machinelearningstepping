{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Checkpoint Path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            enc_outputs, self.enc_last_state= tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "        \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')\n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "            \n",
    "                batch_size = tf.shape(self.enc_inputs)[0:1]\n",
    "                start_tokens = tf.zeros(batch_size, dtype=tf.int32)\n",
    "            \n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=1)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print(f'Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "              load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print(f'\\tInput: {input_sent}')\n",
    "                        print(f'\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print(f'\\tTarget:, {target_sent}')\n",
    "                print(f'\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "        \n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "        \n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "        \n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e1b83930d5f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDemoConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeq2SeqModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# model.summary()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training model built!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-41f10ab28dc7>\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_placeholders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     def train(self, sess, data, from_scratch=False,\n",
      "\u001b[1;32m<ipython-input-12-41f10ab28dc7>\u001b[0m in \u001b[0;36madd_decoder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[0moutput_time_major\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[0mimpute_finished\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                     maximum_iterations=max_dec_len)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;31m# dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/801 [00:00<01:27,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: , , , , , please _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: , , , , , , ,\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: , , , , ,\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: South , , , _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: , , , , is is please is is\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: , , , , , please _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: , , , ,\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: , , , ,\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 13.75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 403/801 [00:28<00:29, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:56<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Saving model at ./ckpt_dir/epoch_801\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQP8PZ4LfGcl8eGgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116e04128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/epoch_801\n",
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO _GO Hi Hi this is Jaemin Jaemin Jaemin .\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO _GO _GO Nice to to meet meet you you\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/epoch_801\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO _GO _GO _GO _GO please please please ! !\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO _GO _GO _GO _GO _GO _GO _GO _GO _GO\n",
      "Target: Bye Bye. \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/epoch_801\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO _GO _GO _GO _GO meet meet meet meet you\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO _GO _GO study study study engineering engineering . .\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/epoch_801\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO _GO _GO _GO please please please ! ! !\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO _GO _GO _GO _GO brown brown brown ! !\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem:\n",
    "\n",
    "### Prediction during training was good enough, but the performance went poor during inference.\n",
    "\n",
    "### There is a discrepancy between during training and inference\n",
    "#### - Training: decoder inputs are ground truth tokens.\n",
    "#### - Inference: decoder inputs are token generated by the model itself.\n",
    "#### => First few poorly generated tokens can guide the model in wrong way.\n",
    "\n",
    "## We can solve this issue with '[Scheduled Sampling with Curriculm learning](https://arxiv.org/abs/1506.03099)'!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
