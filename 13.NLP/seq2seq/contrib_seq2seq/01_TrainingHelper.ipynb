{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot learning curve graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for pretty print\n",
    "from pprint import pprint\n",
    "\n",
    "# for tokenizer\n",
    "import re\n",
    "\n",
    "# for word counter in vocabulary dictionary\n",
    "from collections import Counter\n",
    "\n",
    "# for checkpoint paths\n",
    "import os\n",
    "\n",
    "# for fancy progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# for output_projection\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maximum length of input and target sentences including paddings\n",
    "enc_sentence_length = 10\n",
    "dec_sentence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch_size: 2\n",
    "input_batches = [\n",
    "    ['Hi What is your name?', 'Nice to meet you!'],\n",
    "    ['Which programming language do you use?', 'See you later.'],\n",
    "    ['Where do you live?', 'What is your major?'],\n",
    "    ['What do you want to drink?', 'What is your favorite beer?']]\n",
    "\n",
    "target_batches = [\n",
    "    ['Hi this is Jaemin.', 'Nice to meet you too!'],\n",
    "    ['I like Python.', 'Bye Bye.'],\n",
    "    ['I live in Seoul, South Korea.', 'I study industrial engineering.'],\n",
    "    ['Beer please!', 'Leffe brown!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi What is your name?',\n",
       " 'Nice to meet you!',\n",
       " 'Which programming language do you use?',\n",
       " 'See you later.',\n",
       " 'Where do you live?',\n",
       " 'What is your major?',\n",
       " 'What do you want to drink?',\n",
       " 'What is your favorite beer?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_sentences = []\n",
    "for input_batch in input_batches:\n",
    "    all_input_sentences.extend(input_batch)\n",
    "    \n",
    "all_target_sentences = []\n",
    "for target_batch in target_batches:\n",
    "    all_target_sentences.extend(target_batch)\n",
    "\n",
    "# Example\n",
    "all_input_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '?', '?', '\"', 'sdfs', '%', '@', '#', '%']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(sentence):\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\s\\w]\", sentence)\n",
    "    return tokens\n",
    "\n",
    "# Example\n",
    "tokenizer('Hello world?? \"sdfs%@#%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'!': 12,\n",
      "  '.': 19,\n",
      "  '?': 1,\n",
      "  'Hi': 8,\n",
      "  'Nice': 10,\n",
      "  'See': 17,\n",
      "  'What': 3,\n",
      "  'Where': 20,\n",
      "  'Which': 13,\n",
      "  '_PAD': 0,\n",
      "  'beer': 26,\n",
      "  'do': 6,\n",
      "  'drink': 24,\n",
      "  'favorite': 25,\n",
      "  'is': 4,\n",
      "  'language': 15,\n",
      "  'later': 18,\n",
      "  'live': 21,\n",
      "  'major': 22,\n",
      "  'meet': 11,\n",
      "  'name': 9,\n",
      "  'programming': 14,\n",
      "  'to': 7,\n",
      "  'use': 16,\n",
      "  'want': 23,\n",
      "  'you': 2,\n",
      "  'your': 5},\n",
      " {0: '_PAD',\n",
      "  1: '?',\n",
      "  2: 'you',\n",
      "  3: 'What',\n",
      "  4: 'is',\n",
      "  5: 'your',\n",
      "  6: 'do',\n",
      "  7: 'to',\n",
      "  8: 'Hi',\n",
      "  9: 'name',\n",
      "  10: 'Nice',\n",
      "  11: 'meet',\n",
      "  12: '!',\n",
      "  13: 'Which',\n",
      "  14: 'programming',\n",
      "  15: 'language',\n",
      "  16: 'use',\n",
      "  17: 'See',\n",
      "  18: 'later',\n",
      "  19: '.',\n",
      "  20: 'Where',\n",
      "  21: 'live',\n",
      "  22: 'major',\n",
      "  23: 'want',\n",
      "  24: 'drink',\n",
      "  25: 'favorite',\n",
      "  26: 'beer'},\n",
      " 26)\n",
      "\n",
      "\n",
      "({'!': 2,\n",
      "  ',': 19,\n",
      "  '.': 1,\n",
      "  'Beer': 25,\n",
      "  'Bye': 4,\n",
      "  'Hi': 5,\n",
      "  'I': 3,\n",
      "  'Jaemin': 8,\n",
      "  'Korea': 21,\n",
      "  'Leffe': 27,\n",
      "  'Nice': 9,\n",
      "  'Python': 15,\n",
      "  'Seoul': 18,\n",
      "  'South': 20,\n",
      "  '_PAD': 0,\n",
      "  'brown': 28,\n",
      "  'engineering': 24,\n",
      "  'in': 17,\n",
      "  'industrial': 23,\n",
      "  'is': 7,\n",
      "  'like': 14,\n",
      "  'live': 16,\n",
      "  'meet': 11,\n",
      "  'please': 26,\n",
      "  'study': 22,\n",
      "  'this': 6,\n",
      "  'to': 10,\n",
      "  'too': 13,\n",
      "  'you': 12},\n",
      " {0: '_PAD',\n",
      "  1: '.',\n",
      "  2: '!',\n",
      "  3: 'I',\n",
      "  4: 'Bye',\n",
      "  5: 'Hi',\n",
      "  6: 'this',\n",
      "  7: 'is',\n",
      "  8: 'Jaemin',\n",
      "  9: 'Nice',\n",
      "  10: 'to',\n",
      "  11: 'meet',\n",
      "  12: 'you',\n",
      "  13: 'too',\n",
      "  14: 'like',\n",
      "  15: 'Python',\n",
      "  16: 'live',\n",
      "  17: 'in',\n",
      "  18: 'Seoul',\n",
      "  19: ',',\n",
      "  20: 'South',\n",
      "  21: 'Korea',\n",
      "  22: 'study',\n",
      "  23: 'industrial',\n",
      "  24: 'engineering',\n",
      "  25: 'Beer',\n",
      "  26: 'please',\n",
      "  27: 'Leffe',\n",
      "  28: 'brown'},\n",
      " 28)\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, is_target=False, max_vocab_size=None):\n",
    "    word_counter = Counter()\n",
    "    vocab = dict()\n",
    "    reverse_vocab = dict()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        word_counter.update(tokens)\n",
    "        \n",
    "    if max_vocab_size is None:\n",
    "        max_vocab_size = len(word_counter)\n",
    "    \n",
    "    if is_target:\n",
    "        vocab['_GO'] = 0\n",
    "        vocab['_PAD'] = 1\n",
    "        vocab_idx = 2\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "    else:\n",
    "        vocab['_PAD'] = 0\n",
    "        vocab_idx = 1\n",
    "        for key, value in word_counter.most_common(max_vocab_size):\n",
    "            vocab[key] = vocab_idx\n",
    "            vocab_idx += 1\n",
    "            \n",
    "    for key, value in vocab.items():\n",
    "        reverse_vocab[value] = key\n",
    "            \n",
    "    return vocab, reverse_vocab, max_vocab_size\n",
    "\n",
    "# Example\n",
    "pprint(build_vocab(all_input_sentences))\n",
    "print('\\n')\n",
    "pprint(build_vocab(all_target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocabulary size: 26\n",
      "target vocabulary size: 28\n"
     ]
    }
   ],
   "source": [
    "enc_vocab, enc_reverse_vocab, enc_vocab_size = build_vocab(all_input_sentences)\n",
    "dec_vocab, dec_reverse_vocab, dec_vocab_size = build_vocab(all_target_sentences, is_target=True)\n",
    "\n",
    "print('input vocabulary size:', enc_vocab_size)\n",
    "print('target vocabulary size:', dec_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice 10\n",
      "to 7\n",
      "meet 11\n",
      "you 2\n",
      "! 12\n"
     ]
    }
   ],
   "source": [
    "def token2idx(word, vocab):\n",
    "    return vocab[word]\n",
    "\n",
    "for token in tokenizer('Nice to meet you!'):\n",
    "    print(token, token2idx(token, enc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi What is your name?\n",
      "([8, 3, 4, 5, 9, 1, 0, 0, 0, 0], 6)\n",
      "Hi this is Jaemin.\n",
      "([0, 6, 7, 8, 9, 2, 1, 1, 1, 1, 1], 5)\n"
     ]
    }
   ],
   "source": [
    "def sent2idx(sent, vocab=enc_vocab, max_sentence_length=enc_sentence_length, is_target=False):\n",
    "    tokens = tokenizer(sent)\n",
    "    current_length = len(tokens)\n",
    "    pad_length = max_sentence_length - current_length\n",
    "    if is_target:\n",
    "        return [0] + [token2idx(token, vocab) for token in tokens] + [1] * pad_length, current_length\n",
    "    else:\n",
    "        return [token2idx(token, vocab) for token in tokens] + [0] * pad_length, current_length\n",
    "\n",
    "# Enc Example\n",
    "print('Hi What is your name?')\n",
    "print(sent2idx('Hi What is your name?'))\n",
    "\n",
    "# Dec Example\n",
    "print('Hi this is Jaemin.')\n",
    "print(sent2idx('Hi this is Jaemin.', vocab=dec_vocab, max_sentence_length=dec_sentence_length, is_target=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2token(idx, reverse_vocab):\n",
    "    return reverse_vocab[idx]\n",
    "\n",
    "def idx2sent(indices, reverse_vocab=dec_reverse_vocab):\n",
    "    return \" \".join([idx2token(idx, reverse_vocab) for idx in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DemoConfig:\n",
    "    \n",
    "    # Model\n",
    "    hidden_size = 30\n",
    "    enc_emb_size = 30\n",
    "    dec_emb_size = 30\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell\n",
    "    \n",
    "    # Training\n",
    "    optimizer = tf.train.RMSPropOptimizer\n",
    "    n_epoch = 801\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Checkpoint Path\n",
    "    ckpt_dir = './ckpt_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, mode='training'):\n",
    "        assert mode in ['training', 'evaluation', 'inference']\n",
    "        self.mode = mode\n",
    "\n",
    "        # Model\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.enc_emb_size = config.enc_emb_size\n",
    "        self.dec_emb_size = config.dec_emb_size\n",
    "        self.cell = config.cell\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = config.optimizer\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.learning_rate = config.learning_rate\n",
    "        \n",
    "        # Checkpoint Path\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        \n",
    "    def add_placeholders(self):\n",
    "        self.enc_inputs = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, enc_sentence_length],\n",
    "            name='input_sentences')\n",
    "\n",
    "        self.enc_sequence_length = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None,],\n",
    "            name='input_sequence_length')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.dec_inputs = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, dec_sentence_length+1],\n",
    "                name='target_sentences')\n",
    "\n",
    "            self.dec_sequence_length = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None,],\n",
    "                name='target_sequence_length')\n",
    "            \n",
    "    def add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.enc_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([enc_vocab_size+1, self.enc_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            # [Batch_size x enc_sent_len x embedding_size]\n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                self.enc_Wemb, self.enc_inputs, name='emb_inputs')\n",
    "            enc_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # enc_outputs: [batch_size x enc_sent_len x embedding_size]\n",
    "            # enc_last_state: [batch_size x embedding_size]\n",
    "            enc_outputs, self.enc_last_state= tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell,\n",
    "                inputs=enc_emb_inputs,\n",
    "                sequence_length=self.enc_sequence_length,\n",
    "                time_major=False,\n",
    "                dtype=tf.float32)\n",
    "            \n",
    "    def add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            with tf.device('/cpu:0'):\n",
    "                self.dec_Wemb = tf.get_variable('embedding',\n",
    "                    initializer=tf.random_uniform([dec_vocab_size+2, self.dec_emb_size]),\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "            dec_cell = self.cell(self.hidden_size)\n",
    "\n",
    "            # output projection (replacing `OutputProjectionWrapper`)\n",
    "            output_layer = Dense(dec_vocab_size+2, name='output_projection')\n",
    "            \n",
    "            if self.mode == 'training':\n",
    "\n",
    "                # maxium unrollings in current batch = max(dec_sent_len) + 1(GO symbol)\n",
    "                max_dec_len = tf.reduce_max(self.dec_sequence_length+1, name='max_dec_len')\n",
    "\n",
    "                dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "                    self.dec_Wemb, self.dec_inputs, name='emb_inputs')\n",
    "        \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                    inputs=dec_emb_inputs,\n",
    "                    sequence_length=self.dec_sequence_length+1,\n",
    "                    time_major=False,\n",
    "                    name='training_helper')\n",
    "\n",
    "                training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=training_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer) \n",
    "\n",
    "                train_dec_outputs, train_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    training_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=max_dec_len)\n",
    "                \n",
    "                # dec_outputs: collections.namedtuple(rnn_outputs, sample_id)\n",
    "                # dec_outputs.rnn_output: [batch_size x max(dec_sequence_len) x dec_vocab_size+2], tf.float32\n",
    "                # dec_outputs.sample_id [batch_size], tf.int32\n",
    "                \n",
    "                # logits: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                logits = tf.identity(train_dec_outputs.rnn_output, name='logits')\n",
    "                \n",
    "                # targets: [batch_size x max_dec_len x dec_vocab_size+2]\n",
    "                targets = tf.slice(self.dec_inputs, [0, 0], [-1, max_dec_len], 'targets')\n",
    "                \n",
    "                # masks: [batch_size x max_dec_len]\n",
    "                # => ignore outputs after `dec_senquence_length+1` when calculating loss\n",
    "                masks = tf.sequence_mask(self.dec_sequence_length+1, max_dec_len, dtype=tf.float32, name='masks')\n",
    "                \n",
    "                # Control loss dimensions with `average_across_timesteps` and `average_across_batch`\n",
    "                # internal: `tf.nn.sparse_softmax_cross_entropy_with_logits`\n",
    "                self.batch_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                    logits=logits,\n",
    "                    targets=targets,\n",
    "                    weights=masks,\n",
    "                    name='batch_loss')\n",
    "                \n",
    "                # prediction sample for validation\n",
    "                self.valid_predictions = tf.identity(train_dec_outputs.sample_id, name='valid_preds')\n",
    "\n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "            \n",
    "            elif self.mode == 'inference':\n",
    "            \n",
    "                batch_size = tf.shape(self.enc_inputs)[0:1]\n",
    "                start_tokens = tf.zeros(batch_size, dtype=tf.int32)\n",
    "            \n",
    "                inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=self.dec_Wemb,\n",
    "                    start_tokens=start_tokens,\n",
    "                    end_token=1)\n",
    "                \n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=dec_cell,\n",
    "                    helper=inference_helper,\n",
    "                    initial_state=self.enc_last_state,\n",
    "                    output_layer=output_layer)\n",
    "                \n",
    "                infer_dec_outputs, infer_dec_last_state,_ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    inference_decoder,\n",
    "                    output_time_major=False,\n",
    "                    impute_finished=True,\n",
    "                    maximum_iterations=dec_sentence_length)\n",
    "                \n",
    "                # [batch_size x dec_sentence_length], tf.int32\n",
    "                self.predictions = tf.identity(infer_dec_outputs.sample_id, name='predictions')\n",
    "                # equivalent to tf.argmax(infer_dec_outputs.rnn_output, axis=2, name='predictions')\n",
    "                \n",
    "                # List of training variables\n",
    "                # self.training_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        \n",
    "    def add_training_op(self):\n",
    "        self.training_op = self.optimizer(self.learning_rate, name='training_op').minimize(self.batch_loss)\n",
    "        \n",
    "    def save(self, sess, var_list=None, save_path=None):\n",
    "        print(f'Saving model at {save_path}')\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, save_path, write_meta_graph=False)\n",
    "        \n",
    "    def restore(self, sess, var_list=None, ckpt_path=None):\n",
    "        if hasattr(self, 'training_variables'):\n",
    "            var_list = self.training_variables\n",
    "        self.restorer = tf.train.Saver(var_list)\n",
    "        self.restorer.restore(sess, ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.ckpt_dir,\n",
    "            graph=tf.get_default_graph())\n",
    "        \n",
    "    def build(self):\n",
    "        self.add_placeholders()\n",
    "        self.add_encoder()\n",
    "        self.add_decoder()\n",
    "\n",
    "    def train(self, sess, data, from_scratch=False,\n",
    "              load_ckpt=None, save_path=None):\n",
    "        \n",
    "        # Restore Checkpoint\n",
    "        if from_scratch is False and os.path.isfile(load_ckpt):\n",
    "            self.restore(sess, load_ckpt)\n",
    "    \n",
    "        # Add Optimizer to current graph\n",
    "        self.add_training_op()\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        input_batches, target_batches = data\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in tqdm(range(self.n_epoch)):\n",
    "\n",
    "            all_preds = []\n",
    "            epoch_loss = 0\n",
    "            for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "                input_batch_tokens = []\n",
    "                target_batch_tokens = []\n",
    "                enc_sentence_lengths = []\n",
    "                dec_sentence_lengths = []\n",
    "\n",
    "                for input_sent in input_batch:\n",
    "                    tokens, sent_len = sent2idx(input_sent)\n",
    "                    input_batch_tokens.append(tokens)\n",
    "                    enc_sentence_lengths.append(sent_len)\n",
    "\n",
    "                for target_sent in target_batch:\n",
    "                    tokens, sent_len = sent2idx(target_sent,\n",
    "                                 vocab=dec_vocab,\n",
    "                                 max_sentence_length=dec_sentence_length,\n",
    "                                 is_target=True)\n",
    "                    target_batch_tokens.append(tokens)\n",
    "                    dec_sentence_lengths.append(sent_len)\n",
    "       \n",
    "                # Evaluate 3 ops in the graph\n",
    "                # => valid_predictions, loss, training_op(optimzier)\n",
    "                batch_preds, batch_loss, _ = sess.run(\n",
    "                    [self.valid_predictions, self.batch_loss, self.training_op],\n",
    "                    feed_dict={\n",
    "                        self.enc_inputs: input_batch_tokens,\n",
    "                        self.enc_sequence_length: enc_sentence_lengths,\n",
    "                        self.dec_inputs: target_batch_tokens,\n",
    "                        self.dec_sequence_length: dec_sentence_lengths,\n",
    "                    })\n",
    "                # loss_history.append(batch_loss)\n",
    "                epoch_loss += batch_loss\n",
    "                all_preds.append(batch_preds)\n",
    "                \n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            # Logging every 400 epochs\n",
    "            if epoch % 400 == 0:\n",
    "                print('Epoch', epoch)\n",
    "                for input_batch, target_batch, batch_preds in zip(input_batches, target_batches, all_preds):\n",
    "                    for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "                        print(f'\\tInput: {input_sent}')\n",
    "                        print(f'\\tPrediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "                        print(f'\\tTarget:, {target_sent}')\n",
    "                print(f'\\tepoch loss: {epoch_loss:.2f}\\n')\n",
    "                \n",
    "        if save_path:\n",
    "            self.save(sess, save_path=save_path)\n",
    "\n",
    "        return loss_history\n",
    "    \n",
    "    def inference(self, sess, data, load_ckpt):\n",
    "        \n",
    "        self.restore(sess, ckpt_path=load_ckpt)\n",
    "        \n",
    "        input_batch, target_batch = data\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_tokens = []\n",
    "        batch_sent_lens = []\n",
    "        \n",
    "        for input_sent in input_batch:\n",
    "            tokens, sent_len = sent2idx(input_sent)\n",
    "            batch_tokens.append(tokens)\n",
    "            batch_sent_lens.append(sent_len)\n",
    "            \n",
    "        batch_preds = sess.run(\n",
    "            self.predictions,\n",
    "            feed_dict={\n",
    "                self.enc_inputs: batch_tokens,\n",
    "                self.enc_sequence_length: batch_sent_lens,\n",
    "            })\n",
    "\n",
    "        for input_sent, target_sent, pred in zip(input_batch, target_batch, batch_preds):\n",
    "            print('Input:', input_sent)\n",
    "            print('Prediction:', idx2sent(pred, reverse_vocab=dec_reverse_vocab))\n",
    "            print('Target:', target_sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if models are correctly built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='training')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Training model built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model built!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "config = DemoConfig()\n",
    "model = Seq2SeqModel(config, mode='inference')\n",
    "model.build()\n",
    "# model.summary()\n",
    "print('Inference model built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/801 [00:00<03:52,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: meet meet meet meet meet meet _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: Leffe meet meet meet meet brown brown\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: Leffe meet meet meet meet\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: meet meet meet meet _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: meet meet meet brown brown brown brown brown brown\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: meet meet meet meet meet brown _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: meet meet meet meet\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: meet meet meet meet\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 13.62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 409/801 [00:08<00:06, 58.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:16<00:00, 49.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800\n",
      "\tInput: Hi What is your name?\n",
      "\tPrediction: _GO Hi this is Jaemin . _GO\n",
      "\tTarget:, Hi this is Jaemin.\n",
      "\tInput: Nice to meet you!\n",
      "\tPrediction: _GO Nice to meet you too !\n",
      "\tTarget:, Nice to meet you too!\n",
      "\tInput: Which programming language do you use?\n",
      "\tPrediction: _GO I like Python .\n",
      "\tTarget:, I like Python.\n",
      "\tInput: See you later.\n",
      "\tPrediction: _GO Bye Bye . _GO\n",
      "\tTarget:, Bye Bye.\n",
      "\tInput: Where do you live?\n",
      "\tPrediction: _GO I live in Seoul , South Korea .\n",
      "\tTarget:, I live in Seoul, South Korea.\n",
      "\tInput: What is your major?\n",
      "\tPrediction: _GO I study industrial engineering . _GO _GO _GO\n",
      "\tTarget:, I study industrial engineering.\n",
      "\tInput: What do you want to drink?\n",
      "\tPrediction: _GO Beer please !\n",
      "\tTarget:, Beer please!\n",
      "\tInput: What is your favorite beer?\n",
      "\tPrediction: _GO Leffe brown !\n",
      "\tTarget:, Leffe brown!\n",
      "\tepoch loss: 0.00\n",
      "\n",
      "Saving model at ./ckpt_dir/epoch_801\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()     \n",
    "with tf.Session() as sess:\n",
    "    config = DemoConfig()\n",
    "    model = Seq2SeqModel(config, mode='training')\n",
    "    model.build()\n",
    "    data = (input_batches, target_batches)\n",
    "    loss_history = model.train(sess, data, from_scratch=True, save_path=model.ckpt_dir+f'epoch_{model.n_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAJcCAYAAABwj4S5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyz3clgobAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(model.n_epoch), loss_history)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Global step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore Finished!\n",
      "Input: Hi What is your name?\n",
      "Prediction: _GO _GO _GO study study industrial industrial industrial engineering engineering\n",
      "Target: Hi this is Jaemin. \n",
      "\n",
      "Input: Nice to meet you!\n",
      "Prediction: _GO _GO Nice to to you you too too too\n",
      "Target: Nice to meet you too! \n",
      "\n",
      "Restore Finished!\n",
      "Input: Which programming language do you use?\n",
      "Prediction: _GO _GO I I like Python Python . . .\n",
      "Target: I like Python. \n",
      "\n",
      "Input: See you later.\n",
      "Prediction: _GO _GO Bye Bye Bye Bye . . . .\n",
      "Target: Bye Bye. \n",
      "\n",
      "Restore Finished!\n",
      "Input: Where do you live?\n",
      "Prediction: _GO _GO _GO live live in in , , ,\n",
      "Target: I live in Seoul, South Korea. \n",
      "\n",
      "Input: What is your major?\n",
      "Prediction: _GO _GO I study study industrial industrial industrial industrial South\n",
      "Target: I study industrial engineering. \n",
      "\n",
      "Restore Finished!\n",
      "Input: What do you want to drink?\n",
      "Prediction: _GO _GO _GO Beer Beer ! ! ! ! !\n",
      "Target: Beer please! \n",
      "\n",
      "Input: What is your favorite beer?\n",
      "Prediction: _GO _GO Leffe Leffe brown brown brown , , ,\n",
      "Target: Leffe brown! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    model = Seq2SeqModel(config, mode='inference')\n",
    "    model.build()\n",
    "    for input_batch, target_batch in zip(input_batches, target_batches):\n",
    "        data = (input_batch, target_batch)\n",
    "        model.inference(sess, data, load_ckpt=model.ckpt_dir+f'epoch_{model.n_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem:\n",
    "\n",
    "### Prediction during training was good enough, but the performance went poor during inference.\n",
    "\n",
    "### There is a discrepancy between during training and inference\n",
    "#### - Training: decoder inputs are ground truth tokens.\n",
    "#### - Inference: decoder inputs are token generated by the model itself.\n",
    "#### => First few poorly generated tokens can guide the model in wrong way.\n",
    "\n",
    "## We can solve this issue with '[Scheduled Sampling with Curriculm learning](https://arxiv.org/abs/1506.03099)'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
