{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BP Test\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sigmoid function and its diff\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def diff_sigmoid(x):\n",
    "    fval = sigmoid(x)\n",
    "    return fval * (1 - fval)\n",
    "\n",
    "class BP:\n",
    "    def __init__(self, n_hidden=None, f_hidden='sigmoid', f_output='sigmoid',\n",
    "                 epsilon=1e-3, maxstep=1000, eta=0.1, alpha=0.0): \n",
    "        self.n_input = None  # input layer cell number\n",
    "        self.n_hidden = n_hidden  # hidden layer cell number\n",
    "        self.n_output = None\n",
    "        self.f_hidden = f_hidden\n",
    "        self.f_output = f_output\n",
    "        self.epsilon = epsilon\n",
    "        self.maxstep = maxstep\n",
    "        self.eta = eta  #  learning rate\n",
    "        self.alpha = alpha  # factor\n",
    "\n",
    "        self.wih = None  # input layer to hidden layer weight matrix\n",
    "        self.who = None  # hidden layer to output layer weight matrix\n",
    "        self.bih = None  # input layer to hidden layer bias\n",
    "        self.bho = None  # hidden layer to output layer bias\n",
    "        self.N = None\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def init_param(self, X_data, y_data):\n",
    "        if len(X_data.shape) == 1:  # if input is one-dimension, transpose to be N dimension.\n",
    "            X_data = np.transpose([X_data])\n",
    "        self.N = X_data.shape[0]\n",
    "        if len(y_data.shape) == 1:\n",
    "            y_data = np.transpose([y_data])\n",
    "        self.n_input = X_data.shape[1]\n",
    "        self.n_output = y_data.shape[1]\n",
    "        if self.n_hidden is None:\n",
    "            self.n_hidden = int(math.ceil(math.sqrt(self.n_input + self.n_output)) + 2)\n",
    "        self.wih = np.random.rand(self.n_input, self.n_hidden)  # i*h\n",
    "        self.who = np.random.rand(self.n_hidden, self.n_output)  # h*o\n",
    "        self.bih = np.random.rand(self.n_hidden)  # h\n",
    "        self.bho = np.random.rand(self.n_output)  # o\n",
    "        return X_data, y_data\n",
    "    \n",
    "    def forward(self, X_data):\n",
    "        # forward \n",
    "        x_hidden_in = X_data @ self.wih + self.bih  # n*h\n",
    "        x_hidden_out = sigmoid(x_hidden_in)  # n*h\n",
    "        x_output_in = x_hidden_out @ self.who + self.bho  # n*o\n",
    "        x_output_out = sigmoid(x_output_in)  # n*o\n",
    "        return x_output_out, x_output_in, x_hidden_out, x_hidden_in\n",
    "\n",
    "    def fit(self, X_data, y_data):\n",
    "        X_data, y_data = self.init_param(X_data, y_data)\n",
    "        step = 0\n",
    "        # Initialize all deltas\n",
    "        delta_wih = np.zeros_like(self.wih)\n",
    "        delta_who = np.zeros_like(self.who)\n",
    "        delta_bih = np.zeros_like(self.bih)\n",
    "        delta_bho = np.zeros_like(self.bho)\n",
    "        while step < self.maxstep:\n",
    "            step += 1\n",
    "            # forward \n",
    "            x_output_out, x_output_in, x_hidden_out, x_hidden_in = self.forward(X_data)\n",
    "            if np.sum(abs(x_output_out - y_data)) < self.epsilon:\n",
    "                break\n",
    "                \n",
    "            # loss back pro\n",
    "            err_output = y_data - x_output_out           # n*o， ouput layer, every cell's error\n",
    "            print(\"step {} error_output {} \".format(step, err_output)\n",
    "            delta_ho = -err_output * diff_sigmoid(x_output_in)  # n*o\n",
    "            err_hidden = delta_ho @ self.who.T  # n*h， 隐藏层（相当于输入层的输出），每个神经元上的误差\n",
    "           \n",
    "            # 隐藏层到输出层权值及阈值更新\n",
    "            delta_bho = np.sum(self.eta * delta_ho + self.alpha * delta_bho, axis=0) / self.N\n",
    "            self.bho -= delta_bho\n",
    "            delta_who = self.eta * x_hidden_out.T @ delta_ho + self.alpha * delta_who\n",
    "            self.who -= delta_who\n",
    "            \n",
    "            # 输入层到隐藏层权值及阈值的更新\n",
    "            delta_ih = err_hidden * diff_sigmoid(x_hidden_in)  # n*h\n",
    "            delta_bih = np.sum(self.eta * delta_ih + self.alpha * delta_bih, axis=0) / self.N\n",
    "            self.bih -= delta_bih\n",
    "            delta_wih = self.eta * X_data.T @ delta_ih + self.alpha * delta_wih\n",
    "            self.wih -= delta_wih\n",
    "        return None\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 预测\n",
    "        res = self.forward(X)\n",
    "        return res[0]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    N = 100\n",
    "    X_data = np.linspace(-1, 1, N)\n",
    "    X_data = np.transpose([X_data])\n",
    "    y_data = np.exp(-X_data) * np.sin(2 * X_data)\n",
    "    bp = BP(f_output='linear', maxstep=2000, eta=0.01, alpha=0.1)  # 注意学习率若过大，将导致不能收敛\n",
    "    bp.fit(X_data, y_data)\n",
    "    plt.plot(X_data, y_data)\n",
    "    pred = bp.predict(X_data)\n",
    "    plt.scatter(X_data, pred, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
