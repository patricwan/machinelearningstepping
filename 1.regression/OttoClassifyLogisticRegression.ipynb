{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们以Kaggle 2015年举办的Otto Group Product Classification Challenge竞赛数据为例，分别调用缺省参数LogisticRegression、LogisticRegression + GridSearchCV以及LogisticRegressionCV进行参数调优。实际应用中LogisticRegression + GridSearchCV或LogisticRegressionCV任选一个即可。\n",
    "\n",
    "Otto数据集是著名电商Otto提供的一个多类商品分类问题，类别数=9. 每个样本有93维数值型特征（整数，表示某种事件发生的次数，已经进行过脱敏处理）。 竞赛官网：https://www.kaggle.com/c/otto-group-product-classification-challenge/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先 import 必要的模块\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#竞赛的评价指标为logloss\n",
    "from sklearn.metrics import log_loss  \n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "# path to where the data lies\n",
    "dpath = '../data/'\n",
    "train = pd.read_csv(dpath +\"Otto_train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of           id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0          1       1       0       0       0       0       0       0       0   \n",
       "1          2       0       0       0       0       0       0       0       1   \n",
       "2          3       0       0       0       0       0       0       0       1   \n",
       "3          4       1       0       0       1       6       1       5       0   \n",
       "4          5       0       0       0       0       0       0       0       0   \n",
       "5          6       2       1       0       0       7       0       0       0   \n",
       "6          7       2       0       0       0       0       0       0       2   \n",
       "7          8       0       0       0       0       0       0       0       0   \n",
       "8          9       0       0       0       0       0       0       0       4   \n",
       "9         10       0       0       0       0       0       0       1       0   \n",
       "10        11       0       1       1       2       0       0       2       1   \n",
       "11        12       0       1       2       1       0       0       0       0   \n",
       "12        13       1       0       1       0       0       0       0       1   \n",
       "13        14       0       0       0       1       0       0       0       2   \n",
       "14        15       0       0       0       0       0       0       0       0   \n",
       "15        16       0       0       0       2       0       0       0       1   \n",
       "16        17       0       0       0       0       0       0       0       0   \n",
       "17        18       0       0       0       0       0       0       0       0   \n",
       "18        19       0       0       0       0       0       0       0       1   \n",
       "19        20       0       0       0       0       0       0       0       0   \n",
       "20        21       0       0       2       0       0       0       0       0   \n",
       "21        22       0       0       0       0       0       0       0       0   \n",
       "22        23       0       0       0       0       0       0       0       4   \n",
       "23        24       0       0       0       0       1       0       0       1   \n",
       "24        25       0       0       0       0       0       0       0       1   \n",
       "25        26       0       0       0       0       0       0       0       3   \n",
       "26        27       2       0       0       0       0       0       0       4   \n",
       "27        28       0       0       0       0       0       0       0       1   \n",
       "28        29       0       0       0       0       3       0       0       0   \n",
       "29        30       2       0       0       0       0       0       4       1   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "61848  61849       0       0       0       0       0       0       0       2   \n",
       "61849  61850       5       0       1       1       0       0       1       1   \n",
       "61850  61851       0       0       1       0       0       0       0       6   \n",
       "61851  61852       3       0       0       0       0       0       0       0   \n",
       "61852  61853       0       0       0       0       0       0       0       6   \n",
       "61853  61854       0       0       0       0       0       0       0       0   \n",
       "61854  61855       0       0       1       0       0       0       0       0   \n",
       "61855  61856       0       0       0       0       0       0       0       0   \n",
       "61856  61857       0       0       1       0       0       0       1       3   \n",
       "61857  61858       0       0       0       0       0       0       0      12   \n",
       "61858  61859       4       1       0       0       0       0       0      14   \n",
       "61859  61860       0       0       0       0       1       0       0       2   \n",
       "61860  61861       0       0       0       0       0       0       0       3   \n",
       "61861  61862       0       0       0       0       0       0       0      12   \n",
       "61862  61863       2       0       0       0       0       0       0       1   \n",
       "61863  61864       0       0       0       0       1       0       0       4   \n",
       "61864  61865       0       0       0       0       0       0       0       1   \n",
       "61865  61866       0       0       0       0       0       0       0       2   \n",
       "61866  61867       0       0       0       0       0       0       0      15   \n",
       "61867  61868       0       0       0       0       0       0       0       0   \n",
       "61868  61869       0       0       0       0       0       0       0       2   \n",
       "61869  61870       0       0       0       0       0       0       0       2   \n",
       "61870  61871       1       0       1       0       1       0       0       0   \n",
       "61871  61872       0       0       0       0       0       0       1       1   \n",
       "61872  61873       0       0       0       0       0       0       0       0   \n",
       "61873  61874       1       0       0       1       1       0       0       0   \n",
       "61874  61875       4       0       0       0       0       0       0       0   \n",
       "61875  61876       0       0       0       0       0       0       0       3   \n",
       "61876  61877       1       0       0       0       0       0       0       0   \n",
       "61877  61878       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       feat_9  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "0           0  ...        1        0        0        0        0        0   \n",
       "1           0  ...        0        0        0        0        0        0   \n",
       "2           0  ...        0        0        0        0        0        0   \n",
       "3           0  ...        0        1        2        0        0        0   \n",
       "4           0  ...        1        0        0        0        0        1   \n",
       "5           0  ...        0        3        0        0        0        0   \n",
       "6           0  ...        1        1        0        0        0        0   \n",
       "7           0  ...        0        0        1        0        0        0   \n",
       "8           0  ...        0        2        0        0        0        0   \n",
       "9           0  ...        0        0        1        0        0        0   \n",
       "10          0  ...        0        0        1        0        1        0   \n",
       "11          0  ...        0        2        0        0        0        0   \n",
       "12          0  ...        0        2        0        5        0        0   \n",
       "13          0  ...        2        0        0        1        0        0   \n",
       "14          0  ...        0        0        2        0        0        0   \n",
       "15          0  ...        1        0        1        0        2        0   \n",
       "16          0  ...        0        2        0        0        0        0   \n",
       "17          0  ...        0        0        0        0        0        0   \n",
       "18          0  ...        0        0        3        1        0        0   \n",
       "19          0  ...        0        0        3        0        0        0   \n",
       "20          0  ...        0        0        2        0        0        0   \n",
       "21          0  ...        0        0        0        1        0        0   \n",
       "22          0  ...        0        0        0        0        0        0   \n",
       "23          1  ...        0        0        1        0        0        0   \n",
       "24          0  ...        0        0        0        0        0        0   \n",
       "25          0  ...        0        0        0        1        0        0   \n",
       "26          0  ...        0        0        0        0        1        0   \n",
       "27          0  ...        0        0        0        0        0        0   \n",
       "28          0  ...        0        2        0        0        0        0   \n",
       "29          0  ...        0        0        3        2        0        0   \n",
       "...       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "61848       0  ...        0        0        0        0        0        0   \n",
       "61849       0  ...        0        2        0        0        0        0   \n",
       "61850       0  ...        0        0        0        0        0        0   \n",
       "61851       0  ...        0        1        0        1        0        0   \n",
       "61852       0  ...        0        0        0        0        3        0   \n",
       "61853       0  ...        0        1        1        0        0        0   \n",
       "61854       0  ...        0        0        0        0        0        2   \n",
       "61855       0  ...        0        0        0        0        0        0   \n",
       "61856       0  ...        1        7        3        0        1        0   \n",
       "61857       0  ...        0        0        0        1        1        0   \n",
       "61858       0  ...        2        0        2        1        0        0   \n",
       "61859       0  ...        0        1        1        0        2        0   \n",
       "61860       0  ...        0        0        0        0        1        0   \n",
       "61861       0  ...        0        0        0        0        0        0   \n",
       "61862       3  ...        0        5        2        0        0        0   \n",
       "61863       0  ...        0        0        0        1        0        0   \n",
       "61864       0  ...        0        8        1        0        0        0   \n",
       "61865       0  ...        0        0        1        0        0        0   \n",
       "61866       3  ...        0        0        0        0        3        0   \n",
       "61867       0  ...        0        0        2        0        0        0   \n",
       "61868       0  ...        0        2        0        0        2        0   \n",
       "61869       0  ...        0        3        2        0        0        0   \n",
       "61870       0  ...        1        0        0        0        0        0   \n",
       "61871       0  ...        0        0        0        0        1        0   \n",
       "61872       0  ...        0        1        0        0        0        0   \n",
       "61873       0  ...        1        0        0        0        0        0   \n",
       "61874       0  ...        0        2        0        0        2        0   \n",
       "61875       1  ...        0        3        1        0        0        0   \n",
       "61876       0  ...        0        0        0        0        1        0   \n",
       "61877       0  ...        0        0        0        0        0        0   \n",
       "\n",
       "       feat_91  feat_92  feat_93   target  \n",
       "0            0        0        0  Class_1  \n",
       "1            0        0        0  Class_1  \n",
       "2            0        0        0  Class_1  \n",
       "3            0        0        0  Class_1  \n",
       "4            0        0        0  Class_1  \n",
       "5            2        0        0  Class_1  \n",
       "6            0        0        1  Class_1  \n",
       "7            0        0        0  Class_1  \n",
       "8            0        0        1  Class_1  \n",
       "9            1        0        0  Class_1  \n",
       "10           0        1        0  Class_1  \n",
       "11           0        1        0  Class_1  \n",
       "12           0        0        0  Class_1  \n",
       "13           0        0        0  Class_1  \n",
       "14           0        0        0  Class_1  \n",
       "15           0        0        0  Class_1  \n",
       "16           0        0        0  Class_1  \n",
       "17           0        0        0  Class_1  \n",
       "18           1        0        1  Class_1  \n",
       "19           0        0        0  Class_1  \n",
       "20           0        0        0  Class_1  \n",
       "21           2        0        0  Class_1  \n",
       "22           0        0        0  Class_1  \n",
       "23           0        0        0  Class_1  \n",
       "24           0        0        0  Class_1  \n",
       "25           0        0        0  Class_1  \n",
       "26           1        0        0  Class_1  \n",
       "27           1        1        0  Class_1  \n",
       "28           0        1        0  Class_1  \n",
       "29           0        0        1  Class_1  \n",
       "...        ...      ...      ...      ...  \n",
       "61848        4        0        0  Class_9  \n",
       "61849        0        5        0  Class_9  \n",
       "61850        0        0        0  Class_9  \n",
       "61851        0        7        0  Class_9  \n",
       "61852        0        0        0  Class_9  \n",
       "61853        0        0        0  Class_9  \n",
       "61854        0        0        0  Class_9  \n",
       "61855        0        0        0  Class_9  \n",
       "61856        0        1        0  Class_9  \n",
       "61857        1        0        0  Class_9  \n",
       "61858        1        0        0  Class_9  \n",
       "61859        0        3        0  Class_9  \n",
       "61860        0        0        0  Class_9  \n",
       "61861        0        0        0  Class_9  \n",
       "61862        0        0        0  Class_9  \n",
       "61863        0        1        0  Class_9  \n",
       "61864        0        0        0  Class_9  \n",
       "61865        0        0        0  Class_9  \n",
       "61866        0        0        0  Class_9  \n",
       "61867        0        0        0  Class_9  \n",
       "61868        0        1        0  Class_9  \n",
       "61869        0        1        0  Class_9  \n",
       "61870        0        2        0  Class_9  \n",
       "61871        0        0        0  Class_9  \n",
       "61872        0        0        0  Class_9  \n",
       "61873        0        2        0  Class_9  \n",
       "61874        0        1        0  Class_9  \n",
       "61875        0        0        0  Class_9  \n",
       "61876        3       10        0  Class_9  \n",
       "61877        0        2        0  Class_9  \n",
       "\n",
       "[61878 rows x 95 columns]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "       ...       feat_84       feat_85       feat_86       feat_87  \\\n",
       "count  ...  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean   ...      0.070752      0.532306      1.128576      0.393549   \n",
       "std    ...      1.151460      1.900438      2.681554      1.575455   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      1.000000      0.000000   \n",
       "max    ...     76.000000     55.000000     65.000000     67.000000   \n",
       "\n",
       "            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n",
       "std        2.115466      1.527385      4.597804      2.045646      0.982385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     61.000000    130.000000     52.000000     19.000000   \n",
       "\n",
       "            feat_93  \n",
       "count  61878.000000  \n",
       "mean       0.126135  \n",
       "std        1.201720  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       87.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 各属性的统计特性\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target 分布，看看各类样本分布是否均衡\n",
    "sns.countplot(train[\"target\"]);\n",
    "pyplot.xlabel('target');\n",
    "pyplot.ylabel('Number of occurrences');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  0,  0, ...,  3, 10,  0],\n",
       "       [ 0,  0,  0, ...,  0,  2,  0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将类别字符串变成数字\n",
    "# drop ids and get labels\n",
    "y_train = train[\"target\"]\n",
    "y_train = y_train.map(lambda s: s[6:])\n",
    "y_train = y_train.map(lambda s: int(s)-1)\n",
    "\n",
    "train = train.drop([\"id\", \"target\"], axis=1)\n",
    "X_train = np.array(train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.40209324, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       ...,\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "        -0.38693809, -0.10496314],\n",
       "       [ 0.40209324, -0.21010603, -0.30716546, ...,  1.33702606,\n",
       "         9.792457  , -0.10496314],\n",
       "       [-0.25350808, -0.21010603, -0.30716546, ..., -0.12951551,\n",
       "         1.64894093, -0.10496314]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化特征的标准化器\n",
    "ss_X = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征进行标准化处理\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正则化的 Logistic Regression及参数调优\n",
    "\n",
    "logistic回归的需要调整超参数有：C（正则系数，一般在log域（取log后的值）均匀设置候选参数）和正则函数penalty（L2/L1） 目标函数为：J = sum(logloss(f(xi), yi)) + C* penalty\n",
    "\n",
    "在sklearn框架下，不同学习器的参数调整步骤相同： 设置候选参数集合 调用GridSearchCV 调用fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "penaltys = ['l1','l2']\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "tuned_parameters = dict(penalty = penaltys, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  2.21990261,   5.51592684,   5.20600352,   9.93461542,\n",
       "         14.44186473,  12.06686239,  20.74866939,  15.96489239,\n",
       "         28.79446039, 442.77799711,  33.65370517,  20.3967514 ,\n",
       "         34.36213045,  22.32033634]),\n",
       " 'std_fit_time': array([2.53731363e-01, 6.62370315e-01, 4.18990265e-02, 7.40015778e-01,\n",
       "        2.18400331e+00, 1.02623015e-01, 4.55116171e-01, 2.01857130e-01,\n",
       "        1.35627390e+00, 8.43726804e+02, 9.85466341e-01, 8.01805960e-01,\n",
       "        2.09228885e+00, 1.50442454e+00]),\n",
       " 'mean_score_time': array([0.01502142, 0.00474076, 0.00452847, 0.00521445, 0.00377698,\n",
       "        0.00357852, 0.00326142, 0.00339308, 0.00351062, 0.00390954,\n",
       "        0.00367036, 0.00352483, 0.00384369, 0.00404291]),\n",
       " 'std_score_time': array([0.02072245, 0.00070662, 0.00067741, 0.00196815, 0.00050215,\n",
       "        0.0002895 , 0.00029072, 0.00031112, 0.00025664, 0.00051445,\n",
       "        0.00054348, 0.00025263, 0.00040718, 0.00060251]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100,\n",
       "                    100, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'penalty': 'l1'},\n",
       "  {'C': 0.001, 'penalty': 'l2'},\n",
       "  {'C': 0.01, 'penalty': 'l1'},\n",
       "  {'C': 0.01, 'penalty': 'l2'},\n",
       "  {'C': 0.1, 'penalty': 'l1'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'C': 1, 'penalty': 'l1'},\n",
       "  {'C': 1, 'penalty': 'l2'},\n",
       "  {'C': 10, 'penalty': 'l1'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'C': 100, 'penalty': 'l1'},\n",
       "  {'C': 100, 'penalty': 'l2'},\n",
       "  {'C': 1000, 'penalty': 'l1'},\n",
       "  {'C': 1000, 'penalty': 'l2'}],\n",
       " 'split0_test_score': array([0.67256423, 0.73024721, 0.7324285 , 0.74285022, 0.75173695,\n",
       "        0.75012118, 0.75286799, 0.7521409 , 0.75294878, 0.75294878,\n",
       "        0.75319115, 0.75327193, 0.75311036, 0.75319115]),\n",
       " 'split1_test_score': array([0.67019472, 0.72117638, 0.72683203, 0.73596186, 0.74711158,\n",
       "        0.74573806, 0.75082815, 0.75066656, 0.75179769, 0.75179769,\n",
       "        0.75187848, 0.75195928, 0.75195928, 0.75195928]),\n",
       " 'split2_test_score': array([0.6770362 , 0.72769877, 0.73109244, 0.74062702, 0.75250485,\n",
       "        0.75161603, 0.75379767, 0.75404008, 0.75444409, 0.75436328,\n",
       "        0.75436328, 0.75428248, 0.75444409, 0.75428248]),\n",
       " 'split3_test_score': array([0.67501616, 0.72689076, 0.73383969, 0.74313187, 0.75775695,\n",
       "        0.75646412, 0.75929218, 0.75945378, 0.7602618 , 0.75993859,\n",
       "        0.76010019, 0.76001939, 0.76001939, 0.76001939]),\n",
       " 'split4_test_score': array([0.67359146, 0.72799289, 0.73260044, 0.74019885, 0.75224315,\n",
       "        0.7511923 , 0.75385983, 0.753779  , 0.75418317, 0.75394067,\n",
       "        0.75418317, 0.754264  , 0.75418317, 0.75418317]),\n",
       " 'mean_test_score': array([0.67368047, 0.72680112, 0.73135848, 0.74055399, 0.7522706 ,\n",
       "        0.75102621, 0.75412909, 0.75401597, 0.75472704, 0.75459776,\n",
       "        0.7547432 , 0.75475937, 0.7547432 , 0.75472704]),\n",
       " 'std_test_score': array([0.00230006, 0.00302499, 0.0024251 , 0.00257452, 0.00337816,\n",
       "        0.00342737, 0.0028046 , 0.00297872, 0.00292421, 0.00281329,\n",
       "        0.00282039, 0.0027639 , 0.00278064, 0.00277575]),\n",
       " 'rank_test_score': array([14, 13, 12, 11,  9, 10,  7,  8,  4,  6,  2,  1,  2,  4],\n",
       "       dtype=int32),\n",
       " 'split0_train_score': array([0.67385859, 0.72680808, 0.73280808, 0.74183838, 0.75458586,\n",
       "        0.75345455, 0.75765657, 0.75735354, 0.75828283, 0.75816162,\n",
       "        0.75832323, 0.75836364, 0.75832323, 0.75838384]),\n",
       " 'split1_train_score': array([0.67509747, 0.72972263, 0.73396497, 0.74414658, 0.75620695,\n",
       "        0.75515646, 0.75869174, 0.75844932, 0.75917658, 0.75917658,\n",
       "        0.75919678, 0.75923719, 0.75921699, 0.75925739]),\n",
       " 'split2_train_score': array([0.67344754, 0.72770797, 0.73300069, 0.74227304, 0.75459577,\n",
       "        0.75423215, 0.75805018, 0.75770676, 0.75849461, 0.7583936 ,\n",
       "        0.75857541, 0.75859561, 0.75859561, 0.75861581]),\n",
       " 'split3_train_score': array([0.67340714, 0.72667771, 0.7314856 , 0.74142459, 0.75275746,\n",
       "        0.75245445, 0.75625227, 0.75596946, 0.75687851, 0.75661589,\n",
       "        0.75687851, 0.75683811, 0.75687851, 0.75687851]),\n",
       " 'split4_train_score': array([0.67430868, 0.72668512, 0.73306805, 0.74250106, 0.75538813,\n",
       "        0.75441857, 0.75813521, 0.75779183, 0.7583776 , 0.75819581,\n",
       "        0.7584786 , 0.7584382 , 0.7584786 , 0.7584988 ]),\n",
       " 'mean_train_score': array([0.67402388, 0.7275203 , 0.73286548, 0.74243673, 0.75470683,\n",
       "        0.75394323, 0.75775719, 0.75745418, 0.75824203, 0.7581087 ,\n",
       "        0.75829051, 0.75829455, 0.75829859, 0.75832687]),\n",
       " 'std_train_score': array([0.00062826, 0.00116621, 0.00079694, 0.00093134, 0.00114381,\n",
       "        0.0009205 , 0.00082183, 0.00082251, 0.00075052, 0.00083191,\n",
       "        0.00076586, 0.00079068, 0.00077218, 0.00078484])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the complete results (list of named tuples)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7547593652024952\n",
      "{'C': 100, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果最佳值在候选参数的边缘，最好再尝试更大的候选参数或更小的候选参数，直到找到拐点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).to_csv('LogisticGridSearchCV_Otto.csv')\n",
    "\n",
    "# plot CV误差曲线\n",
    "test_means = grid.cv_results_[ 'mean_test_score' ]\n",
    "test_stds = grid.cv_results_[ 'std_test_score' ]\n",
    "train_means = grid.cv_results_[ 'mean_train_score' ]\n",
    "train_stds = grid.cv_results_[ 'std_train_score' ]\n",
    "\n",
    "\n",
    "#cvresult = pd.DataFrame.from_csv('LogisticGridSearchCV_Otto.csv')\n",
    "#test_means = cv_results['mean_test_score']\n",
    "#test_stds = cv_results['std_test_score'] \n",
    "#train_means = cvresult['mean_train_score']\n",
    "#train_stds = cvresult['std_train_score'] \n",
    "\n",
    "# plot results\n",
    "number_C = len(Cs)\n",
    "number_penaltys = len(penaltys)\n",
    "test_scores = np.array(test_means).reshape(number_C,number_penaltys)\n",
    "train_scores = np.array(train_means).reshape(number_C,number_penaltys)\n",
    "test_stds = np.array(test_stds).reshape(number_C,number_penaltys)\n",
    "train_stds = np.array(train_stds).reshape(number_C,number_penaltys)\n",
    "\n",
    "x_axis = np.log10(Cs)\n",
    "for i, value in enumerate(penaltys):\n",
    "    #pyplot.plot(log(Cs), test_scores[i], label= 'penalty:'   + str(value))\n",
    "    pyplot.errorbar(x_axis, test_scores[:,i], yerr=test_stds[:,i] ,label = penaltys[i] +' Test')\n",
    "    pyplot.errorbar(x_axis, train_scores[:,i], yerr=train_stds[:,i] ,label = penaltys[i] +' Train')\n",
    "    \n",
    "pyplot.legend()\n",
    "pyplot.xlabel( 'log(C)' )                                                                                                      \n",
    "pyplot.ylabel( 'accuracy' )\n",
    "pyplot.savefig('LogisticGridSearchCV_C.png' )\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图给出了L1正则和L2正则下、不同正则参数C对应的模型在训练集上测试集上的正确率（score）。可以看出在训练集上C越大（正则越少）的模型性能越好；但在测试集上当C=100时性能最好（L1正则和L2正则均是）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[0.97148166, 0.97156245, 0.97156245, 0.97156245],\n",
       "        [0.97002505, 0.97010584, 0.97010584, 0.97010584],\n",
       "        [0.97171946, 0.97163866, 0.97163866, 0.97163866],\n",
       "        [0.97285068, 0.97285068, 0.97285068, 0.97285068],\n",
       "        [0.97219303, 0.97219303, 0.9721122 , 0.9721122 ]]),\n",
       " 1: array([[0.84141218, 0.84133139, 0.84125061, 0.84125061],\n",
       "        [0.8409146 , 0.84115698, 0.84115698, 0.84115698],\n",
       "        [0.84276018, 0.84243697, 0.84219457, 0.84219457],\n",
       "        [0.843649  , 0.8438106 , 0.8438106 , 0.8438106 ],\n",
       "        [0.84398998, 0.84374747, 0.84358581, 0.84358581]]),\n",
       " 2: array([[0.87825174, 0.8784941 , 0.8784941 , 0.8784941 ],\n",
       "        [0.87589884, 0.87597964, 0.87589884, 0.87589884],\n",
       "        [0.87467679, 0.8749192 , 0.8749192 , 0.8749192 ],\n",
       "        [0.87322237, 0.87322237, 0.87322237, 0.87322237],\n",
       "        [0.87575782, 0.87616199, 0.87640449, 0.87640449]]),\n",
       " 3: array([[0.95774762, 0.95766683, 0.95766683, 0.95766683],\n",
       "        [0.95855215, 0.95847136, 0.95847136, 0.95847136],\n",
       "        [0.9581448 , 0.9581448 , 0.9581448 , 0.9581448 ],\n",
       "        [0.9583872 , 0.958468  , 0.958468  , 0.958468  ],\n",
       "        [0.95853205, 0.95853205, 0.95853205, 0.95853205]]),\n",
       " 4: array([[0.99571821, 0.99563742, 0.99563742, 0.99555663],\n",
       "        [0.99701058, 0.9967682 , 0.9967682 , 0.9967682 ],\n",
       "        [0.99595992, 0.99612153, 0.99620233, 0.99612153],\n",
       "        [0.99587912, 0.99579832, 0.99579832, 0.99579832],\n",
       "        [0.99652413, 0.99644329, 0.99644329, 0.99644329]]),\n",
       " 5: array([[0.96219098, 0.96235256, 0.96235256, 0.96235256],\n",
       "        [0.96348065, 0.96356144, 0.96356144, 0.96356144],\n",
       "        [0.96501293, 0.96517453, 0.96517453, 0.96517453],\n",
       "        [0.97058824, 0.97058824, 0.97050743, 0.97050743],\n",
       "        [0.9664538 , 0.96653464, 0.96653464, 0.96653464]]),\n",
       " 6: array([[0.96590725, 0.96590725, 0.96590725, 0.96590725],\n",
       "        [0.96469257, 0.96461178, 0.96461178, 0.96461178],\n",
       "        [0.96574014, 0.96565934, 0.96565934, 0.96565934],\n",
       "        [0.96622495, 0.96630575, 0.96630575, 0.96630575],\n",
       "        [0.96669631, 0.9664538 , 0.9664538 , 0.9664538 ]]),\n",
       " 7: array([[0.96606883, 0.96623041, 0.96623041, 0.96623041],\n",
       "        [0.96275349, 0.96283429, 0.96291508, 0.96291508],\n",
       "        [0.96493213, 0.96501293, 0.96501293, 0.96501293],\n",
       "        [0.96242728, 0.96250808, 0.96250808, 0.96258888],\n",
       "        [0.9633821 , 0.9633821 , 0.9633821 , 0.9633821 ]]),\n",
       " 8: array([[0.96711908, 0.96703829, 0.96703829, 0.96703829],\n",
       "        [0.96889392, 0.96897471, 0.96897471, 0.96897471],\n",
       "        [0.96969942, 0.96994182, 0.96994182, 0.97002262],\n",
       "        [0.96824499, 0.96824499, 0.96824499, 0.96824499],\n",
       "        [0.9662113 , 0.9659688 , 0.96588796, 0.96588796]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用LogisticRegressionCV实现正则化的 Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = [1, 10,100,1000]\n",
    "\n",
    "# 大量样本（7W）、高维度（93），L1正则 --> 可选用saga优化求解器(0.19版本新功能)\n",
    "lr_cv = LogisticRegressionCV(Cs=Cs, cv = 5, penalty='l1', solver='liblinear', multi_class='ovr')\n",
    "lr_cv.fit(X_train, y_train)    \n",
    "\n",
    "lr_cv.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
