{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART & RF——Otto商品分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们以Kaggle 2015年举办的Otto Group Product Classification Challenge竞赛数据为例，分别调用缺省参数CART、CART + GridSearchCV 以及Random Forest + GridSearchCV进行参数调优。\n",
    "\n",
    "同时考虑通过feature_importances_进行特征选择\n",
    "\n",
    "Otto数据集是著名电商Otto提供的一个多类商品分类问题，类别数=9. 每个样本有93维数值型特征（整数，表示某种事件发生的次数，已经进行过脱敏处理）。 竞赛官网：https://www.kaggle.com/c/otto-group-product-classification-challenge/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先 import 必要的模块\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#竞赛的评价指标为logloss\n",
    "from sklearn.metrics import log_loss \n",
    "from sklearn import metrics  \n",
    "\n",
    "from matplotlib import pyplot \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据 & 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "# path to where the data lies\n",
    "dpath = '../data/'\n",
    "train = pd.read_csv(dpath +\"Otto_train.csv\")\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 各属性的统计特性\n",
    "#train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target 分布，看看各类样本分布是否均衡\n",
    "sns.countplot(train.target);\n",
    "pyplot.xlabel('target');\n",
    "pyplot.ylabel('Number of occurrences');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各类样本不均衡。交叉验证对分类任务缺省的是采用StratifiedKFold，在每折采样时根据各类样本按比例采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将类别字符串变成数字\n",
    "# drop ids and get labels\n",
    "y_train = train['target']   #形式为Class_x\n",
    "y_train = y_train.map(lambda s: s[6:])\n",
    "y_train = y_train.map(lambda s: int(s)-1)\n",
    "\n",
    "train = train.drop([\"id\", \"target\"], axis=1)\n",
    "columns = train.columns\n",
    "\n",
    "X_train = np.array(train)\n",
    "\n",
    "#如果计算资源有限，也可只取少量样本，如取前1000个样本\n",
    "#（分类中其实还需要确保取出来的这部分样本各类样本的比例和总体一致）\n",
    "#n_trains = 1000\n",
    "#y_train = train.label.values[:n_trains]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 初始化特征的标准化器\n",
    "ss_X = StandardScaler()\n",
    "\n",
    "# 分别对训练和测试数据的特征进行标准化处理\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "#X_test = ss_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default Desion Tree (CART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = DecisionTreeClassifier()\n",
    "\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss of each fold is:  [10.26903865 10.08659469  9.77575707  9.98220856  9.92961913  9.80441179\n",
      "  9.56432654  9.70949437  9.56432654  9.80916891]\n",
      "cv logloss is: 9.849494624396684\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证用于评估模型性能和进行参数调优（模型选择）\n",
    "#分类任务中交叉验证缺省是采用StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "loss = cross_val_score(model_tree, X_train, y_train, cv=10, scoring='neg_log_loss')\n",
    "print('logloss of each fold is: ',-loss)\n",
    "print('cv logloss is:', -loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feat_11</td>\n",
       "      <td>0.101641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>feat_60</td>\n",
       "      <td>0.080466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>feat_34</td>\n",
       "      <td>0.051490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>feat_90</td>\n",
       "      <td>0.046284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feat_14</td>\n",
       "      <td>0.041107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feat_15</td>\n",
       "      <td>0.038382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>feat_39</td>\n",
       "      <td>0.025081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>feat_36</td>\n",
       "      <td>0.024844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>feat_86</td>\n",
       "      <td>0.022643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>feat_42</td>\n",
       "      <td>0.021590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>feat_67</td>\n",
       "      <td>0.021446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>feat_40</td>\n",
       "      <td>0.020977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feat_25</td>\n",
       "      <td>0.018171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>feat_48</td>\n",
       "      <td>0.017638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>feat_62</td>\n",
       "      <td>0.017079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>feat_30</td>\n",
       "      <td>0.016311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>feat_32</td>\n",
       "      <td>0.015083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feat_24</td>\n",
       "      <td>0.014427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feat_16</td>\n",
       "      <td>0.014094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>feat_53</td>\n",
       "      <td>0.014089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>feat_68</td>\n",
       "      <td>0.014070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>feat_64</td>\n",
       "      <td>0.013770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feat_26</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>feat_69</td>\n",
       "      <td>0.013160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feat_9</td>\n",
       "      <td>0.013071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>feat_88</td>\n",
       "      <td>0.012603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>feat_43</td>\n",
       "      <td>0.011671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feat_8</td>\n",
       "      <td>0.010954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>feat_72</td>\n",
       "      <td>0.009275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>feat_59</td>\n",
       "      <td>0.009272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>feat_44</td>\n",
       "      <td>0.003950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>feat_74</td>\n",
       "      <td>0.003718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>feat_58</td>\n",
       "      <td>0.003268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feat_10</td>\n",
       "      <td>0.003109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feat_4</td>\n",
       "      <td>0.003088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>feat_45</td>\n",
       "      <td>0.002927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>feat_52</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feat_27</td>\n",
       "      <td>0.002893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feat_23</td>\n",
       "      <td>0.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>feat_65</td>\n",
       "      <td>0.002570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>feat_49</td>\n",
       "      <td>0.002521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>feat_80</td>\n",
       "      <td>0.002459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>feat_63</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feat_7</td>\n",
       "      <td>0.002309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feat_19</td>\n",
       "      <td>0.002234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>feat_77</td>\n",
       "      <td>0.002227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>feat_46</td>\n",
       "      <td>0.001989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>feat_93</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feat_3</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feat_2</td>\n",
       "      <td>0.001608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feat_5</td>\n",
       "      <td>0.001529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>feat_81</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feat_12</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feat_28</td>\n",
       "      <td>0.001179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>feat_31</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>feat_51</td>\n",
       "      <td>0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>feat_82</td>\n",
       "      <td>0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feat_6</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>feat_61</td>\n",
       "      <td>0.000548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>feat_84</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    columns  importance\n",
       "10  feat_11    0.101641\n",
       "59  feat_60    0.080466\n",
       "33  feat_34    0.051490\n",
       "89  feat_90    0.046284\n",
       "13  feat_14    0.041107\n",
       "14  feat_15    0.038382\n",
       "38  feat_39    0.025081\n",
       "35  feat_36    0.024844\n",
       "85  feat_86    0.022643\n",
       "41  feat_42    0.021590\n",
       "66  feat_67    0.021446\n",
       "39  feat_40    0.020977\n",
       "24  feat_25    0.018171\n",
       "47  feat_48    0.017638\n",
       "61  feat_62    0.017079\n",
       "29  feat_30    0.016311\n",
       "31  feat_32    0.015083\n",
       "23  feat_24    0.014427\n",
       "15  feat_16    0.014094\n",
       "52  feat_53    0.014089\n",
       "67  feat_68    0.014070\n",
       "63  feat_64    0.013770\n",
       "25  feat_26    0.013500\n",
       "68  feat_69    0.013160\n",
       "8    feat_9    0.013071\n",
       "87  feat_88    0.012603\n",
       "42  feat_43    0.011671\n",
       "7    feat_8    0.010954\n",
       "71  feat_72    0.009275\n",
       "58  feat_59    0.009272\n",
       "..      ...         ...\n",
       "43  feat_44    0.003950\n",
       "73  feat_74    0.003718\n",
       "57  feat_58    0.003268\n",
       "9   feat_10    0.003109\n",
       "3    feat_4    0.003088\n",
       "44  feat_45    0.002927\n",
       "51  feat_52    0.002909\n",
       "26  feat_27    0.002893\n",
       "22  feat_23    0.002602\n",
       "64  feat_65    0.002570\n",
       "48  feat_49    0.002521\n",
       "79  feat_80    0.002459\n",
       "62  feat_63    0.002323\n",
       "6    feat_7    0.002309\n",
       "18  feat_19    0.002234\n",
       "76  feat_77    0.002227\n",
       "45  feat_46    0.001989\n",
       "92  feat_93    0.001779\n",
       "2    feat_3    0.001737\n",
       "1    feat_2    0.001608\n",
       "4    feat_5    0.001529\n",
       "80  feat_81    0.001345\n",
       "11  feat_12    0.001198\n",
       "27  feat_28    0.001179\n",
       "30  feat_31    0.001151\n",
       "50  feat_51    0.001028\n",
       "81  feat_82    0.000739\n",
       "5    feat_6    0.000738\n",
       "60  feat_61    0.000548\n",
       "83  feat_84    0.000340\n",
       "\n",
       "[93 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看看特征重要性\n",
    "df = pd.DataFrame({\"columns\":list(columns), \"importance\":list(model_tree.feature_importances_.T)})\n",
    "df.sort_values(by=['importance'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的超参数有：max_depth（树的深度）或max_leaf_nodes（叶子结点的数目）、max_features（最大特征数目）、min_samples_leaf（叶子结点的最小样本数）、min_samples_split（中间结点的最小样本树）、min_weight_fraction_leaf（叶子节点的样本权重占总权重的比例）\n",
    "min_impurity_split（最小不纯净度）也可以调整\n",
    "\n",
    "这里调整max_depth试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DD = DecisionTreeClassifier()\n",
    "\n",
    "#设置参数搜索grid\n",
    "max_depth = range(5,15,1)\n",
    "#min_samples_leaf = range(1,10,2)\n",
    "tuned_parameters = dict(max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(5, 15)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='neg_log_loss',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "DD = GridSearchCV(model_DD, tuned_parameters, scoring='neg_log_loss', cv=10)\n",
    "DD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1.153345 using {'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (-DD.best_score_, DD.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_means = -DD.cv_results_[ 'mean_test_score' ]\n",
    "\n",
    "x_axis = range(5, test_means.shape[0]+5)\n",
    "        \n",
    "pyplot.plot(x_axis, test_means)\n",
    "pyplot.title(\"max_depth vs Log Loss\")\n",
    "pyplot.xlabel( 'max_depth' )\n",
    "pyplot.ylabel( 'Log Loss' )\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feat_11</td>\n",
       "      <td>0.207394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>feat_60</td>\n",
       "      <td>0.162120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>feat_34</td>\n",
       "      <td>0.096588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>feat_90</td>\n",
       "      <td>0.094571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feat_14</td>\n",
       "      <td>0.064401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feat_15</td>\n",
       "      <td>0.059532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>feat_36</td>\n",
       "      <td>0.040157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>feat_39</td>\n",
       "      <td>0.033905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>feat_30</td>\n",
       "      <td>0.030314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>feat_42</td>\n",
       "      <td>0.023786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>feat_86</td>\n",
       "      <td>0.020887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>feat_69</td>\n",
       "      <td>0.013848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feat_26</td>\n",
       "      <td>0.013719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>feat_48</td>\n",
       "      <td>0.012453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>feat_62</td>\n",
       "      <td>0.012108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feat_16</td>\n",
       "      <td>0.009595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feat_8</td>\n",
       "      <td>0.009568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>feat_67</td>\n",
       "      <td>0.008789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>feat_43</td>\n",
       "      <td>0.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>feat_32</td>\n",
       "      <td>0.007621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>feat_55</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>feat_91</td>\n",
       "      <td>0.004789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>feat_47</td>\n",
       "      <td>0.004283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>feat_53</td>\n",
       "      <td>0.004198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>feat_83</td>\n",
       "      <td>0.004041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feat_25</td>\n",
       "      <td>0.004040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>feat_59</td>\n",
       "      <td>0.003994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>feat_29</td>\n",
       "      <td>0.003127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>feat_78</td>\n",
       "      <td>0.002560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>feat_88</td>\n",
       "      <td>0.002493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>feat_65</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>feat_57</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>feat_74</td>\n",
       "      <td>0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>feat_77</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>feat_31</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>feat_92</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>feat_63</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feat_22</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>feat_51</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feat_3</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feat_23</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feat_18</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feat_28</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>feat_71</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feat_1</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>feat_46</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>feat_33</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>feat_79</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>feat_73</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>feat_81</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>feat_82</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>feat_61</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>feat_52</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>feat_38</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feat_19</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feat_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feat_10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feat_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feat_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>feat_93</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    columns  importance\n",
       "10  feat_11    0.207394\n",
       "59  feat_60    0.162120\n",
       "33  feat_34    0.096588\n",
       "89  feat_90    0.094571\n",
       "13  feat_14    0.064401\n",
       "14  feat_15    0.059532\n",
       "35  feat_36    0.040157\n",
       "38  feat_39    0.033905\n",
       "29  feat_30    0.030314\n",
       "41  feat_42    0.023786\n",
       "85  feat_86    0.020887\n",
       "68  feat_69    0.013848\n",
       "25  feat_26    0.013719\n",
       "47  feat_48    0.012453\n",
       "61  feat_62    0.012108\n",
       "15  feat_16    0.009595\n",
       "7    feat_8    0.009568\n",
       "66  feat_67    0.008789\n",
       "42  feat_43    0.008436\n",
       "31  feat_32    0.007621\n",
       "54  feat_55    0.005242\n",
       "90  feat_91    0.004789\n",
       "46  feat_47    0.004283\n",
       "52  feat_53    0.004198\n",
       "82  feat_83    0.004041\n",
       "24  feat_25    0.004040\n",
       "58  feat_59    0.003994\n",
       "28  feat_29    0.003127\n",
       "77  feat_78    0.002560\n",
       "87  feat_88    0.002493\n",
       "..      ...         ...\n",
       "64  feat_65    0.000289\n",
       "56  feat_57    0.000273\n",
       "73  feat_74    0.000263\n",
       "76  feat_77    0.000234\n",
       "30  feat_31    0.000193\n",
       "91  feat_92    0.000181\n",
       "62  feat_63    0.000157\n",
       "21  feat_22    0.000133\n",
       "50  feat_51    0.000118\n",
       "2    feat_3    0.000116\n",
       "22  feat_23    0.000106\n",
       "17  feat_18    0.000083\n",
       "27  feat_28    0.000083\n",
       "70  feat_71    0.000081\n",
       "0    feat_1    0.000078\n",
       "45  feat_46    0.000063\n",
       "32  feat_33    0.000063\n",
       "78  feat_79    0.000000\n",
       "72  feat_73    0.000000\n",
       "80  feat_81    0.000000\n",
       "81  feat_82    0.000000\n",
       "60  feat_61    0.000000\n",
       "51  feat_52    0.000000\n",
       "37  feat_38    0.000000\n",
       "18  feat_19    0.000000\n",
       "11  feat_12    0.000000\n",
       "9   feat_10    0.000000\n",
       "6    feat_7    0.000000\n",
       "5    feat_6    0.000000\n",
       "92  feat_93    0.000000\n",
       "\n",
       "[93 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看看特征重要性\n",
    "df = pd.DataFrame({\"columns\":list(columns), \"importance\":list(DD.best_estimator_.feature_importances_.T)})\n",
    "df.sort_values(by=['importance'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 做下特征选择看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61878, 15)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(DD.best_estimator_, prefit=True)\n",
    "X_Train_new = model.transform(X_train)\n",
    "X_Train_new.shape               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用选择的特征，CV选择的max_depth参数，再次训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss of each fold is:  [1.10033581 1.19411354 1.18658322 1.22201171 1.23646701 1.20128401\n",
      " 1.18555535 1.1321167  1.15176874 1.12647757]\n",
      "cv logloss is: 1.173671364356865\n"
     ]
    }
   ],
   "source": [
    "model_tuned_tree = DecisionTreeClassifier(max_depth= DD.best_params_['max_depth'])\n",
    "\n",
    "#model_tuned_tree.fit(X_Train_new, y_train)\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "loss = cross_val_score(model_tuned_tree, X_Train_new, y_train, cv=10, scoring='neg_log_loss')\n",
    "print('logloss of each fold is: ',-loss)\n",
    "print('cv logloss is:', -loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这比用全部特征得到的1.148384大了好多，特征剔除得太多了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61878, 80)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 少剔除一些看看\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(DD.best_estimator_, threshold = 0.000042, prefit=True)\n",
    "X_Train_new = model.transform(X_train)\n",
    "X_Train_new.shape               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss of each fold is:  [1.09242622 1.17787894 1.14685185 1.19842063 1.155486   1.15431382\n",
      " 1.21336335 1.10025896 1.12014831 1.12122504]\n",
      "cv logloss is: 1.1480373122701084\n"
     ]
    }
   ],
   "source": [
    "model_tuned_tree = DecisionTreeClassifier(max_depth= DD.best_params_['max_depth'])\n",
    "\n",
    "#model_tuned_tree.fit(X_Train_new, y_train)\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "loss = cross_val_score(model_tuned_tree, X_Train_new, y_train, cv=10, scoring='neg_log_loss')\n",
    "print ('logloss of each fold is: ',-loss)\n",
    "print('cv logloss is:', -loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "结果好像好了一丢丢，特征少点更好。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 还是写一个自动监控程序看看\n",
    "\n",
    "决策树运行快，所以在这示意监控过程。Random Forest部分大家可以参照写一个，不过得对训练时间有足够的心理准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 一个threshold对应的特征选择，及相应的模型训练和测试，得到该参数下模型在校验集上的预测性能\n",
    "def one_feature_selection(threshold, X_train, y_train):\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"threshold: {}\".format(threshold))\n",
    "    model = SelectFromModel(DD.best_estimator_, threshold = threshold, prefit=True)\n",
    "    X_Train_new = model.transform(X_train)\n",
    "    print(X_Train_new.shape)   \n",
    "\n",
    "    # 在训练集和测试集降维 \n",
    "    DD.best_estimator_.get_params()\n",
    "    model_tuned_tree = DecisionTreeClassifier(max_depth = DD.best_estimator_.get_params()['max_depth'] )\n",
    "\n",
    "    loss = cross_val_score(model_tuned_tree, X_Train_new, y_train, cv=10, scoring='neg_log_loss')\n",
    "    cvloss = -loss.mean()\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"cvloss: {}\".format(cvloss.mean()))\n",
    "    return cvloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.09457054439603475\n",
      "(61878, 4)\n",
      "cvloss: 1.518650654072649\n",
      "threshold: 0.020887028999046986\n",
      "(61878, 11)\n",
      "cvloss: 1.2112258155330564\n",
      "threshold: 0.0\n",
      "(61878, 93)\n",
      "cvloss: 1.1576621257319932\n",
      "threshold: 0.0025599216128586364\n",
      "(61878, 29)\n",
      "cvloss: 1.1654205684586727\n",
      "threshold: 0.00026328022492576184\n",
      "(61878, 66)\n",
      "cvloss: 1.1452820723240698\n",
      "threshold: 0.0011449379882482505\n",
      "(61878, 38)\n",
      "cvloss: 1.1619289759146745\n",
      "threshold: 0.00029463094456647537\n",
      "(61878, 63)\n",
      "cvloss: 1.1457113194306017\n",
      "threshold: 0.012107878983018159\n",
      "(61878, 15)\n",
      "cvloss: 1.1708009126365795\n",
      "threshold: 0.00030758105395277874\n",
      "(61878, 62)\n",
      "cvloss: 1.1461786512179135\n",
      "threshold: 0.0008590718907913167\n",
      "(61878, 42)\n",
      "cvloss: 1.1566615374762788\n",
      "threshold: 0.0009593339084311434\n",
      "(61878, 39)\n",
      "cvloss: 1.153983158218362\n",
      "threshold: 6.252905341986845e-05\n",
      "(61878, 80)\n",
      "cvloss: 1.1512469426028484\n",
      "threshold: 0.023785620688790737\n",
      "(61878, 10)\n",
      "cvloss: 1.2057427957324323\n",
      "threshold: 0.0\n",
      "(61878, 93)\n",
      "cvloss: 1.1582924772862966\n",
      "threshold: 0.09658812612060114\n",
      "(61878, 3)\n",
      "cvloss: 1.5749814860982374\n",
      "threshold: 0.03031405452901337\n",
      "(61878, 9)\n",
      "cvloss: 1.244909839323008\n",
      "threshold: 0.013718510862385298\n",
      "(61878, 13)\n",
      "cvloss: 1.198561505566908\n",
      "threshold: 0.00013299830409940256\n",
      "(61878, 71)\n",
      "cvloss: 1.145008525399664\n",
      "threshold: 8.337207122649127e-05\n",
      "(61878, 75)\n",
      "cvloss: 1.1483950991792082\n"
     ]
    }
   ],
   "source": [
    "# 设置threshold搜索范围\n",
    "# 每次去掉最不重要的5%\n",
    "cols = df.shape[0] #总的特征数目\n",
    "step = int(cols*0.05)\n",
    "\n",
    "threshold_s = np.zeros(20)\n",
    "losses = []\n",
    "for i in range(1,20,1):\n",
    "    threshold_s[i-1] = df.importance[cols - i*step]\n",
    "    #排序好像不起作用，取不到特征阈值，再好好看看。。。\n",
    "    tmp = one_feature_selection(threshold_s[i-1],  X_train, y_train)\n",
    "    losses.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林可调整的超参数（除了和决策树相同的参数）：n_estimators（弱学习器的数目）\n",
    "所以下面一起调整树的max_depth和n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_RR=RandomForestClassifier()\n",
    "\n",
    "#设置参数搜索grid\n",
    "max_depth = range(10,30,2)\n",
    "n_estimators = range(10,20,2)\n",
    "tuned_parameters = dict(max_depth=max_depth, n_estimators = n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "RR = GridSearchCV(model_RR, tuned_parameters, scoring='neg_log_loss', cv=10)\n",
    "RR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (-RR.best_score_, RR.best_params_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "性能比一棵树好多了，还是森林好！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_means = -RR.cv_results_[ 'mean_test_score' ]\n",
    "\n",
    "# plot results\n",
    "test_scores = np.array(test_means).reshape(len(max_depth), len(n_estimators))\n",
    "x_axis = n_estimators\n",
    "for i, value in enumerate(max_depth):\n",
    "    pyplot.plot(n_estimators, test_scores[i], label= 'max_depth:'   + str(value))\n",
    "\n",
    "pyplot.legend()\n",
    "pyplot.xlabel( 'n_estimators' )                                                                                                      \n",
    "pyplot.ylabel( 'logloss' )\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最佳的n_estimators在我们参数搜索范围的边界，我们还需要进一步扩大n_estimators的搜索范围，继续寻找\n",
    "并且max_depth在20以前是下降明显（不管对多少的n_estimators）\n",
    "\n",
    "GBDT是递归，所以树的深度不要太大，n_estimators可以多\n",
    "随机森林还是需要每棵树深一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_RR=RandomForestClassifier()\n",
    "\n",
    "#设置参数搜索grid\n",
    "max_depth = range(20,30,2)\n",
    "n_estimators = range(20,100,10)\n",
    "tuned_parameters = dict(max_depth=max_depth, n_estimators = n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以先去睡觉...\n",
    "随着树的深度和数目的增加，训练时间越来越长\n",
    "可以考虑不用交叉验证，而是train_test_split(尤其是计算资源不够的情况下，之前给过SVM核参数调优的时候给个示例代码，大家可以参考)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "RR = GridSearchCV(model_RR, tuned_parameters, scoring='neg_log_loss', cv=10)\n",
    "RR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (-RR.best_score_, RR.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_means = -RR.cv_results_[ 'mean_test_score' ]\n",
    "\n",
    "# plot results\n",
    "test_scores = np.array(test_means).reshape(len(max_depth), len(n_estimators))\n",
    "x_axis = n_estimators\n",
    "for i, value in enumerate(max_depth):\n",
    "    pyplot.plot(n_estimators, test_scores[i], label= 'max_depth:'   + str(value))\n",
    "\n",
    "pyplot.legend()\n",
    "pyplot.xlabel( 'n_estimators' )                                                                                                      \n",
    "pyplot.ylabel( 'logloss' )\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看来模型还是太简单，大家请继续调整参数，继续增加模型复杂度。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 请自行补充根据特征重要性选择特征\n",
    "可以设置threshold的搜索范围，然后用CV监控模型性能，从而确定合适的特征数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生产测试结果\n",
    "假设模型已经训练好了，利用训练好的模型在测试样本上机械能测试，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "test = pd.read_csv(dpath +\"Otto_test.csv\")\n",
    "\n",
    "#准备好测试数据\n",
    "ids = test[\"id\"]\n",
    "test = train.drop([\"id\"], axis=1)\n",
    "\n",
    "#数据预处理\n",
    "X_test = np.array(test)\n",
    "X_test = ss_X.transform(X_test)\n",
    "\n",
    "#测试\n",
    "y_pred = RR.predict_proba(X_test)\n",
    "\n",
    "submission = pd.DataFrame({ \"id\": ids})\n",
    "\n",
    "i = 0\n",
    "# Create column name based on target values(see sample_submission.csv)\n",
    "for num in range_of_classes:\n",
    "    col_name = str(\"Class_{}\".format(num))\n",
    "    submission[col_name] = y_pred[:,i]\n",
    "    i = i + 1\n",
    "    \n",
    "submission.to_csv('test_Result_otto.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
